diff --git a/configure b/configure
index 6b5ef63..1370243 100755
--- a/configure
+++ b/configure
@@ -348,6 +348,7 @@ External library support:
   --enable-rkmpp           enable Rockchip Media Process Platform code [no]
   --disable-v4l2-m2m       disable V4L2 mem2mem code [autodetect]
   --disable-vaapi          disable Video Acceleration API (mainly Unix/Intel) code [autodetect]
+  --disable-vastapi        disable VAST API code [autodetect]
   --disable-vdpau          disable Nvidia Video Decode and Presentation API for Unix code [autodetect]
   --disable-videotoolbox   disable VideoToolbox code [autodetect]
 
@@ -1743,6 +1744,10 @@ EXAMPLE_LIST="
     transcoding_example
     vaapi_encode_example
     vaapi_transcode_example
+    vastapi_downscale_example
+    vastapi_transcode_example
+    vastapi_varres_transcode_example
+    vastapi_10bit_encode_example
 "
 
 EXTERNAL_AUTODETECT_LIBRARY_LIST="
@@ -1895,6 +1900,7 @@ HWACCEL_AUTODETECT_LIBRARY_LIST="
     nvdec
     nvenc
     vaapi
+    vastapi
     vdpau
     videotoolbox
     vulkan
@@ -2502,6 +2508,7 @@ CONFIG_EXTRA="
     tpeldsp
     vaapi_1
     vaapi_encode
+    vastapi_encode
     vc1dsp
     videodsp
     vp3dsp
@@ -3029,6 +3036,10 @@ h264_nvdec_hwaccel_deps="nvdec"
 h264_nvdec_hwaccel_select="h264_decoder"
 h264_vaapi_hwaccel_deps="vaapi"
 h264_vaapi_hwaccel_select="h264_decoder"
+h264_vastapi_hwaccel_deps="vastapi"
+hevc_vastapi_hwaccel_deps="vastapi"
+av1_vastapi_hwaccel_deps="vastapi"
+mjpeg_vastapi_hwaccel_deps="vastapi"
 h264_vdpau_hwaccel_deps="vdpau"
 h264_vdpau_hwaccel_select="h264_decoder"
 h264_videotoolbox_hwaccel_deps="videotoolbox"
@@ -3134,6 +3145,7 @@ qsvdec_select="qsv"
 qsvenc_select="qsv"
 qsvvpp_select="qsv"
 vaapi_encode_deps="vaapi"
+vastapi_encode_deps="vastapi"
 v4l2_m2m_deps="linux_videodev2_h sem_timedwait"
 
 hwupload_cuda_filter_deps="ffnvcodec"
@@ -3173,6 +3185,10 @@ h264_qsv_encoder_select="atsc_a53 qsvenc"
 h264_rkmpp_decoder_deps="rkmpp"
 h264_rkmpp_decoder_select="h264_mp4toannexb_bsf"
 h264_vaapi_encoder_select="cbs_h264 vaapi_encode"
+h264_vastapi_encoder_select="vastapi_encode"
+hevc_vastapi_encoder_select="vastapi_encode"
+av1_vastapi_encoder_select="vastapi"
+mjpeg_vastapi_encoder_select="cbs_jpeg jpegtables vastapi_encode"
 h264_v4l2m2m_decoder_deps="v4l2_m2m h264_v4l2_m2m"
 h264_v4l2m2m_decoder_select="h264_mp4toannexb_bsf"
 h264_v4l2m2m_encoder_deps="v4l2_m2m h264_v4l2_m2m"
@@ -3602,6 +3618,7 @@ libzmq_protocol_deps="libzmq"
 libzmq_protocol_select="network"
 
 # filters
+misc_vastapi_filter_deps="vastapi"
 afir_filter_deps="avcodec"
 afir_filter_select="rdft"
 ametadata_filter_deps="avformat"
@@ -3761,6 +3778,10 @@ yadif_cuda_filter_deps_any="cuda_nvcc cuda_llvm"
 yadif_videotoolbox_filter_deps="metal corevideo videotoolbox"
 
 # examples
+vastapi_downscale_example_deps="vastapi"
+vastapi_transcode_example_deps="avcodec avformat avutil h264_vastapi_encoder"
+vastapi_varres_transcode_example_deps="avcodec avformat avutil h264_vastapi_encoder"
+vastapi_10bit_encode_example_deps="avcodec avformat avutil h264_vastapi_encoder"
 avio_list_dir_deps="avformat avutil"
 avio_reading_deps="avformat avcodec avutil"
 decode_audio_example_deps="avcodec avutil"
@@ -6891,6 +6912,10 @@ if enabled vaapi; then
     check_type "va/va.h va/va_enc_vp9.h"  "VAEncPictureParameterBufferVP9"
 fi
 
+#if enabled vastapi ; then
+#    vastapi_extralibs='-l:vastai_drv_video.so'
+#fi
+
 if enabled_all opencl libdrm ; then
     check_type "CL/cl_intel.h" "clCreateImageFromFdINTEL_fn" &&
         enable opencl_drm_beignet
diff --git a/doc/examples/Makefile b/doc/examples/Makefile
index 81bfd34..c5dc536 100644
--- a/doc/examples/Makefile
+++ b/doc/examples/Makefile
@@ -21,7 +21,10 @@ EXAMPLES-$(CONFIG_TRANSCODE_AAC_EXAMPLE)     += transcode_aac
 EXAMPLES-$(CONFIG_TRANSCODING_EXAMPLE)       += transcoding
 EXAMPLES-$(CONFIG_VAAPI_ENCODE_EXAMPLE)      += vaapi_encode
 EXAMPLES-$(CONFIG_VAAPI_TRANSCODE_EXAMPLE)   += vaapi_transcode
-
+EXAMPLES-$(CONFIG_VASTAPI_DOWNSCALE_EXAMPLE) += vastapi_downscale
+EXAMPLES-$(CONFIG_VASTAPI_TRANSCODE_EXAMPLE) += vastapi_transcode
+EXAMPLES-$(CONFIG_VASTAPI_VARRES_TRANSCODE_EXAMPLE) += vastapi_varres_transcode
+EXAMPLES-$(CONFIG_VASTAPI_10BIT_ENCODE_EXAMPLE) += vastapi_10bit_encode
 EXAMPLES       := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)$(EXESUF))
 EXAMPLES_G     := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)_g$(EXESUF))
 ALL_EXAMPLES   := $(EXAMPLES) $(EXAMPLES-:%=doc/examples/%$(PROGSSUF)$(EXESUF))
diff --git a/doc/examples/vastapi_10bit_encode.c b/doc/examples/vastapi_10bit_encode.c
new file mode 100644
index 0000000..c7ed02e
--- /dev/null
+++ b/doc/examples/vastapi_10bit_encode.c
@@ -0,0 +1,546 @@
+#define CONFIG_VASTAPI 1
+#include <stdio.h>
+#include <errno.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <pthread.h>
+#include <unistd.h>
+#include "libavutil/hwcontext.h"
+#include "libavcodec/avcodec.h"
+#include "libavformat/avformat.h"
+#include "libavutil/opt.h"
+#include <string.h>
+#include <semaphore.h>
+#include <getopt.h>
+#include <sys/time.h>
+#include <unistd.h>
+#include "libavcodec/internal.h"
+
+#define MAX_LEN 2
+pthread_t pid_1;
+pthread_t pid_2;
+pthread_t pid_3;
+#define read_frame_count 10
+
+uint8_t            *data_yuv_y[read_frame_count]  = { NULL };
+uint8_t            *data_yuv_u[read_frame_count]  = { NULL };
+uint8_t            *data_yuv_v[read_frame_count]  = { NULL };
+uint8_t            *data_uv_tmp[read_frame_count] = { NULL };
+struct Queue       *queue_odd;
+struct Queue       *queue_even;
+static AVBufferRef *hw_device_ctx = NULL;
+AVCodecContext     *avctx         = NULL;
+FILE               *fin = NULL, *fout = NULL;
+int                 dma_count    = 0;
+int                 encode_count = 0;
+int                 input_w;
+int                 input_h;
+
+typedef struct node {
+    AVFrame     *dma_frame;
+    struct node *next;
+} node;
+
+typedef struct {
+    node           *front;
+    node           *rear;
+    int             len;
+    int             max_len;
+    pthread_mutex_t q_lock;
+    pthread_cond_t  not_empty;
+    pthread_cond_t  not_full;
+} Queue;
+
+static void *init_queue(void)
+{
+    Queue *queue = (Queue *)malloc(sizeof(Queue));
+    if (!queue)
+        exit(1);
+
+    queue->rear = queue->front = (node *)malloc(sizeof(node));
+    queue->front->next         = NULL;
+    queue->len                 = 0;
+    queue->max_len             = MAX_LEN;
+
+    pthread_mutex_init(&queue->q_lock, NULL);
+    pthread_cond_init(&queue->not_empty, NULL);
+    pthread_cond_init(&queue->not_full, NULL);
+
+    return queue;
+}
+
+static void de_queue(Queue *q)
+{
+    node *newnode;
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == 0) {
+        printf("this queue is empty\n");
+        pthread_cond_wait(&q->not_empty, &q->q_lock);
+    }
+
+    newnode        = (void *)q->front->next;
+    q->front->next = newnode->next;
+
+    if (q->rear == newnode)
+        q->rear = q->front;
+
+    av_frame_free(&newnode->dma_frame);
+    newnode->dma_frame = NULL;
+    free(newnode);
+
+    q->len = q->len - 1;
+
+    pthread_cond_signal(&q->not_full);
+    pthread_mutex_unlock(&q->q_lock);
+    return;
+}
+
+static void *read_queue(Queue *q)
+{
+    node          *read_node;
+    struct timeval start;
+    struct timeval end;
+    gettimeofday(&start, NULL);
+    pthread_mutex_lock(&q->q_lock);
+
+    while (q->len == 0) {
+        pthread_cond_wait(&q->not_empty, &q->q_lock);
+    }
+    read_node = (void *)q->front->next;
+    if (read_node == NULL) {
+        printf("q->front->next is empty\n");
+        return NULL;
+    }
+
+    pthread_cond_signal(&q->not_full);
+    pthread_mutex_unlock(&q->q_lock);
+    gettimeofday(&end, NULL);
+    printf("read time =%ld us\n", (end.tv_sec * 1000000 - start.tv_sec * 1000000) + (end.tv_usec - start.tv_usec));
+    return read_node->dma_frame;
+}
+
+static int destroy_queue(Queue *q)
+{
+    while (q->front) {
+        q->rear = (void *)q->front->next;
+        free(q->front);
+        q->front = q->rear;
+    }
+
+    return 0;
+}
+
+typedef struct var {
+    int                width;
+    int                height;
+    char              *enc;
+    int                frameCnt;
+    enum AVPixelFormat pixel_format;
+    int                fps;
+    int                bit_rate;
+    char              *input_file;
+    char              *out_file;
+    char              *render;
+    char              *vast_config;
+} var;
+
+static void freep(AVFrame **sw_frame, AVFrame **hw_frame)
+{
+    if (*sw_frame) {
+        av_frame_free(sw_frame);
+        *sw_frame = NULL;
+    }
+    if (*hw_frame) {
+        av_frame_free(hw_frame);
+        *hw_frame = NULL;
+    }
+}
+
+static void push_normal_var(AVCodecContext *avctx, var *normal_var)
+{
+    avctx->width               = normal_var->width;
+    avctx->height              = normal_var->height;
+    avctx->time_base           = (AVRational){ 1, normal_var->fps };
+    avctx->framerate           = (AVRational){ normal_var->fps, 1 };
+    avctx->sample_aspect_ratio = (AVRational){ 1, 1 };
+    avctx->pix_fmt             = AV_PIX_FMT_VASTAPI;
+    avctx->sw_pix_fmt          = AV_PIX_FMT_NONE;
+    avctx->bit_rate            = normal_var->bit_rate;
+}
+
+static int set_hw_frame_ctx(AVCodecContext *ctx, AVBufferRef *hw_device_ctx, var *source)
+{
+    AVBufferRef       *hw_frames_ref;
+    AVHWFramesContext *frames_ctx = NULL;
+    int                err        = 0;
+    if (!(hw_frames_ref = av_hwframe_ctx_alloc(hw_device_ctx))) {
+        fprintf(stderr, "Failed to create VASTAPI frame context.\n");
+        return -1;
+    }
+    frames_ctx                    = (AVHWFramesContext *)(hw_frames_ref->data);
+    frames_ctx->format            = AV_PIX_FMT_VASTAPI;
+    frames_ctx->sw_format         = source->pixel_format;
+    frames_ctx->width             = source->width;
+    frames_ctx->height            = source->height;
+    frames_ctx->initial_pool_size = 64; // raoli pass2match org=20; raoli 2pass for gop4look4 last 4frame not match
+    if ((err = av_hwframe_ctx_init(hw_frames_ref)) < 0) {
+        fprintf(stderr, "Failed to initialize VASTAPI frame context. Error: %s\n", av_err2str(err));
+        av_buffer_unref(&hw_frames_ref);
+        return err;
+    }
+    ctx->hw_frames_ctx = av_buffer_ref(hw_frames_ref);
+    if (!ctx->hw_frames_ctx) {
+        err = AVERROR(ENOMEM);
+    }
+    av_buffer_unref(&hw_frames_ref);
+    return err;
+}
+
+static int init_codec(var *normal_var)
+{
+    int      err;
+    AVCodec *codec = NULL;
+    if ((err = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_VASTAPI, normal_var->render, NULL, 0)) < 0) {
+        fprintf(stderr, "Failed to create a VASTAPI device. Error: %s\n", av_err2str(err));
+        return err;
+    }
+    if (!(codec = avcodec_find_encoder_by_name(normal_var->enc))) {
+        fprintf(stderr, "Failed to find %s encoder\n", normal_var->enc);
+        err = -1;
+        return err;
+    }
+    if (!(avctx = avcodec_alloc_context3(codec))) {
+        fprintf(stderr, "Failed to create %s codec context\n", normal_var->enc);
+        err = -1;
+        return err;
+    }
+    push_normal_var(avctx, normal_var);
+    av_opt_set(avctx->priv_data, "vast-params", normal_var->vast_config, 0);
+    if ((err = set_hw_frame_ctx(avctx, hw_device_ctx, normal_var)) < 0) {
+        fprintf(stderr, "Failed to set hwframe context.\n");
+        return err;
+    }
+    if ((err = avcodec_open2(avctx, codec, NULL)) < 0) {
+        fprintf(stderr, "Cannot open video encoder codec.\n");
+        return err;
+    }
+    return 0;
+}
+
+static int encode_write(AVCodecContext *avctx, AVFrame *frame, FILE *fout, char *enc)
+{
+    int              ret = 0, i = 0;
+    AVPacket         enc_pkt;
+    AVCodecInternal *avci      = avctx->internal;
+    AVCodec         *enc_codec = NULL;
+    av_init_packet(&enc_pkt);
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+    if ((ret = avcodec_send_frame(avctx, frame)) < 0) {
+        fprintf(stderr, "Error code: %s\n", av_err2str(ret));
+        goto end;
+    }
+
+    while (1) {
+        ret = avcodec_receive_packet(avctx, &enc_pkt);
+        if (ret) {
+            break;
+        }
+        enc_pkt.stream_index = 0;
+        ret                  = fwrite(enc_pkt.data, enc_pkt.size, 1, fout);
+        av_packet_unref(&enc_pkt);
+    }
+end:
+    ret = ((ret == AVERROR(EAGAIN)) ? 0 : -1);
+    return ret;
+}
+
+static void en_queue_even(Queue *q, VastFrameInfo info)
+{
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == MAX_LEN) {
+        pthread_cond_wait(&q->not_full, &q->q_lock);
+    }
+    AVFrame *frame     = NULL;
+    frame              = av_frame_alloc_vastai(avctx->hw_frames_ctx, &info);
+    node *newnode      = (node *)malloc(sizeof(node));
+    newnode->dma_frame = frame;
+
+    memcpy(newnode->dma_frame->data[0], data_yuv_y[dma_count % read_frame_count], input_h * input_w * 2);
+    memcpy(newnode->dma_frame->data[1], data_uv_tmp[dma_count % read_frame_count], input_h * input_w);
+
+    newnode->next = NULL;
+
+    q->rear->next = (void *)newnode;
+    q->rear       = newnode;
+    q->len        = q->len + 1;
+    dma_count++;
+    pthread_cond_signal(&q->not_empty);
+    pthread_mutex_unlock(&q->q_lock);
+}
+
+static void en_queue_odd(Queue *q, VastFrameInfo info)
+{
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == MAX_LEN) {
+        pthread_cond_wait(&q->not_full, &q->q_lock);
+    }
+    AVFrame *frame     = NULL;
+    frame              = av_frame_alloc_vastai(avctx->hw_frames_ctx, &info);
+    node *newnode      = (node *)malloc(sizeof(node));
+    newnode->dma_frame = frame;
+
+    memcpy(newnode->dma_frame->data[0], data_yuv_y[dma_count % read_frame_count], input_h * input_w * 2);
+    memcpy(newnode->dma_frame->data[1], data_uv_tmp[dma_count % read_frame_count], input_h * input_w);
+
+    newnode->next = NULL;
+
+    q->rear->next = (void *)newnode;
+    q->rear       = newnode;
+    q->len        = q->len + 1;
+    dma_count++;
+    pthread_cond_signal(&q->not_empty);
+    pthread_mutex_unlock(&q->q_lock);
+}
+
+static void *input_dma_buffer_even(void *arg)
+{
+    struct var   *normal_var = (struct var *)arg;
+    VastFrameInfo info;
+    info.format = normal_var->pixel_format;
+    info.width  = normal_var->width;
+    info.height = normal_var->height;
+    while (dma_count < normal_var->frameCnt) {
+        if (dma_count % 2 == 0) {
+            en_queue_even((void *)queue_even, info);
+        }
+    }
+    return NULL;
+}
+
+static void *input_dma_buffer_odd(void *arg)
+{
+
+    struct var   *normal_var = (struct var *)arg;
+    VastFrameInfo info;
+    info.format = normal_var->pixel_format;
+    info.width  = normal_var->width;
+    info.height = normal_var->height;
+    while (dma_count < normal_var->frameCnt) {
+        if (dma_count % 2 == 1) {
+            en_queue_odd((void *)queue_odd, info);
+        }
+    }
+    return NULL;
+}
+
+static void *encode_frame(void *arg)
+{
+    struct var *normal_var = (struct var *)arg;
+    int         err;
+    while (encode_count < normal_var->frameCnt) {
+        struct timeval start;
+        struct timeval end;
+        gettimeofday(&start, NULL);
+
+        AVFrame *dma_frame = NULL;
+        AVFrame *hw_frame  = NULL;
+
+        if (!(hw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(err));
+        }
+        if ((err = av_hwframe_get_buffer(avctx->hw_frames_ctx, hw_frame, 0)) < 0) {
+            fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(err));
+        }
+        if (!hw_frame->hw_frames_ctx) {
+            err = AVERROR(ENOMEM);
+            fprintf(stderr, "Hardware frame context is null! Error: %s.\n", av_err2str(err));
+        }
+        if (encode_count % 2 == 0) {
+            dma_frame = read_queue((void *)queue_even);
+        } else {
+            dma_frame = read_queue((void *)queue_odd);
+        }
+        if ((err = av_hwframe_transfer_data(hw_frame, dma_frame, 0)) < 0) {
+            fprintf(stderr, "Failed to transfer frame data to surface, Error: %s.\n", av_err2str(err));
+        }
+        av_hwframe_sync_surface(hw_frame);
+        if ((err = encode_write(avctx, hw_frame, fout, normal_var->enc)) < 0) {
+            fprintf(stderr, "Failed to encode, Error:%s.\n", av_err2str(err));
+        }
+        av_frame_free(&hw_frame);
+        if (encode_count % 2 == 0) {
+            de_queue((void *)queue_even);
+        } else {
+            de_queue((void *)queue_odd);
+        }
+        encode_count++;
+        gettimeofday(&end, NULL);
+        printf("all time =%ld us\n", (end.tv_sec * 1000000 - start.tv_sec * 1000000) + (end.tv_usec - start.tv_usec));
+    }
+    return NULL;
+}
+
+static int init_yuv_10bit(var *normal_var)
+{
+    if (!(fin = fopen(normal_var->input_file, "r"))) {
+        fprintf(stderr, "Failed to open input file: %s\n", normal_var->input_file);
+        return -1;
+    }
+    if (!(fout = fopen(normal_var->out_file, "w+b"))) {
+        fprintf(stderr, "Failed to open output file %s\n", normal_var->out_file);
+        return -1;
+    }
+    printf("================== out file: %s ==================\n", normal_var->out_file);
+    if (normal_var->pixel_format == AV_PIX_FMT_P010LE) {
+        for (int i = 0; i < read_frame_count; i++) {
+            data_yuv_y[i]  = (uint8_t *)malloc(sizeof(uint8_t) * normal_var->width * normal_var->height * 2);
+            data_yuv_u[i]  = (uint8_t *)malloc(sizeof(uint8_t) * normal_var->width * normal_var->height / 2);
+            data_yuv_v[i]  = (uint8_t *)malloc(sizeof(uint8_t) * normal_var->width * normal_var->height / 2);
+            data_uv_tmp[i] = (uint8_t *)malloc(sizeof(uint8_t) * normal_var->width * normal_var->height);
+            fread(data_yuv_y[i], normal_var->width * normal_var->height * 2, 1, fin);
+            fread(data_yuv_u[i], normal_var->width * normal_var->height / 2, 1, fin);
+            fread(data_yuv_v[i], normal_var->width * normal_var->height / 2, 1, fin);
+            uint16_t *tmp_y  = NULL;
+            uint16_t *tmp_u  = NULL;
+            uint16_t *tmp_v  = NULL;
+            uint16_t *tmp_uv = NULL;
+            tmp_y            = data_yuv_y[i];
+            tmp_u            = data_yuv_u[i];
+            tmp_v            = data_yuv_v[i];
+            tmp_uv           = data_uv_tmp[i];
+            for (int j = 0; j < normal_var->width * normal_var->height; j++) {
+                *tmp_y = *tmp_y << 6;
+                *tmp_y++;
+            }
+            for (int j = 0; j < normal_var->width * normal_var->height / 2; j++) {
+                *tmp_uv = *tmp_u << 6;
+                tmp_u++;
+                tmp_uv++;
+                *tmp_uv = *tmp_v << 6;
+                tmp_uv++;
+                tmp_v++;
+            }
+        }
+    }
+    return 0;
+}
+
+static void free_alloc(var *normal_var)
+{
+    if (fin) {
+        fclose(fin);
+        fin = NULL;
+    }
+    if (fout) {
+        fclose(fout);
+        fout = NULL;
+    }
+    if (avctx) {
+        avcodec_free_context(&avctx);
+        avctx = NULL;
+    }
+    if (normal_var) {
+        free(normal_var);
+        normal_var = NULL;
+    }
+    for (int j = 0; j < read_frame_count; j++) {
+        if (data_uv_tmp[j]) {
+            free(data_uv_tmp[j]);
+            data_uv_tmp[j] = NULL;
+        }
+        if (data_yuv_y[j]) {
+            free(data_yuv_y[j]);
+            data_yuv_y[j] = NULL;
+        }
+    }
+}
+
+static void init_params(var *normal_var)
+{
+    normal_var->bit_rate   = 1000000;
+    normal_var->enc        = "hevc_vastapi";
+    normal_var->fps        = 25;
+    normal_var->frameCnt   = 1000;
+    normal_var->width      = 7680;
+    normal_var->height     = 4320;
+    normal_var->input_file = "/home/zheliu/python_API/8K_test/lala_8k.yuv";
+    // normal_var->input_file = "/home/zheliu/yuv/4k_10bit.yuv";
+    normal_var->out_file     = "/home/zheliu/liuzhe/test_2thread.hevc";
+    normal_var->render       = "/dev/dri/renderD129";
+    normal_var->pixel_format = AV_PIX_FMT_P010LE;
+    normal_var->vast_config =
+        "lookaheadLength=0:preset=bronze_quality:miniGopSize=1:keyint=40:tune=1:bitDepthLuma=10:bitDepthChroma=10";
+    input_w = normal_var->width;
+    input_h = normal_var->height;
+}
+
+int main(int argc, char *argv[])
+{
+    int         err;
+    struct var *normal_var = (var *)malloc(sizeof(var));
+    memset(normal_var, 0, sizeof(var));
+    init_params(normal_var);
+    queue_odd  = init_queue();
+    queue_even = init_queue();
+    if (init_codec(normal_var) < 0) {
+        printf("init codec err!\n");
+        return -1;
+    }
+    if (init_yuv_10bit(normal_var) < 0) {
+        printf("init yuv err!\n");
+        return -1;
+    }
+
+    if (pthread_create(&pid_1, NULL, input_dma_buffer_even, (void *)normal_var)) {
+        printf("create error!\n");
+        return -1;
+    }
+    if (pthread_create(&pid_2, NULL, input_dma_buffer_odd, (void *)normal_var)) {
+        printf("create error!\n");
+        return -1;
+    }
+    if (pthread_create(&pid_3, NULL, encode_frame, (void *)normal_var)) {
+        printf("create error!\n");
+        return -1;
+    }
+
+    // cpu_set_t mask;
+    // CPU_ZERO(&mask);
+
+    // CPU_SET(1,&mask);
+    // // 将线程1 固定在CPU5上运行
+    // if(pthread_setaffinity_np(pid_1,sizeof(mask),&mask) < 0)
+    // {
+    // 	printf("pthread_setaffinity_np failed\n");
+    // }
+
+    // CPU_ZERO(&mask);
+
+    // CPU_SET(7,&mask);
+    // // 将线程2 固定在CPU7上运行
+    // if(pthread_setaffinity_np(pid_2,sizeof(mask),&mask) < 0)
+    // {
+    // 	printf("pthread_setaffinity_np failed\n");
+    // }
+
+    if (pthread_join(pid_1, NULL)) {
+        printf("thread is not exit...\n");
+        return -2;
+    }
+    if (pthread_join(pid_2, NULL)) {
+        printf("thread is not exit...\n");
+        return -2;
+    }
+    if (pthread_join(pid_3, NULL)) {
+        printf("thread is not exit...\n");
+        return -2;
+    }
+
+    err = encode_write(avctx, NULL, fout, normal_var->enc);
+    free_alloc(normal_var);
+    destroy_queue((void *)queue_odd);
+    destroy_queue((void *)queue_even);
+    printf("finish!!! %d\n", err);
+    return 0;
+}
diff --git a/doc/examples/vastapi_README b/doc/examples/vastapi_README
new file mode 100644
index 0000000..8117260
--- /dev/null
+++ b/doc/examples/vastapi_README
@@ -0,0 +1,65 @@
+vastai examples README
+----------------------
+1.编译
+sample路径为/opt/vastai/vaststream/samples/vastapi，执行如下编译命令可获取sample的可执行文件。
+
+```bash
+cd /opt/vastai/vaststream/samples/vastapi
+make clean;make
+```
+2.测试
+
+使用downscale一进多出(xx.yuv 与xx_x.h264,xx_x.hevc为输入输出路径，vastai_videoX为节点名,根据/dev/路径下进行调配)
+```bash
+/opt/vastai/vaststream/samples/vastapi_downscale -i /opt/vastai/vaststream/samples\
+/dataset/video/mp4/ParkScene_1920x1080_30fps_loop_8M.mp4 -e /dev/vastai_video0\
+-c hevc_vastapi,hevc_vastapi,hevc_vastapi,hevc_vastapi\
+-f "vacl_scale=format=nv12:outputs=4:resize_type=bicubic:\
+output_size=1280x720+960x540+640x360+1920x1080"\
+-b 1000000,512000,512000,2000000\
+-v "vbvBufSize=1000:vbvMaxRate=1200:keyint=60:miniGopSize=0:lookaheadLength=20\
+:intraQpOffset=-2:preset=gold_quality:userCoreID=0"\
+"vbvBufSize=512:vbvMaxRate=600:keyint=60:miniGopSize=0:lookaheadLength=20\
+:intraQpOffset=-2:preset=gold_quality:userCoreID=0"\
+"vbvBufSize=512:vbvMaxRate=600:keyint=60:miniGopSize=0:lookaheadLength=20\
+:intraQpOffset=-2:preset=gold_quality:userCoreID=0"\
+"vbvBufSize=2000:vbvMaxRate=2400:keyint=60:miniGopSize=0:lookaheadLength=20\
+:intraQpOffset=-2:preset=gold_quality:userCoreID=0"\
+-o die0_case2_gold_0.hevc,die0_case2_gold_1.hevc,die0_case2_gold_2.hevc\
+,die0_case2_gold_3.hevc
+```
+
+使用transcode进行编码(xx.yuv 与xx.hevc为输入输出路径，vastai_videoX为节点名,根据/dev/路径下进行调配)
+```bash
+/opt/vastai/vaststream/samples/vastapi/vastapi_transcode\
+-i xx.yuv\
+-r /dev/vastai_video0\
+-e hevc_vastapi\
+-f 24\
+-s 1920x1080\
+--pix_fmt yuv420p\
+-b 2000000\
+--vast_params tune=1:vbvBufSize=2000:vbvMaxRate=2400:keyint=60\
+:lookaheadLength=4:intraQpOffset=-2:preset=gold_quality:miniGopSize=0\
+-o xx.hevc
+```
+
+使用transcode进行转码(xx.mp4 与xx.h264为输入输出路径，vastai_videoX为节点名,根据/dev/路径下进行调配)
+```bash
+/opt/vastai/vaststream/samples/vastapi/vastapi_transcode -i xx.mp4\
+-r /dev/vastai_video0\
+-c h264_vastapi\
+-b 2000000\
+--vast_params tune=1:vbvBufSize=2000:vbvMaxRate=2400:keyint=60:lookaheadLength=4:\
+intraQpOffset=-2:preset=gold_quality:miniGopSize=0\
+-o xx.h264
+```
+3.参数说明
+--vast_params          与ffmpeg中vast-prarms参数使用一致
+-i                     输入文件名
+-r                     设备节点名
+-c                     编码类型
+-f                     编码帧率
+-b					   码率
+-pix_fmt		       编码文件类型
+-s                     码流尺寸
diff --git a/doc/examples/vastapi_downscale.c b/doc/examples/vastapi_downscale.c
new file mode 100644
index 0000000..93fc225
--- /dev/null
+++ b/doc/examples/vastapi_downscale.c
@@ -0,0 +1,1584 @@
+/*
+ * Copyright (c) 2010 Nicolas George
+ * Copyright (c) 2011 Stefano Sabatini
+ * Copyright (c) 2014 Andrey Utkin
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * API example for demuxing, decoding, filtering, encoding and muxing
+ * @example transcoding.c
+ */
+
+#define CONFIG_VASTAPI 1
+
+#include <libavcodec/avcodec.h>
+#include <libavfilter/buffersink.h>
+#include <libavfilter/buffersrc.h>
+#include <libavformat/avformat.h>
+#include <libavutil/opt.h>
+#include <libavutil/pixdesc.h>
+
+//#include <time.h>
+#include "dlfcn.h"
+#include <getopt.h>
+#include <pthread.h>
+#include <signal.h>
+#include <sys/time.h>
+#include <unistd.h>
+
+pthread_cond_t  cond  = PTHREAD_COND_INITIALIZER;
+pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
+
+static int term_status = 0;
+static int initialized = 0;
+
+static void sigterm_handler(int sig)
+{
+    printf("Have caught signal N.O. %d\n", sig);
+    term_status = 1;
+}
+
+#define MAX_CHANNEL 8
+#define ENABLE_ENCODE
+
+typedef struct FilteringContext {
+    AVFilterContext *buffersink_ctx[MAX_CHANNEL];
+    AVFilterContext *buffersrc_ctx;
+    AVFilterGraph   *filter_graph;
+    AVPacket        *enc_pkt[MAX_CHANNEL];
+} FilteringContext;
+
+typedef struct ThreadContext {
+    int input_num;
+    int status[MAX_CHANNEL];
+} ThreadContext;
+
+typedef struct StreamContext {
+    AVCodecContext *dec_ctx;
+    AVCodecContext *enc_ctx[MAX_CHANNEL];
+    AVFrame        *dec_frame;
+    int64_t         ts_offset;
+} StreamContext;
+
+struct thread_info {      /* Used as argument to thread_start() */
+    pthread_t thread_id;  /* ID returned by pthread_create() */
+    int       thread_num; /* Application-defined thread # */
+    void     *handle;
+};
+
+typedef struct Resolution {
+    int   width;
+    int   height;
+    int   new_width;
+    int   new_height;
+    float scaleh[MAX_CHANNEL];
+    float scalew[MAX_CHANNEL];
+    char  filter_descr[1000];
+    int   out_new_width[MAX_CHANNEL];
+    int   out_new_height[MAX_CHANNEL];
+    char  out_filename[MAX_CHANNEL][1000];
+} ResolutionCtx;
+
+struct DownscaleCtx {
+    struct thread_info *tinfo;
+    ThreadContext      *thread_ctx;
+    StreamContext      *stream_ctx;
+    FilteringContext   *filter_ctx;
+    AVBufferRef        *hw_device_ctx;
+    AVFormatContext    *ifmt_ctx;
+    AVFormatContext   **ofmt_ctx;
+    struct queue_root **queue_array;
+    AVRational          frame_rate;
+    int                 thread_num;
+    int                 scene_case;
+    char                render[100];
+    char                filename[500];
+    char                vast_params[MAX_CHANNEL][1000];
+    char                out_filename[MAX_CHANNEL][1000];
+    char                encoder_name[MAX_CHANNEL][100];
+    int                 bitrate[MAX_CHANNEL];
+    char                filter_descr[1000];
+    int                 stream_index;
+    ResolutionCtx       resctx;
+    int                 frame_count[MAX_CHANNEL];
+};
+
+AVDictionary *opts;
+
+static void *encode_thread(void *arg);
+void         filter_encode_deinit(struct DownscaleCtx *downscale_ctx);
+
+struct queue_root {
+    struct queue_node    *head;
+    struct queue_node    *tail;
+    volatile unsigned int size;
+};
+
+struct queue_node {
+    void              *n;
+    struct queue_node *next;
+};
+
+enum EncodeStatus {
+    ENCODE_STATUS_UNKNOWN = -1, ///<
+    ENCODE_STATUS_BEGAIN,
+    ENCODE_STATUS_END,
+    ENCODE_STATUS_EXIT,
+};
+
+enum ScaleCase {
+    SCALE_CASE_UNKNOWN = -1, ///<
+    SCALE_CASE_1TO4    = 1,
+    SCALE_CASE_1TO4_HEVC,
+    SCALE_CASE_1TO8,
+    SCALE_CASE_1TO2,
+    SCALE_CASE_1TO2_HEVC,
+    SCALE_CASE_1TO4_6,
+    SCALE_CASE_1TO5,
+};
+
+static void init_queue(struct queue_root **root)
+{
+    *root = (struct queue_root *)malloc(sizeof(struct queue_root));
+    if (*root == NULL) {
+        printf("malloc failed");
+        exit(1);
+    }
+    (*root)->head       = (struct queue_node *)malloc(sizeof(struct queue_node)); /* Sentinel node */
+    (*root)->tail       = (*root)->head;
+    (*root)->head->n    = NULL;
+    (*root)->head->next = NULL;
+    (*root)->size       = 0;
+}
+
+static int queue_add(struct queue_root *root, void *val)
+{
+    struct queue_node *n;
+    struct queue_node *node = (struct queue_node *)malloc(sizeof(struct queue_node));
+    node->n                 = val;
+    node->next              = NULL;
+    while (1) {
+        n = root->tail;
+        if (__sync_bool_compare_and_swap(&(n->next), NULL, node)) {
+            break;
+        } else {
+            __sync_bool_compare_and_swap(&(root->tail), n, n->next);
+        }
+    }
+    __sync_bool_compare_and_swap(&(root->tail), n, node);
+    __sync_fetch_and_add(&root->size, 1);
+
+    return 1;
+}
+
+static void *queue_get(struct queue_root *root)
+{
+    struct queue_node *n;
+    void              *val;
+    while (1) {
+        n = root->head;
+        if (n->next == NULL) {
+            return NULL;
+        }
+
+        if (__sync_bool_compare_and_swap(&(root->head), n, n->next)) {
+            break;
+        }
+    }
+    val = (void *)n->next->n;
+    free(n);
+    __sync_fetch_and_sub(&root->size, 1);
+    return val;
+}
+
+static void deinit_queue(struct queue_root **root)
+{
+    if (root && *root) {
+        void *val = NULL;
+        do {
+            val = queue_get(*root);
+        } while (val);
+        if ((*root)->head) {
+            free((*root)->head);
+        }
+        free(*root);
+        *root = NULL;
+    }
+}
+
+static void print_localtime(void)
+{
+    time_t     timep;
+    struct tm *p;
+    time(&timep);
+    p = gmtime(&timep);
+    fprintf(stdout, "[%4d/%02d/%02d %02d:%02d:%02d]", 1900 + p->tm_year, 1 + p->tm_mon, p->tm_mday,
+            (8 + p->tm_hour) % 24, p->tm_min, p->tm_sec);
+}
+
+static int hw_decoder_init(struct DownscaleCtx *downscale_ctx, AVCodecContext *ctx)
+{
+    int err = 0;
+    av_dict_set(&opts, "vastai_file_url", downscale_ctx->filename, 0);
+    av_dict_set_int(&opts, "vastai_file_index", 0, 0);
+    av_dict_set_int(&opts, "vastai_stream_index", 0, 0);
+    av_dict_set_int(&opts, "vastai_width", ctx->width, 0);
+    av_dict_set_int(&opts, "vastai_height", ctx->height, 0);
+
+    err =
+        av_hwdevice_ctx_create(&downscale_ctx->hw_device_ctx, AV_HWDEVICE_TYPE_VASTAPI, downscale_ctx->render, opts, 0);
+    if (err < 0) {
+        fprintf(stderr, "Failed to create a VASTAPI device. Error code: %s\n", av_err2str(err));
+        return -1;
+    }
+    ctx->hw_device_ctx = av_buffer_ref(downscale_ctx->hw_device_ctx);
+    return err;
+}
+
+static enum AVPixelFormat get_vastapi_format(AVCodecContext *ctx, const enum AVPixelFormat *pix_fmts)
+{
+    const enum AVPixelFormat *p;
+    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
+        if (*p == AV_PIX_FMT_VASTAPI)
+            return *p;
+    }
+    fprintf(stderr, "Unable to decode this file using VA-API.\n");
+    return AV_PIX_FMT_NONE;
+}
+
+static int open_input_file(struct DownscaleCtx *downscale_ctx)
+{
+    int             ret;
+    AVCodec        *decoder = NULL;
+    AVStream       *stream  = NULL;
+    AVCodecContext *codec_ctx;
+
+    downscale_ctx->ifmt_ctx = NULL;
+    if ((ret = avformat_open_input(&downscale_ctx->ifmt_ctx, downscale_ctx->filename, NULL, NULL)) < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Cannot open input file\n");
+        return ret;
+    }
+
+    if ((ret = avformat_find_stream_info(downscale_ctx->ifmt_ctx, NULL)) < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Cannot find stream information\n");
+        return ret;
+    }
+    ret = av_find_best_stream(downscale_ctx->ifmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, &decoder, 0);
+    if (ret < 0) {
+        fprintf(stderr,
+                "Cannot find a video stream in the input file. "
+                "Error code: %s\n",
+                av_err2str(ret));
+        return ret;
+    }
+    downscale_ctx->stream_index = ret;
+    downscale_ctx->stream_ctx   = av_mallocz(sizeof(*downscale_ctx->stream_ctx));
+    if (!downscale_ctx->stream_ctx)
+        return AVERROR(ENOMEM);
+    if (downscale_ctx->ifmt_ctx->start_time != AV_NOPTS_VALUE)
+        downscale_ctx->stream_ctx->ts_offset = 0 - downscale_ctx->ifmt_ctx->start_time;
+    else
+        downscale_ctx->stream_ctx->ts_offset = 0;
+
+    stream = downscale_ctx->ifmt_ctx->streams[downscale_ctx->stream_index];
+
+    codec_ctx = avcodec_alloc_context3(decoder);
+    if (!codec_ctx) {
+        av_log(NULL, AV_LOG_ERROR, "Failed to allocate the decoder context for stream #%u\n",
+               downscale_ctx->stream_index);
+        return AVERROR(ENOMEM);
+    }
+    ret = avcodec_parameters_to_context(codec_ctx, stream->codecpar);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR,
+               "Failed to copy decoder parameters to input decoder context "
+               "for stream #%u\n",
+               downscale_ctx->stream_index);
+        return ret;
+    }
+
+    downscale_ctx->resctx.width      = codec_ctx->width;
+    downscale_ctx->resctx.height     = codec_ctx->height;
+    downscale_ctx->resctx.new_width  = codec_ctx->width;
+    downscale_ctx->resctx.new_height = codec_ctx->height;
+    print_localtime();
+    fprintf(stdout,
+            "[vastapi_downscale, pid %d]: create decoder,  input resolution "
+            "%dx%d. \n",
+            getpid(), codec_ctx->width, codec_ctx->height);
+
+    ret = hw_decoder_init(downscale_ctx, codec_ctx);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Failed to init hw decoder for stream #%u\n", downscale_ctx->stream_index);
+        return ret;
+    }
+    codec_ctx->get_format = get_vastapi_format;
+
+    /* Reencode video & audio and remux subtitles etc. */
+
+    codec_ctx->framerate = av_guess_frame_rate(downscale_ctx->ifmt_ctx, stream, NULL);
+    /* Open decoder */
+    ret = avcodec_open2(codec_ctx, decoder, NULL);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Failed to open decoder for stream #%u\n", downscale_ctx->stream_index);
+        return ret;
+    }
+    downscale_ctx->stream_ctx->dec_ctx   = codec_ctx;
+    downscale_ctx->stream_ctx->dec_frame = av_frame_alloc();
+    if (!downscale_ctx->stream_ctx->dec_frame)
+        return AVERROR(ENOMEM);
+
+    av_dump_format(downscale_ctx->ifmt_ctx, 0, downscale_ctx->filename, 0);
+    return 0;
+}
+
+static int open_output_file(struct DownscaleCtx *downscale_ctx, const char *filename, int thread_num)
+{
+    AVStream *out_stream;
+    // AVStream *in_stream;
+    AVCodecContext *dec_ctx, *enc_ctx;
+    AVCodec        *encoder;
+    int             ret;
+    unsigned int    i;
+    char            encoder_name[200];
+    if (*downscale_ctx->encoder_name[thread_num])
+        strcpy(encoder_name, downscale_ctx->encoder_name[thread_num]);
+    else
+        strcpy(encoder_name, "hevc_vastapi");
+
+    downscale_ctx->ofmt_ctx[thread_num] = NULL;
+    if (strcmp(filename, "-"))
+        avformat_alloc_output_context2(&downscale_ctx->ofmt_ctx[thread_num], NULL, NULL, filename);
+    else
+        avformat_alloc_output_context2(&downscale_ctx->ofmt_ctx[thread_num], NULL, "null", filename);
+
+    if (!downscale_ctx->ofmt_ctx[thread_num]) {
+        av_log(NULL, AV_LOG_ERROR, "Could not create output context\n");
+        return AVERROR_UNKNOWN;
+    }
+
+    // for (i = 0; i < downscale_ctx->ifmt_ctx->nb_streams; i++)
+    // i = downscale_ctx->stream_index;
+    // in_stream =
+    // downscale_ctx->ifmt_ctx->streams[downscale_ctx->stream_index];
+    dec_ctx = downscale_ctx->stream_ctx->dec_ctx;
+    // if (dec_ctx->codec_type != AVMEDIA_TYPE_VIDEO)
+    //     continue;
+    out_stream = avformat_new_stream(downscale_ctx->ofmt_ctx[thread_num], NULL);
+    if (!out_stream) {
+        av_log(NULL, AV_LOG_ERROR, "Failed allocating output stream\n");
+        return AVERROR_UNKNOWN;
+    }
+
+    if (dec_ctx->codec_type == AVMEDIA_TYPE_VIDEO) {
+        /* in this example, we choose transcoding to same codec */
+        encoder = avcodec_find_encoder_by_name(encoder_name);
+        if (!encoder) {
+            av_log(NULL, AV_LOG_FATAL, "Necessary encoder not found\n");
+            return AVERROR_INVALIDDATA;
+        }
+        enc_ctx = avcodec_alloc_context3(encoder);
+        if (!enc_ctx) {
+            av_log(NULL, AV_LOG_FATAL, "Failed to allocate the encoder context\n");
+            return AVERROR(ENOMEM);
+        }
+        av_opt_set(enc_ctx->priv_data, "vast-params", downscale_ctx->vast_params[thread_num], 0);
+        enc_ctx->bit_rate  = downscale_ctx->bitrate[thread_num];
+        enc_ctx->framerate = dec_ctx->framerate;
+        /* In this example, we transcode to same properties (picture size,
+         * sample rate etc.). These properties can be changed for output
+         * streams easily using filters */
+        enc_ctx->height              = downscale_ctx->filter_ctx->buffersink_ctx[thread_num]->inputs[0]->h;
+        enc_ctx->width               = downscale_ctx->filter_ctx->buffersink_ctx[thread_num]->inputs[0]->w;
+        enc_ctx->sample_aspect_ratio = dec_ctx->sample_aspect_ratio;
+        /* take first format from list of supported formats */
+        enc_ctx->pix_fmt    = AV_PIX_FMT_VASTAPI;
+        enc_ctx->sw_pix_fmt = AV_PIX_FMT_NV12;
+        /* video time_base can be set to whatever is handy and supported
+         * by encoder */
+        if (downscale_ctx->frame_rate.num)
+            enc_ctx->time_base = av_inv_q(downscale_ctx->frame_rate);
+        else
+            enc_ctx->time_base = av_inv_q(dec_ctx->framerate);
+
+        enc_ctx->hw_device_ctx = av_buffer_ref(downscale_ctx->hw_device_ctx);
+        if (!enc_ctx->hw_device_ctx) {
+            fprintf(stderr, "A hardware device reference create failed.\n");
+            return AVERROR(ENOMEM);
+        }
+        enc_ctx->hw_frames_ctx =
+            av_buffer_ref(downscale_ctx->filter_ctx->buffersink_ctx[thread_num]->inputs[0]->hw_frames_ctx);
+        if (!enc_ctx->hw_frames_ctx) {
+            av_log(NULL, AV_LOG_ERROR, "Cannot open video encoder for stream \n");
+            ret = AVERROR(ENOMEM);
+            return ret;
+        }
+        if (downscale_ctx->ofmt_ctx[thread_num]->oformat->flags & AVFMT_GLOBALHEADER)
+            enc_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
+
+        /* Third parameter can be used to pass settings to encoder */
+        ret = avcodec_open2(enc_ctx, encoder, NULL);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Cannot open video encoder for stream #%u\n", i);
+            return ret;
+        }
+        ret = avcodec_parameters_from_context(out_stream->codecpar, enc_ctx);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Failed to copy encoder parameters to output stream #%u\n", i);
+            return ret;
+        }
+
+        out_stream->time_base                          = enc_ctx->time_base;
+        downscale_ctx->stream_ctx->enc_ctx[thread_num] = enc_ctx;
+    } else {
+        /* if this stream must be remuxed */
+        av_log(NULL, AV_LOG_ERROR, "Error stream not supported\n");
+    }
+    av_dump_format(downscale_ctx->ofmt_ctx[thread_num], 0, filename, 1);
+
+    if (!(downscale_ctx->ofmt_ctx[thread_num]->oformat->flags & AVFMT_NOFILE)) {
+        ret = avio_open(&downscale_ctx->ofmt_ctx[thread_num]->pb, filename, AVIO_FLAG_WRITE);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Could not open output file '%s'", filename);
+            return ret;
+        }
+    }
+
+    /* init muxer, write output file header */
+    ret = avformat_write_header(downscale_ctx->ofmt_ctx[thread_num], NULL);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Error occurred when opening output file\n");
+        return ret;
+    }
+
+    return 0;
+}
+
+static int init_filter(FilteringContext *fctx, AVCodecContext *dec_ctx, AVCodecContext *enc_ctx,
+                       const char *filter_spec, int thread_num)
+{
+    char             args[512];
+    int              ret           = 0;
+    const AVFilter  *buffersrc     = NULL;
+    const AVFilter  *buffersink    = NULL;
+    AVFilterContext *buffersrc_ctx = NULL;
+    AVFilterGraph   *filter_graph  = avfilter_graph_alloc();
+    AVFilterContext *last_filter   = NULL;
+    AVFilterInOut   *outputs       = NULL;
+    AVFilterInOut   *inputs        = NULL;
+    AVFilterInOut   *cur           = NULL;
+
+    enum AVPixelFormat pix_fmts[] = { AV_PIX_FMT_VASTAPI };
+
+    int i             = 0;
+    int split_check   = 1;
+    int outputs_index = 0;
+    if (!filter_graph) {
+        ret = AVERROR(ENOMEM);
+        return ret;
+    }
+    AVBufferSrcParameters *par = av_buffersrc_parameters_alloc();
+    if (!par)
+        return AVERROR(ENOMEM);
+    memset(par, 0, sizeof(*par));
+    par->format = AV_PIX_FMT_NONE;
+
+    buffersrc  = avfilter_get_by_name("buffer");
+    buffersink = avfilter_get_by_name("buffersink");
+    if (!buffersrc || !buffersink) {
+        av_log(NULL, AV_LOG_ERROR, "filtering source or sink element not found\n");
+        ret = AVERROR_UNKNOWN;
+        goto end;
+    }
+
+    snprintf(args, sizeof(args), "video_size=%dx%d:pix_fmt=%d:time_base=%d/%d:pixel_aspect=%d/%d", dec_ctx->width,
+             dec_ctx->height, AV_PIX_FMT_VASTAPI, dec_ctx->time_base.num, dec_ctx->time_base.den,
+             dec_ctx->sample_aspect_ratio.num, dec_ctx->sample_aspect_ratio.den);
+
+    ret = avfilter_graph_create_filter(&buffersrc_ctx, buffersrc, "in", args, NULL, filter_graph);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Cannot create buffer source\n");
+        goto end;
+    }
+    
+    par->hw_frames_ctx = dec_ctx->hw_frames_ctx;
+    ret = av_buffersrc_parameters_set(buffersrc_ctx, par);
+    if (ret < 0)
+        goto end;
+    av_freep(&par);
+    if ((ret = avfilter_graph_parse2(filter_graph, filter_spec, &inputs, &outputs)) < 0) {
+        av_log(NULL, AV_LOG_ERROR, "avfilter_graph_parse2 failed\n");
+        goto end;
+    }
+
+    if ((ret = avfilter_link(buffersrc_ctx, 0, inputs->filter_ctx, inputs->pad_idx)) < 0) {
+        av_log(NULL, AV_LOG_ERROR, "avfilter_link failed\n");
+        return ret;
+    }
+
+    // inputs->filter_ctx->inputs[0]->hw_frames_ctx = av_buffer_ref(dec_ctx->hw_frames_ctx);
+    // if (!inputs->filter_ctx->inputs[0]->hw_frames_ctx) {
+    //     av_log(NULL, AV_LOG_ERROR, "AVFilterLink::hw_frames_ctx is NULL\n");
+    //     goto end;
+    // }
+    for (cur = outputs, i = 0; cur; cur = cur->next, i++) {
+        int have_name = cur->name ? 1 : 0;
+        split_check &= have_name;
+    }
+
+    if (split_check) {
+        outputs_index = thread_num - 1;
+    } else {
+        outputs_index = 0;
+    }
+
+    for (cur = outputs, i = outputs_index; cur; cur = cur->next) {
+        AVFilterContext *filter_out;
+        char             name[255];
+        last_filter = cur->filter_ctx;
+        snprintf(name, sizeof(name), "format_out_%d", i);
+        ret = avfilter_graph_create_filter(&filter_out, avfilter_get_by_name("format"), name, "vastapi", NULL,
+                                           filter_graph);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Cannot create format filter\n");
+            return ret;
+        }
+
+        if ((ret = avfilter_link(last_filter, cur->pad_idx, filter_out, 0)) < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error connecting filters\n");
+            return ret;
+        }
+
+        snprintf(name, sizeof(name), "out_%d", i);
+        ret = avfilter_graph_create_filter(&fctx->buffersink_ctx[i], buffersink, name, NULL, NULL, filter_graph);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Cannot create buffer source\n");
+            goto end;
+        }
+        ret = av_opt_set_bin(fctx->buffersink_ctx[i], "pix_fmts", (uint8_t *)&pix_fmts, sizeof(pix_fmts),
+                             AV_OPT_SEARCH_CHILDREN);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Cannot set output pixel format\n");
+            goto end;
+        }
+        if ((ret = avfilter_link(filter_out, 0, fctx->buffersink_ctx[i], 0)) < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error connecting filters\n");
+            return ret;
+        }
+        if (split_check) {
+            i--;
+        } else {
+            i++;
+        }
+    }
+
+    if ((ret = avfilter_graph_config(filter_graph, NULL)) < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Error configuring the filter graph\n");
+        goto end;
+    }
+
+    /* Fill FilteringContext */
+    fctx->buffersrc_ctx = buffersrc_ctx;
+    fctx->filter_graph  = filter_graph;
+end:
+    avfilter_inout_free(&inputs);
+    avfilter_inout_free(&outputs);
+    return ret;
+}
+
+static int init_filters(struct DownscaleCtx *downscale_ctx)
+{
+    unsigned int i;
+    int          ret;
+    downscale_ctx->filter_ctx = av_mallocz(sizeof(AVFormatContext));
+    if (!downscale_ctx->filter_ctx)
+        return AVERROR(ENOMEM);
+
+    downscale_ctx->filter_ctx->buffersrc_ctx = NULL;
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        downscale_ctx->filter_ctx->buffersink_ctx[i] = NULL;
+    }
+    downscale_ctx->filter_ctx->filter_graph = NULL;
+
+    ret = init_filter(downscale_ctx->filter_ctx, downscale_ctx->stream_ctx->dec_ctx, NULL, downscale_ctx->filter_descr,
+                      downscale_ctx->thread_num);
+    if (ret)
+        return ret;
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        downscale_ctx->filter_ctx->enc_pkt[i] = av_packet_alloc();
+        if (!downscale_ctx->filter_ctx->enc_pkt[i])
+            return AVERROR(ENOMEM);
+    }
+    return 0;
+}
+
+static int encode_write_frame(struct DownscaleCtx *downscale_ctx, int thread_index)
+{
+    int       ret;
+    AVPacket *enc_pkt    = NULL;
+    AVFrame  *filt_frame = NULL;
+
+    pthread_mutex_lock(&mutex);
+
+    while (downscale_ctx->queue_array[thread_index]->size == 0 &&
+           downscale_ctx->thread_ctx->status[thread_index] != ENCODE_STATUS_END)
+        pthread_cond_wait(&cond, &mutex);
+    pthread_mutex_unlock(&mutex);
+
+    // av_log(NULL, AV_LOG_INFO, "Encoding frame\n");
+    filt_frame = (AVFrame *)queue_get(downscale_ctx->queue_array[thread_index]);
+    // if (!filt_frame) {
+    //     fprintf(stderr, "Error get filter frame NULL. \n");
+    //     return -1;
+    // }
+    if (filt_frame) {
+        ret = av_hwframe_sync_surface(filt_frame);
+        if (ret < 0) {
+            fprintf(stderr, "av_hwframe_sync_surface ret %d \n", ret);
+            return ret;
+        }
+    }
+
+    /* encode filtered frame */
+    enc_pkt = downscale_ctx->filter_ctx->enc_pkt[thread_index];
+
+    if ((ret = avcodec_send_frame(downscale_ctx->stream_ctx->enc_ctx[thread_index], filt_frame)) < 0) {
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            ret = 0;
+        } else {
+            fprintf(stderr, "Error sending a frame for encoding. Error code: %s\n", av_err2str(ret));
+            return ret;
+        }
+    }
+
+    while (1) {
+        ret = avcodec_receive_packet(downscale_ctx->stream_ctx->enc_ctx[thread_index], enc_pkt);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+            break;
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_FATAL, "Error during encoding %d ret = %d \n", __LINE__, ret);
+            return -1;
+        }
+
+        enc_pkt->stream_index = 0;
+        // enc_pkt->pts = enc_pkt->dts = downscale_ctx->frame_count[thread_index] *
+        //                               downscale_ctx->ofmt_ctx[thread_index]->streams[0]->time_base.den /
+        //                               downscale_ctx->ofmt_ctx[thread_index]->streams[0]->time_base.num /
+        //                               (downscale_ctx->stream_ctx->enc_ctx[thread_index]->framerate.num /
+        //                                downscale_ctx->stream_ctx->enc_ctx[thread_index]->framerate.den);
+        av_packet_rescale_ts(enc_pkt, downscale_ctx->stream_ctx->enc_ctx[thread_index]->time_base,
+                             downscale_ctx->ofmt_ctx[thread_index]->streams[0]->time_base);
+
+        ret = av_interleaved_write_frame(downscale_ctx->ofmt_ctx[thread_index], enc_pkt);
+        if (ret < 0) {
+            fprintf(stderr,
+                    "Error during writing data to output file. "
+                    "Error code: %s\n",
+                    av_err2str(ret));
+            return -1;
+        }
+        downscale_ctx->frame_count[thread_index]++;
+    }
+
+    av_frame_free(&filt_frame);
+    if (ret == AVERROR_EOF)
+        return 0;
+    ret = ((ret == AVERROR(EAGAIN)) ? 0 : -1);
+    return ret;
+}
+
+static int flush_encode_write_frame(struct DownscaleCtx *downscale_ctx, AVFrame *filt_frame, int thread_num)
+{
+    int      ret     = 0;
+    AVPacket enc_pkt = { 0 };
+
+    // printf(" read queue %p q %p thread_num %d \n", filt_frame,
+    // queue_array[thread_num], thread_num);
+    /* encode filtered frame */
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+    av_init_packet(&enc_pkt);
+
+    if ((ret = avcodec_send_frame(downscale_ctx->stream_ctx->enc_ctx[thread_num], filt_frame)) < 0) {
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            ret = 0;
+        } else {
+            fprintf(stderr, "Error sending a frame for encoding. Error code: %s\n", av_err2str(ret));
+            return ret;
+        }
+    }
+
+    while (ret >= 0) {
+        ret = avcodec_receive_packet(downscale_ctx->stream_ctx->enc_ctx[thread_num], &enc_pkt);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            // ret = 0;
+            break;
+        }
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_FATAL, "Error during encoding %d\n", __LINE__);
+            return -1;
+        }
+
+        enc_pkt.stream_index = 0;
+        av_packet_rescale_ts(&enc_pkt, downscale_ctx->stream_ctx->enc_ctx[thread_num]->time_base,
+                             downscale_ctx->ofmt_ctx[thread_num]->streams[0]->time_base);
+        // enc_pkt.pts = enc_pkt.dts = downscale_ctx->frame_count[thread_num] *
+        //                             downscale_ctx->ofmt_ctx[thread_num]->streams[0]->time_base.den /
+        //                             downscale_ctx->ofmt_ctx[thread_num]->streams[0]->time_base.num /
+        //                             (downscale_ctx->stream_ctx->enc_ctx[thread_num]->framerate.num /
+        //                              downscale_ctx->stream_ctx->enc_ctx[thread_num]->framerate.den);
+
+        ret = av_interleaved_write_frame(downscale_ctx->ofmt_ctx[thread_num], &enc_pkt);
+        if (ret < 0) {
+            fprintf(stderr,
+                    "Error during writing data to output file. "
+                    "Error code: %s\n",
+                    av_err2str(ret));
+            return -1;
+        }
+        downscale_ctx->frame_count[thread_num]++;
+    }
+    av_packet_unref(&enc_pkt);
+    av_frame_free(&filt_frame);
+    if (ret == AVERROR_EOF)
+        return 0;
+    ret = ((ret == AVERROR(EAGAIN)) ? 0 : -1);
+    return ret;
+}
+
+static int filter_encode_init(struct DownscaleCtx *downscale_ctx, unsigned int stream_index)
+{
+    int ret;
+    int num_threads = downscale_ctx->thread_num;
+    int i           = 0;
+    for (i = 0; i < num_threads; i++) {
+        init_queue(&downscale_ctx->queue_array[i]);
+    }
+
+    if ((ret = init_filters(downscale_ctx)) < 0)
+        return ret;
+    for (i = 0; i < num_threads; i++) {
+        if (ret = open_output_file(downscale_ctx, downscale_ctx->out_filename[i], i) < 0)
+            return ret;
+    }
+
+    downscale_ctx->tinfo = calloc(num_threads, sizeof(struct thread_info));
+    if (downscale_ctx->tinfo == NULL) {
+        av_log(NULL, AV_LOG_ERROR, "Error while calloc the threadinfo\n");
+        return ret;
+    }
+    // downscale_ctx->thread_ctx = calloc(1, sizeof(ThreadContext));
+    for (i = 0; i < num_threads; i++) {
+        downscale_ctx->stream_ctx->enc_ctx[i]->height = downscale_ctx->filter_ctx->buffersink_ctx[i]->inputs[0]->h;
+        downscale_ctx->stream_ctx->enc_ctx[i]->width  = downscale_ctx->filter_ctx->buffersink_ctx[i]->inputs[0]->w;
+        downscale_ctx->stream_ctx->enc_ctx[i]->sample_aspect_ratio =
+            downscale_ctx->stream_ctx->dec_ctx->sample_aspect_ratio;
+        /* take first format from list of supported formats */
+        downscale_ctx->stream_ctx->enc_ctx[i]->pix_fmt    = AV_PIX_FMT_VASTAPI;
+        downscale_ctx->stream_ctx->enc_ctx[i]->sw_pix_fmt = AV_PIX_FMT_NV12;
+        downscale_ctx->resctx.scaleh[i] =
+            downscale_ctx->stream_ctx->enc_ctx[i]->height * 1.0 / downscale_ctx->resctx.height;
+        downscale_ctx->resctx.scalew[i] =
+            downscale_ctx->stream_ctx->enc_ctx[i]->width * 1.0 / downscale_ctx->resctx.width;
+        if (downscale_ctx->resctx.scaleh[i] > 1) {
+            fprintf(stdout, "[vastapi_downscale, pid %d]: scaleh %f. \n", getpid(), downscale_ctx->resctx.scaleh[i]);
+            // return -1;
+        }
+        if (downscale_ctx->resctx.scalew[i] > 1) {
+            fprintf(stdout, "[vastapi_downscale, pid %d]: scalew %f. \n", getpid(), downscale_ctx->resctx.scalew[i]);
+            // return -1;
+        }
+    }
+
+    for (int i = 0; i < num_threads; i++) {
+        downscale_ctx->tinfo[i].thread_num = i;
+        downscale_ctx->tinfo[i].handle     = downscale_ctx;
+        print_localtime();
+        fprintf(stdout,
+                "[vastapi_downscale, pid %d]: create encoder thread %d, output "
+                "resolution %dx%d. \n",
+                getpid(), i, downscale_ctx->stream_ctx->enc_ctx[i]->width,
+                downscale_ctx->stream_ctx->enc_ctx[i]->height);
+        downscale_ctx->thread_ctx->status[i] = ENCODE_STATUS_BEGAIN;
+        ret = pthread_create(&downscale_ctx->tinfo[i].thread_id, NULL, &encode_thread, &downscale_ctx->tinfo[i]);
+        if (ret != 0)
+            return ret;
+    }
+
+    return 0;
+}
+
+void filter_encode_deinit(struct DownscaleCtx *downscale_ctx)
+{
+    int i = 0;
+    if (downscale_ctx->tinfo) {
+        free(downscale_ctx->tinfo);
+        downscale_ctx->tinfo = NULL;
+    }
+
+    if (downscale_ctx->thread_ctx) {
+        free(downscale_ctx->thread_ctx);
+        downscale_ctx->thread_ctx = NULL;
+    }
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        deinit_queue(&downscale_ctx->queue_array[i]);
+    }
+}
+
+static int filter_encode_write_frame(struct DownscaleCtx *downscale_ctx, AVFrame *frame)
+{
+    int      ret;
+    AVFrame *filt_frame;
+    int      i = 0;
+
+    // av_log(NULL, AV_LOG_INFO, "Pushing decoded frame to filters\n");
+    /* push the decoded frame into the filtergraph */
+    ret = av_buffersrc_add_frame_flags(downscale_ctx->filter_ctx->buffersrc_ctx, frame, AV_BUFFERSRC_FLAG_PUSH);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Error while feeding the filtergraph\n");
+        return ret;
+    }
+
+    /* pull filtered frames from the filtergraph */
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        while (1) {
+            filt_frame = av_frame_alloc();
+            if (!filt_frame) {
+                ret = AVERROR(ENOMEM);
+                break;
+            }
+
+            // av_log(NULL, AV_LOG_INFO, "Pulling filtered frame from
+            // filters\n");
+
+            ret = av_buffersink_get_frame_flags(downscale_ctx->filter_ctx->buffersink_ctx[i], filt_frame,
+                                                AV_BUFFERSINK_FLAG_NO_REQUEST);
+            if (ret < 0) {
+                /* if no more frames for output - returns AVERROR(EAGAIN)
+                 * if flushed and no more frames for output - returns
+                 * AVERROR_EOF rewrite retcode to 0 to show it as normal
+                 * procedure completion
+                 */
+                if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+                    ret = 0;
+                av_frame_free(&filt_frame);
+                break;
+            }
+
+            filt_frame->pict_type = AV_PICTURE_TYPE_NONE;
+#ifdef ENABLE_ENCODE
+            queue_add(downscale_ctx->queue_array[i], filt_frame);
+            // downscale_ctx->thread_ctx->status[i] = ENCODE_STATUS_BEGAIN;
+
+            if (downscale_ctx->queue_array[i]->size > 0) {
+                pthread_mutex_lock(&mutex);
+                pthread_cond_signal(&cond);
+                pthread_mutex_unlock(&mutex);
+            }
+            // if(term_status)
+            //     return AVERROR_EOF;
+            while (downscale_ctx->queue_array[i]->size > 6) {
+                pthread_mutex_lock(&mutex);
+                pthread_cond_signal(&cond);
+                pthread_mutex_unlock(&mutex);
+                usleep(30000);
+                if (downscale_ctx->thread_ctx->status[i] == ENCODE_STATUS_EXIT) {
+                    break;
+                }
+            }
+
+#else
+            av_frame_free(&filt_frame);
+#endif
+        }
+    }
+
+    return ret;
+}
+
+static void *encode_thread(void *arg)
+{
+    struct thread_info  *th_info       = arg;
+    int                  thread_num    = th_info->thread_num;
+    struct DownscaleCtx *downscale_ctx = (struct DownscaleCtx *)th_info->handle;
+    int                  ret           = 0;
+    while (1) {
+        if (ret < 0) {
+            term_status                                   = 1;
+            downscale_ctx->thread_ctx->status[thread_num] = ENCODE_STATUS_EXIT;
+            av_log(NULL, AV_LOG_ERROR, "Error: thread %d exit pid: %d \n", thread_num, getpid());
+            pthread_exit(0);
+        } else if (downscale_ctx->thread_ctx->status[thread_num] == ENCODE_STATUS_END)
+            pthread_exit(0);
+        else {
+            ret = encode_write_frame(downscale_ctx, thread_num);
+        }
+    }
+}
+
+static int flush_encoder(struct DownscaleCtx *downscale_ctx)
+{
+    int ret = 0;
+
+    int i = 0;
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        if (!(downscale_ctx->stream_ctx->enc_ctx[i]->codec->capabilities & AV_CODEC_CAP_DELAY))
+            return 0;
+        if (term_status) {
+            return 0;
+        }
+        av_log(NULL, AV_LOG_INFO, "Flushing stream video encoder\n");
+        ret = flush_encode_write_frame(downscale_ctx, NULL, i);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error: Flushing encoder failed\n");
+            return ret;
+        }
+    }
+
+    return ret;
+}
+
+static void reconfig_descr(struct DownscaleCtx *downscale_ctx)
+{
+    int        i = 0;
+    int        width, height;
+    char       filter_descr[100] = "output_size=";
+    char       tmp[100]          = { 0 };
+    char      *cp                = NULL;
+    char      *cpafter           = NULL;
+    static int change_time       = 0;
+    int        outputs           = 0;
+
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        height = downscale_ctx->resctx.scaleh[i] * downscale_ctx->resctx.new_height;
+        width  = downscale_ctx->resctx.scalew[i] * downscale_ctx->resctx.new_width;
+        if (width < 144 || width >= 8192)
+            width = downscale_ctx->resctx.new_width;
+        if (height < 144 || height >= 8192)
+            height = downscale_ctx->resctx.new_height;
+        width                                   = width & ~(16 - 1);
+        height                                  = height & ~(16 - 1);
+        downscale_ctx->resctx.out_new_width[i]  = width;
+        downscale_ctx->resctx.out_new_height[i] = height;
+    }
+
+    cp = strstr(downscale_ctx->filter_descr, "outputs=") + strlen("outputs=");
+    if (cp) {
+        outputs = strtol(cp, &cpafter, 10);
+    }
+    for (i = 0; i < outputs; i++) {
+        sprintf(tmp, "%dx%d+", downscale_ctx->resctx.out_new_width[i], downscale_ctx->resctx.out_new_height[i]);
+        strcat(filter_descr, tmp);
+    }
+
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        if (strcmp(downscale_ctx->out_filename[i], "-")) {
+            cp = strstr(downscale_ctx->out_filename[i], ".hevc");
+            if (!cp)
+                cp = strstr(downscale_ctx->out_filename[i], ".h264");
+            if (!cp)
+                cp = strstr(downscale_ctx->out_filename[i], ".");
+            if (!cp)
+                cp = downscale_ctx->out_filename[i] + strlen(downscale_ctx->out_filename[i]) - 1;
+            strncpy(downscale_ctx->resctx.out_filename[i], downscale_ctx->out_filename[i],
+                    cp - downscale_ctx->out_filename[i]);
+            sprintf(downscale_ctx->resctx.out_filename[i] + (cp - downscale_ctx->out_filename[i]), "_change_%dx%d_%d%s",
+                    downscale_ctx->resctx.out_new_width[i], downscale_ctx->resctx.out_new_height[i], change_time, cp);
+        } else
+            strcpy(downscale_ctx->resctx.out_filename[i], "-");
+    }
+
+    filter_descr[strlen(filter_descr) - 1] = 0;
+
+    cp      = strstr(downscale_ctx->filter_descr, "output_size=");
+    cpafter = strstr(downscale_ctx->filter_descr, "[");
+    strcpy(downscale_ctx->resctx.filter_descr, "");
+    strncpy(downscale_ctx->resctx.filter_descr, downscale_ctx->filter_descr, cp - downscale_ctx->filter_descr);
+    sprintf(downscale_ctx->resctx.filter_descr + (cp - downscale_ctx->filter_descr), "%s", filter_descr);
+    if (cpafter)
+        strcat(downscale_ctx->resctx.filter_descr, cpafter);
+    strcpy(downscale_ctx->filter_descr, downscale_ctx->resctx.filter_descr);
+    print_localtime();
+    fprintf(stdout, "[vastapi_downscale, pid %d]: resolution changed. \n", getpid());
+    printf("new resolution filter_descr %s\n", downscale_ctx->resctx.filter_descr);
+    printf("input width height %dx%d\n", downscale_ctx->resctx.new_width, downscale_ctx->resctx.new_height);
+
+    change_time++;
+}
+
+static int reset_filter_encoder(struct DownscaleCtx *downscale_ctx)
+{
+    int i = 0;
+
+    int ret = 0;
+
+    ret = filter_encode_write_frame(downscale_ctx, NULL);
+    if (ret) {
+        if (!term_status)
+            av_log(NULL, AV_LOG_ERROR, "filter_encode_write_frame \n");
+        return ret;
+    }
+
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        while (downscale_ctx->queue_array[i]->size != 0) {
+            pthread_mutex_lock(&mutex);
+            pthread_cond_signal(&cond);
+            pthread_mutex_unlock(&mutex);
+            if (term_status)
+                break;
+        }
+        usleep(10000);
+        downscale_ctx->thread_ctx->status[i] = ENCODE_STATUS_END;
+    }
+
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        pthread_cond_broadcast(&cond);
+        pthread_join(downscale_ctx->tinfo[i].thread_id, NULL);
+    }
+
+    flush_encoder(downscale_ctx);
+
+    // for(j = 0; j < downscale_ctx->ifmt_ctx->nb_streams; j++)
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        if (downscale_ctx->stream_ctx->enc_ctx[i]) {
+            avcodec_free_context(&downscale_ctx->stream_ctx->enc_ctx[i]);
+        }
+    }
+    if (downscale_ctx->filter_ctx->filter_graph) {
+        avfilter_graph_free(&downscale_ctx->filter_ctx->filter_graph);
+    }
+
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        if (downscale_ctx->ofmt_ctx[i] && !(downscale_ctx->ofmt_ctx[i]->oformat->flags & AVFMT_NOFILE))
+            avio_closep(&downscale_ctx->ofmt_ctx[i]->pb);
+        avformat_free_context(downscale_ctx->ofmt_ctx[i]);
+        downscale_ctx->ofmt_ctx[i] = NULL;
+    }
+
+    reconfig_descr(downscale_ctx);
+    initialized = 0;
+
+    // for(j = 0; j < downscale_ctx->ifmt_ctx->nb_streams; j++)
+    ret = init_filter(downscale_ctx->filter_ctx, downscale_ctx->stream_ctx->dec_ctx, NULL,
+                      downscale_ctx->resctx.filter_descr, downscale_ctx->thread_num);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Error configuring the filter graph\n");
+        return ret;
+    }
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        if (ret = open_output_file(downscale_ctx, downscale_ctx->resctx.out_filename[i], i) < 0)
+            return ret;
+    }
+
+    for (int i = 0; i < downscale_ctx->thread_num; i++) {
+        downscale_ctx->tinfo[i].thread_num   = i;
+        downscale_ctx->tinfo[i].handle       = downscale_ctx;
+        downscale_ctx->thread_ctx->status[i] = ENCODE_STATUS_BEGAIN;
+        ret = pthread_create(&downscale_ctx->tinfo[i].thread_id, NULL, &encode_thread, &downscale_ctx->tinfo[i]);
+        if (ret != 0)
+            return ret;
+    }
+    initialized = 1;
+
+    return 0;
+}
+
+struct InputParameters {
+    char  *filename;
+    char  *outfile_list;
+    char  *render;
+    double out_fps;
+    char  *bitrate_str;
+    int    enable_wavefilter;
+    char  *vast_params;
+    char  *filter_descr;
+    char  *encoder_name;
+};
+
+static int downscale_open(void **handle, struct InputParameters *input_params)
+{
+    int                  ret = 0;
+    int                  i = 0, j = 0;
+    char                *comma         = NULL;
+    struct DownscaleCtx *downscale_ctx = NULL;
+    char                *cp            = NULL;
+    // int device_id = 0;
+    print_localtime();
+    fprintf(stdout, "[vastapi_downscale, pid %d]: open. \n", getpid());
+    signal(SIGINT, sigterm_handler);  /* Interrupt (ANSI).    */
+    signal(SIGTERM, sigterm_handler); /* Termination (ANSI).  */
+
+    downscale_ctx = (struct DownscaleCtx *)malloc(sizeof(struct DownscaleCtx));
+    if (!downscale_ctx) {
+        fprintf(stderr, "downscale_ctx malloc failed. \n");
+        exit(-1);
+    }
+    memset(downscale_ctx, 0, sizeof(struct DownscaleCtx));
+    *handle                   = downscale_ctx;
+    downscale_ctx->frame_rate = av_d2q(input_params->out_fps, 4096);
+    // downscale_ctx->thread_num = input_params->thread_num;
+    strcpy(downscale_ctx->render, input_params->render);
+    strcpy(downscale_ctx->filename, input_params->filename);
+
+    i = 0, j = 0;
+    while (comma = strstr(&input_params->encoder_name[i], ",")) {
+        strncpy(downscale_ctx->encoder_name[j], &input_params->encoder_name[i], comma - &input_params->encoder_name[i]);
+        i += (comma - &input_params->encoder_name[i] + 1);
+        j++;
+    }
+    strcpy(downscale_ctx->encoder_name[j], &input_params->encoder_name[i]);
+
+    i = 0, j = 0;
+    while (comma = strstr(&input_params->outfile_list[i], ",")) {
+        strncpy(downscale_ctx->out_filename[j], &input_params->outfile_list[i], comma - &input_params->outfile_list[i]);
+        i += (comma - &input_params->outfile_list[i] + 1);
+        j++;
+    }
+    strcpy(downscale_ctx->out_filename[j], &input_params->outfile_list[i]);
+    downscale_ctx->thread_num = j + 1;
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        printf("out filename %s  \n", downscale_ctx->out_filename[i]);
+    }
+    if (downscale_ctx->thread_num > MAX_CHANNEL ||
+        (downscale_ctx->thread_num != 1 && downscale_ctx->thread_num != 2 && downscale_ctx->thread_num != 4 &&
+         downscale_ctx->thread_num != 5 && downscale_ctx->thread_num != 8
+
+         )) {
+        fprintf(stderr, "unsupported output count :%d\n", downscale_ctx->thread_num);
+    }
+
+    strcpy(downscale_ctx->filter_descr, input_params->filter_descr);
+    i = 0, j = 0;
+    while (comma = strstr(&input_params->vast_params[i], ",")) {
+        strncpy(downscale_ctx->vast_params[j], &input_params->vast_params[i], comma - &input_params->vast_params[i]);
+        i += (comma - &input_params->vast_params[i] + 1);
+        j++;
+    }
+    strcpy(downscale_ctx->vast_params[j], &input_params->vast_params[i]);
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        printf("vast_params name %s  \n", downscale_ctx->vast_params[i]);
+    }
+    cp = input_params->bitrate_str;
+    i = 0, j = 0;
+    while (cp && *cp != 0) {
+        if (*cp == ',') {
+            downscale_ctx->bitrate[j++] = i;
+            i                           = 0;
+            cp++;
+        }
+        i = i * 10 + (*cp - '0');
+        cp++;
+    }
+    downscale_ctx->bitrate[j] = i;
+    downscale_ctx->thread_ctx = (struct ThreadContext *)malloc(sizeof(struct ThreadContext));
+    if (!downscale_ctx->thread_ctx) {
+        fprintf(stderr, "downscale_ctx->ThreadContext malloc failed. \n");
+        exit(-1);
+    }
+
+    downscale_ctx->queue_array = (struct queue_root **)malloc(sizeof(struct queue_root *) * downscale_ctx->thread_num);
+    if (!downscale_ctx->queue_array) {
+        fprintf(stderr, "downscale_ctx->ThreadContext malloc failed. \n");
+        exit(-1);
+    }
+    memset(downscale_ctx->queue_array, 0, sizeof(struct queue_root *));
+
+    // downscale_ctx->filter_ctx =
+    //     (struct FilteringContext *)malloc(sizeof(struct FilteringContext));
+    // if (!downscale_ctx->filter_ctx) {
+    //     fprintf(stderr, "downscale_ctx->filter_ctx malloc failed. \n");
+    //     exit(-1);
+    // }
+
+    downscale_ctx->ofmt_ctx = (AVFormatContext **)malloc(sizeof(AVFormatContext *) * downscale_ctx->thread_num);
+    if (!downscale_ctx->ofmt_ctx) {
+        fprintf(stderr, "downscale_ctx->ofmt_ctx malloc failed. \n");
+        exit(-1);
+    }
+    memset(downscale_ctx->ofmt_ctx, 0, sizeof(AVFormatContext *) * downscale_ctx->thread_num);
+    if ((ret = open_input_file(downscale_ctx)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static void downscale_close(void *handle)
+{
+    struct DownscaleCtx *downscale_ctx = (struct DownscaleCtx *)handle;
+    int                  i             = 0;
+    // for(j = 0; j < downscale_ctx->ifmt_ctx->nb_streams; j++)
+    avcodec_free_context(&downscale_ctx->stream_ctx->dec_ctx);
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        av_packet_free(&downscale_ctx->filter_ctx->enc_pkt[i]);
+        if (downscale_ctx->ofmt_ctx[i] && downscale_ctx->ofmt_ctx[i]->streams && downscale_ctx->stream_ctx->enc_ctx[i])
+            avcodec_free_context(&downscale_ctx->stream_ctx->enc_ctx[i]);
+    }
+    if (downscale_ctx->filter_ctx && downscale_ctx->filter_ctx->filter_graph) {
+        avfilter_graph_free(&downscale_ctx->filter_ctx->filter_graph);
+    }
+    av_frame_free(&downscale_ctx->stream_ctx->dec_frame);
+
+    av_free(downscale_ctx->stream_ctx);
+    avformat_close_input(&downscale_ctx->ifmt_ctx);
+    for (i = 0; i < downscale_ctx->thread_num; i++) {
+        if (downscale_ctx->ofmt_ctx[i] && !(downscale_ctx->ofmt_ctx[i]->oformat->flags & AVFMT_NOFILE))
+            avio_closep(&downscale_ctx->ofmt_ctx[i]->pb);
+        avformat_free_context(downscale_ctx->ofmt_ctx[i]);
+        if (downscale_ctx->queue_array[i])
+            free(downscale_ctx->queue_array[i]);
+    }
+
+    if (downscale_ctx->filter_ctx) {
+        free(downscale_ctx->filter_ctx);
+        downscale_ctx->filter_ctx = NULL;
+    }
+
+    if (downscale_ctx->ofmt_ctx) {
+        free(downscale_ctx->ofmt_ctx);
+        downscale_ctx->ofmt_ctx = NULL;
+    }
+
+    if (downscale_ctx->thread_ctx) {
+        free(downscale_ctx->thread_ctx);
+        downscale_ctx->thread_ctx = NULL;
+    }
+
+    if (downscale_ctx->queue_array) {
+        free(downscale_ctx->queue_array);
+        downscale_ctx->queue_array = NULL;
+    }
+    av_dict_free(&opts);
+
+    av_buffer_unref(&downscale_ctx->hw_device_ctx);
+
+    if (downscale_ctx) {
+        free(downscale_ctx);
+    }
+    // vastsdk_deinit();
+    print_localtime();
+    fprintf(stdout, "[vastapi_downscale, pid %d]: close. \n", getpid());
+}
+
+static int flush_decoder(struct DownscaleCtx *downscale_ctx)
+{
+    int      ret;
+    AVFrame *frame;
+    AVPacket packet = { .data = NULL, .size = 0 };
+    ret             = avcodec_send_packet(downscale_ctx->stream_ctx->dec_ctx, &packet);
+    if (ret < 0) {
+        fprintf(stderr, "Error during decoding. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+    while (ret >= 0) {
+        if (!(frame = av_frame_alloc()))
+            return AVERROR(ENOMEM);
+
+        ret = avcodec_receive_frame(downscale_ctx->stream_ctx->dec_ctx, frame);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            av_frame_free(&frame);
+            break;
+        } else if (ret < 0) {
+            fprintf(stderr, "Error while decoding. Error code: %s\n", av_err2str(ret));
+            goto fail;
+        }
+
+        ret = av_hwframe_sync_surface(frame);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error flush_decoder av_hwframe_sync_surface ret %d \n", ret);
+            goto fail;
+        }
+
+        ret = filter_encode_write_frame(downscale_ctx, frame);
+        if (ret) {
+            if (!term_status)
+                av_log(NULL, AV_LOG_ERROR, "filter_encode_write_frame \n");
+            goto fail;
+        }
+
+    fail:
+        av_frame_free(&frame);
+        if (ret < 0)
+            return ret;
+    }
+    return ret;
+}
+
+static int downscale_process(void *handle)
+{
+    int ret;
+    // AVPacket packet = {.data = NULL, .size = 0};
+    AVPacket *packet = NULL;
+    AVFrame  *frame  = NULL;
+    // enum AVMediaType type;
+    unsigned int         stream_index;
+    unsigned int         i             = 0;
+    struct DownscaleCtx *downscale_ctx = (struct DownscaleCtx *)handle;
+    AVFormatContext     *ifmt_ctx      = downscale_ctx->ifmt_ctx;
+    StreamContext       *stream_ctx    = downscale_ctx->stream_ctx;
+    int                  thread_num    = downscale_ctx->thread_num;
+    // int frame_num = 0;
+    av_log_set_level(AV_LOG_ERROR);
+    frame = stream_ctx->dec_frame;
+
+    print_localtime();
+    fprintf(stdout, "[vastapi_downscale, pid %d]: process. \n", getpid());
+    if (!(packet = av_packet_alloc()))
+        goto end;
+    /* read all packets */
+    while (!term_status) {
+        if ((ret = av_read_frame(ifmt_ctx, packet)) < 0) {
+            break;
+        }
+
+        // type = ifmt_ctx->streams[packet->stream_index]->codecpar->codec_type;
+        // if (AVMEDIA_TYPE_VIDEO != type)
+        if (downscale_ctx->stream_index != packet->stream_index) {
+            av_packet_unref(packet);
+            continue;
+        }
+
+        stream_index = downscale_ctx->stream_index;
+        av_log(NULL, AV_LOG_DEBUG, "Demuxer gave frame of stream_index %u\n", stream_index);
+
+        av_log(NULL, AV_LOG_DEBUG, "Going to reencode&filter the frame\n");
+        // frame = av_frame_alloc();
+        // if (!frame) {
+        //     ret = AVERROR(ENOMEM);
+        //     break;
+        // }
+        if (packet->dts != AV_NOPTS_VALUE)
+            packet->dts +=
+                av_rescale_q(stream_ctx->ts_offset, AV_TIME_BASE_Q, ifmt_ctx->streams[stream_index]->time_base);
+        if (packet->pts != AV_NOPTS_VALUE)
+            packet->pts +=
+                av_rescale_q(stream_ctx->ts_offset, AV_TIME_BASE_Q, ifmt_ctx->streams[stream_index]->time_base);
+
+        av_packet_rescale_ts(packet, ifmt_ctx->streams[stream_index]->time_base, stream_ctx->dec_ctx->time_base);
+
+        ret = avcodec_send_packet(stream_ctx->dec_ctx, packet);
+        if (ret < 0) {
+            fprintf(stderr, "Error during decoding. Error code: %s\n", av_err2str(ret));
+            goto end;
+        }
+        while (1) {
+
+            ret = avcodec_receive_frame(stream_ctx->dec_ctx, frame);
+            if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+                // av_frame_free(&frame);
+                break;
+            } else if (ret < 0) {
+                fprintf(stderr, "Error while decoding\n");
+                if (initialized)
+                    goto end;
+            }
+            ret = av_hwframe_sync_surface(frame);
+            if (ret < 0) {
+                av_log(NULL, AV_LOG_ERROR, "Error av_hwframe_sync_surface ret %d \n", ret);
+                if (initialized)
+                    goto end;
+            }
+
+            frame->pts = frame->best_effort_timestamp;
+            if (!initialized) {
+                ret = filter_encode_init(downscale_ctx, stream_index);
+                if (ret) {
+                    av_log(NULL, AV_LOG_ERROR, "Error filter_encode_init ret %d \n", ret);
+                    goto end;
+                }
+                initialized = 1;
+            }
+            if (frame->width != downscale_ctx->resctx.new_width || frame->height != downscale_ctx->resctx.new_height) {
+                downscale_ctx->resctx.new_width  = frame->width;
+                downscale_ctx->resctx.new_height = frame->height;
+                if (ret = reset_filter_encoder(downscale_ctx) < 0)
+                    goto end;
+                av_log(NULL, AV_LOG_INFO, "change resolution to %dx%d\n", downscale_ctx->resctx.new_width,
+                       downscale_ctx->resctx.new_height);
+            }
+
+            // av_log(NULL, AV_LOG_INFO, "decoded frame  %u \n", frame_num++);
+            // fprintf(stdout,  "decoded frame  %u \n", frame_num++);
+
+            ret = filter_encode_write_frame(downscale_ctx, frame);
+            if (ret) {
+                if (!term_status)
+                    av_log(NULL, AV_LOG_ERROR, "filter_encode_write_frame \n");
+                goto end;
+            }
+
+            // av_frame_unref(frame);
+            if (ret < 0)
+                goto end;
+            break;
+        }
+
+        // av_frame_free(&frame);
+        av_packet_unref(packet);
+    }
+
+end:
+    /* flush decoder */
+    if (initialized) {
+        for (i = 0; i < thread_num; i++) {
+            while (downscale_ctx->queue_array[i]->size != 0) {
+                pthread_mutex_lock(&mutex);
+                pthread_cond_signal(&cond);
+                pthread_mutex_unlock(&mutex);
+                if (term_status)
+                    break;
+            }
+        }
+    }
+
+    if (ret == AVERROR_EOF)
+        flush_decoder(downscale_ctx);
+    if (initialized) {
+        for (i = 0; i < thread_num; i++) {
+            while (downscale_ctx->queue_array[i]->size != 0) {
+                pthread_mutex_lock(&mutex);
+                pthread_cond_signal(&cond);
+                pthread_mutex_unlock(&mutex);
+                if (term_status)
+                    break;
+            }
+            pthread_cond_broadcast(&cond);
+            downscale_ctx->thread_ctx->status[i] = ENCODE_STATUS_END;
+            usleep(5000);
+        }
+    }
+
+    if (initialized) {
+        for (i = 0; i < thread_num; i++) {
+            pthread_cond_broadcast(&cond);
+            pthread_join(downscale_ctx->tinfo[i].thread_id, NULL);
+        }
+
+        /* flush filters and encoders */
+        /* flush encoder */
+        if (ret == AVERROR_EOF) {
+            ret = flush_encoder(downscale_ctx);
+            if (ret < 0) {
+                av_log(NULL, AV_LOG_ERROR, "Flushing encoder failed\n");
+            }
+        }
+
+        for (i = 0; i < thread_num; i++) {
+            av_write_trailer(downscale_ctx->ofmt_ctx[i]);
+        }
+
+        filter_encode_deinit(downscale_ctx);
+    }
+
+    av_packet_free(&packet);
+    if (ret < 0)
+        av_log(NULL, AV_LOG_ERROR, "Error occurred: %s\n", av_err2str(ret));
+    return ret;
+}
+
+static void usage(const char *program)
+{
+    fprintf(stderr, "Usage: %s [options]\n", program);
+    fprintf(stderr, "\n");
+    fprintf(stderr, "  -e    render node\n");
+    fprintf(stderr, "  -i    input video file path\n");
+    fprintf(stderr, "  -o    output count\n");
+    fprintf(stderr, "  -r    set output frame rate \n");
+    fprintf(stderr, "  -b    set encode bitrate \n");
+    fprintf(stderr, "  -v    vast-params \n");
+    fprintf(stderr, "  -c    encoder name \n");
+    fprintf(stderr, "  -f    set filter description \n");
+}
+
+static int parse_options(int argc, char **argv, struct InputParameters *input_params)
+{
+    static const char optstr[] = "i:o:e:r:b:c:f:v:";
+    int               c;
+
+    while ((c = getopt(argc, argv, optstr)) != -1) {
+        switch (c) {
+        case 'e':
+            input_params->render = optarg;
+            break;
+        case 'i':
+            input_params->filename = optarg;
+            break;
+        case 'o':
+            input_params->outfile_list = optarg;
+            break;
+        case 'r':
+            input_params->out_fps = atof(optarg);
+            break;
+        case 'b':
+            input_params->bitrate_str = optarg;
+            break;
+        case 'c':
+            input_params->encoder_name = optarg;
+            break;
+        case 'v':
+            input_params->vast_params = optarg;
+            break;
+        case 'f':
+            input_params->filter_descr = optarg;
+            break;
+        case '?':
+        default:
+            fprintf(stderr, "  unsupported option %c \n", c);
+            usage(argv[0]);
+            return -1;
+        }
+    }
+    if (!input_params->filter_descr) {
+        fprintf(stderr, "please set filter description use -f option \n");
+        return -1;
+    }
+    if (optind < argc) {
+        usage(argv[0]);
+        return -1;
+    }
+
+    return 0;
+}
+
+int main(int argc, char **argv)
+{
+    int                    ret;
+    void                  *handle;
+    struct InputParameters input_params = { 0 };
+
+    if (ret = parse_options(argc, argv, &input_params) < 0) {
+        fprintf(stderr, "parse_options failed pid %d. \n", getpid());
+        return ret;
+    }
+
+    if (ret = downscale_open(&handle, &input_params) < 0) {
+        fprintf(stderr, "downscale_open failed pid %d. \n", getpid());
+        return ret;
+    }
+
+    if (ret = downscale_process(handle) < 0) {
+        fprintf(stderr, "downscale_process failed pid %d. \n", getpid());
+    }
+
+    downscale_close(handle);
+
+    return ret ? 1 : 0;
+}
diff --git a/doc/examples/vastapi_transcode.c b/doc/examples/vastapi_transcode.c
new file mode 100644
index 0000000..0005056
--- /dev/null
+++ b/doc/examples/vastapi_transcode.c
@@ -0,0 +1,1727 @@
+#define CONFIG_VASTAPI 1
+#include <stdio.h>
+#include <errno.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <pthread.h>
+#include <unistd.h>
+#include <string.h>
+#include <semaphore.h>
+#include <getopt.h>
+#include <sys/time.h>
+#include "libavutil/hwcontext.h"
+#include "libavcodec/avcodec.h"
+#include "libavformat/avformat.h"
+#include "libavutil/opt.h"
+
+#define DYNAMIC_FRAMERATE_TEST
+#define DYNAMIC_BITRATE_TEST
+#define INSERTIDR_TEST
+#define SEI_TEST
+#define ROIMAP_TEST
+#define DYNAMIC_CRF_TEST
+// #define VASTAI_AVFRAME_TEST
+// #define EXTERNA_BUFFER_ENCODE_TEST
+// #define DMABUFFER_FD_ENCODE_TEST
+// #define DUMP_YUV_WITH_PADDING
+// #define USER_GET_PSNR_TEST
+
+/*系统声明的全局变量 */
+extern char *optarg;
+extern int   optind, opterr, optopt;
+
+#define MAX_STR_LEN 1024  // string len
+#define MAX_QUEUE_LEN 20  // queue len
+#define MAX_THREAD_NUM 32 // thread num
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+#define EXTERNAL_BUFFER_START_ADDR 0x900000000 /*Reserved for sv 100 GPU ddr addr*/
+#endif
+
+#ifdef VASTAI_AVFRAME_TEST
+#define DMA_BUFFER_NUM_MAX 4
+#endif
+
+#ifdef DMABUFFER_FD_ENCODE_TEST
+#define INPUT_TYPE_FD 0
+#define INPUT_TYPE_ADDR 1
+#endif
+
+static AVFormatContext *ifmt_ctx[MAX_THREAD_NUM] = { NULL }, *ofmt_ctx[MAX_THREAD_NUM] = { NULL };
+static AVBufferRef     *hw_device_ctx               = NULL;
+static AVCodecContext  *decoder_ctx[MAX_THREAD_NUM] = { NULL }, *encoder_ctx[MAX_THREAD_NUM] = { NULL };
+static int              video_stream[MAX_THREAD_NUM] = { 0 };
+static AVStream        *ist[MAX_THREAD_NUM]          = { NULL };
+static AVStream        *ost[MAX_THREAD_NUM]          = { NULL };
+static long             cnt[MAX_THREAD_NUM] = { 0 }, enc_frame_cnt[MAX_THREAD_NUM] = { 0 };
+struct Queue           *queue_g[MAX_THREAD_NUM]        = { NULL };
+static int              frame_cnt[MAX_THREAD_NUM]      = { 0 };
+static long             frame_pts[MAX_THREAD_NUM]      = { 0 };
+static int              thread_end[MAX_THREAD_NUM]     = { 0 };
+static int              loop[MAX_THREAD_NUM]           = { 0 };
+static int64_t          start_duration[MAX_THREAD_NUM] = { 0 };
+
+#ifdef SEI_TEST
+#define SEI_COUNT 2
+#define SEI_BUFFER_SIZE 28
+static const uint8_t encode_h264_sei_appdata_uuid[2][16] = {
+    { 0x9e, 0x03, 0xef, 0xfd, 0x23, 0x95, 0x41, 0x01, 0xb6, 0xc2, 0x0c, 0x02, 0xbb, 0x0d, 0xa8, 0xae },
+    { 0x9f, 0x03, 0xef, 0xfd, 0x23, 0x95, 0x41, 0x01, 0xb6, 0xc2, 0x0c, 0x02, 0xbb, 0x0d, 0xa8, 0xae }
+};
+#endif
+
+typedef struct option_t {
+    char      *input;
+    char      *output;
+    char      *output_file;
+    char      *render;
+    double     fps;
+    AVRational frame_rate;
+    int        bitrate;
+    char      *vast_params;
+    char      *video_size;
+    char      *pixel_format;
+    char      *encoder;
+    char      *profile;
+    double     level;
+    int        thread_num;
+    int        frame_cnt;
+    int        loop;
+    int        save;
+    double     vfr_fps;
+
+    int enable_roi;
+    int enable_sei;
+    int enable_idr;
+    int enable_dynamic_bitrate;
+    int enable_dynamic_fps;
+    int enable_dynamic_crf;
+    int enable_dynamic_keyint;
+} option_t;
+
+struct thread_info {
+    pthread_t thread_id;  /* ID returned by pthread_create() */
+    int       thread_chn; /* Application-defined thread id # */
+    void     *handle;
+};
+
+typedef struct {
+    void        *data;
+    struct Node *next;
+} Node;
+
+typedef struct {
+    Node           *front; // head
+    Node           *rear;  // tail
+    int             len;
+    int             max_len;
+    pthread_mutex_t q_lock;
+    pthread_cond_t  not_empty;
+    pthread_cond_t  not_full;
+} Queue;
+
+typedef struct Usrdata {
+    int      chn;
+    int      cnt;
+    char     endflg;
+    AVFrame *frame;
+    AVFrame *hw_frame_dec;
+} Usrdata;
+
+static void *init_queue(void)
+{
+    Queue *queue = (Queue *)malloc(sizeof(Queue));
+    if (!queue) {
+        printf("not enough mem\n");
+        exit(1);
+    }
+
+    queue->rear = queue->front = (Node *)malloc(sizeof(Node));
+    queue->front->next         = NULL;
+    queue->len                 = 0;
+    queue->max_len             = MAX_QUEUE_LEN;
+
+    pthread_mutex_init(&queue->q_lock, NULL);
+    pthread_cond_init(&queue->not_empty, NULL);
+    pthread_cond_init(&queue->not_full, NULL);
+
+    return queue;
+}
+
+static void en_queue(Queue *q, void *data, size_t len)
+{
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == MAX_QUEUE_LEN) {
+        // printf("en queue is full\n");
+        pthread_cond_wait(&q->not_full, &q->q_lock);
+    }
+
+    Node *newnode = (Node *)malloc(sizeof(Node));
+    newnode->data = malloc(len);
+    memcpy(newnode->data, data, len);
+    newnode->next = NULL;
+
+    q->rear->next = (void *)newnode;
+    q->rear       = newnode;
+    q->len        = q->len + 1;
+
+    pthread_cond_signal(&q->not_empty);
+    pthread_mutex_unlock(&q->q_lock);
+}
+
+static void de_queue(Queue *q)
+{
+    Node *newnode;
+
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == 0) {
+        // printf("de queue is empty\n");
+        pthread_cond_wait(&q->not_empty, &q->q_lock);
+    }
+
+    newnode        = (void *)q->front->next;
+    q->front->next = newnode->next;
+
+    if (q->rear == newnode)
+        q->rear = q->front;
+
+    free(newnode->data);
+    free(newnode);
+
+    q->len = q->len - 1;
+
+    pthread_cond_signal(&q->not_full);
+    pthread_mutex_unlock(&q->q_lock);
+    return;
+}
+
+static void *read_queue(Queue *q)
+{
+    Node *read_node;
+
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == 0) {
+        // printf("read queue is empty\n");
+        pthread_cond_wait(&q->not_empty, &q->q_lock);
+    }
+
+    read_node = (void *)q->front->next;
+    if (read_node == NULL) {
+        printf("q->front->next is empty\n");
+        return NULL;
+    }
+
+    pthread_cond_signal(&q->not_empty);
+    pthread_mutex_unlock(&q->q_lock);
+    return read_node->data;
+}
+
+static int is_empty(Queue *q)
+{
+    return (q->len == 0);
+}
+
+static int destroy_queue(Queue *q)
+{
+    while (q->front) {
+        q->rear = (void *)q->front->next;
+        free(q->front);
+        q->front = q->rear;
+    }
+
+    return 0;
+}
+
+// 获取formart
+static enum AVPixelFormat get_vastapi_format(AVCodecContext *ctx, const enum AVPixelFormat *pix_fmts)
+{
+    const enum AVPixelFormat *p;
+    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
+        if (*p == AV_PIX_FMT_VASTAPI)
+            return *p;
+    }
+
+    fprintf(stderr, "Unable to decode this file using VASTAPI.\n");
+    return AV_PIX_FMT_NONE;
+}
+
+static int set_hwframe_ctx(AVCodecContext *ctx, AVBufferRef *hw_device_ctx, struct option_t *input_params, int flag)
+{
+    AVBufferRef       *hw_frames_ref = NULL;
+    AVHWFramesContext *frames_ctx    = NULL;
+    int                ret           = 0;
+
+    if (!(hw_frames_ref = av_hwframe_ctx_alloc(hw_device_ctx))) {
+        fprintf(stderr, "Failed to create VASTAPI frame context.\n");
+        return -1;
+    }
+
+    frames_ctx = (AVHWFramesContext *)(hw_frames_ref->data);
+
+    if (strcmp(input_params->pixel_format, "yuv420p") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_YUV420P;
+    else if (strcmp(input_params->pixel_format, "nv12") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_NV12;
+    else if (strcmp(input_params->pixel_format, "nv21") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_NV21;
+    else if (strcmp(input_params->pixel_format, "rgb0") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_RGB0;
+    else if (strcmp(input_params->pixel_format, "yuv420p10le") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_YUV420P10LE;
+    else
+        frames_ctx->sw_format = AV_PIX_FMT_NONE;
+
+    frames_ctx->format            = AV_PIX_FMT_VASTAPI;
+    frames_ctx->width             = ctx->width;
+    frames_ctx->height            = ctx->height;
+    frames_ctx->initial_pool_size = 32;
+    frames_ctx->frame_buffer_flag = flag;
+
+    if ((ret = av_hwframe_ctx_init(hw_frames_ref)) < 0) {
+        fprintf(stderr, "Failed to initialize VASTAPI frame context. Error code: %s\n", av_err2str(ret));
+        av_buffer_unref(&hw_frames_ref);
+        return ret;
+    }
+
+    ctx->hw_frames_ctx = av_buffer_ref(hw_frames_ref);
+    if (!ctx->hw_frames_ctx)
+        ret = AVERROR(ENOMEM);
+
+    av_buffer_unref(&hw_frames_ref);
+    return ret;
+}
+
+static int decode_init(int chan, struct option_t *input_params)
+{
+    int           ret = 0, rawyuv = 0;
+    AVCodec      *decoder     = NULL;
+    AVStream     *video       = NULL;
+    AVDictionary *format_opts = NULL;
+    char         *fiename_in  = input_params->input;
+
+    rawyuv = strstr(fiename_in, ".yuv") || strstr(fiename_in, ".rgb");
+    if (rawyuv) {
+        av_dict_set(&format_opts, "video_size", input_params->video_size, 0);
+        av_dict_set(&format_opts, "pixel_format", input_params->pixel_format, 0);
+
+        if ((ret = avformat_open_input(&ifmt_ctx[chan], fiename_in, NULL, &format_opts)) < 0) {
+            fprintf(stderr, "Cannot open input file '%s', Error code: %s\n", fiename_in, av_err2str(ret));
+            goto fail;
+        }
+    } else {
+        if ((ret = avformat_open_input(&ifmt_ctx[chan], fiename_in, NULL, NULL)) < 0) {
+            fprintf(stderr, "Cannot open input file %s, Error code: %s\n", fiename_in, av_err2str(ret));
+            goto fail;
+        }
+    }
+
+    if ((ret = avformat_find_stream_info(ifmt_ctx[chan], NULL)) < 0) {
+        fprintf(stderr, "Cannot find input stream information. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+    if ((ret = av_find_best_stream(ifmt_ctx[chan], AVMEDIA_TYPE_VIDEO, -1, -1, &decoder, 0)) < 0) {
+        fprintf(stderr, "Cannot find a video stream in the input file. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+    video_stream[chan] = ret;
+
+#ifndef FFMPEG_N26
+    if (!(decoder_ctx[chan] = avcodec_alloc_context3(decoder))) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+#endif
+
+    video     = ifmt_ctx[chan]->streams[video_stream[chan]];
+    ist[chan] = video;
+
+#ifdef FFMPEG_N26
+    decoder_ctx[chan] = video->codec;
+    av_opt_set_int(decoder_ctx[chan], "refcounted_frames", 1, 0);
+#else
+    if ((ret = avcodec_parameters_to_context(decoder_ctx[chan], video->codecpar)) < 0) {
+        fprintf(stderr, "avcodec_parameters_to_context error. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+#endif
+
+    ret = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_VASTAPI, input_params->render, NULL, 0);
+    if (ret < 0) {
+        fprintf(stderr, "Failed to create a VASTAPI device. Error code: %s\n", av_err2str(ret));
+        return -1;
+    }
+
+    if (!(decoder_ctx[chan]->hw_device_ctx = av_buffer_ref(hw_device_ctx))) {
+        fprintf(stderr, "A hardware device reference create failed.\n");
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    decoder_ctx[chan]->get_format = get_vastapi_format;
+    decoder_ctx[chan]->framerate  = av_guess_frame_rate(ifmt_ctx[chan], video, NULL);
+
+    if ((ret = avcodec_open2(decoder_ctx[chan], decoder, NULL)) < 0) {
+        fprintf(stderr, "Failed to open codec for decoding. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+#ifdef DMABUFFER_FD_ENCODE_TEST
+    set_hwframe_ctx(decoder_ctx[chan], hw_device_ctx, input_params, 2);
+#elif defined EXTERNA_BUFFER_ENCODE_TEST
+    set_hwframe_ctx(decoder_ctx[chan], hw_device_ctx, input_params, 1);
+#else
+    set_hwframe_ctx(decoder_ctx[chan], hw_device_ctx, input_params, 0);
+#endif
+
+    return 0;
+
+fail:
+    if (decoder_ctx[chan]) {
+#ifdef FFMPEG_N26
+        avcodec_close(decoder_ctx[chan]);
+#else
+        avcodec_free_context(&decoder_ctx[chan]);
+#endif
+        decoder_ctx[chan] = NULL;
+    }
+
+    if (ifmt_ctx[chan])
+        avformat_close_input(&ifmt_ctx[chan]);
+
+    return ret;
+}
+
+static int set_user_profile(int *profile, char **cmd_profile, char *encoder_name)
+{
+    if (*cmd_profile == NULL) {
+        return 0;
+    }
+
+    if (strcmp(encoder_name, "h264_vastapi") == 0) {
+        if (strcmp(*cmd_profile, "main") == 0) {
+            *profile = FF_PROFILE_H264_MAIN;
+        } else if (strcmp(*cmd_profile, "baseline") == 0) {
+            *profile = FF_PROFILE_H264_CONSTRAINED_BASELINE;
+        } else if (strcmp(*cmd_profile, "high") == 0) {
+            *profile = FF_PROFILE_H264_HIGH;
+        } else if (strcmp(*cmd_profile, "high10") == 0) {
+            *profile = FF_PROFILE_H264_HIGH_10;
+        }
+    } else if (strcmp(encoder_name, "hevc_vastapi") == 0) {
+        if (strcmp(*cmd_profile, "main") == 0) {
+            *profile = FF_PROFILE_HEVC_MAIN;
+        } else if (strcmp(*cmd_profile, "main10") == 0) {
+            *profile = FF_PROFILE_HEVC_MAIN_10;
+        }
+        printf("hevc_vastapi profile only can set main\n");
+    } else if (strcmp(encoder_name, "av1_vastapi") == 0) {
+        if (strcmp(*cmd_profile, "main") == 0) {
+            *profile = FF_PROFILE_AV1_MAIN;
+        }
+        printf("av1_vastapi profile only can set main\n");
+    } else {
+        printf("warnning: encoder set error!\n");
+    }
+
+    return 0;
+}
+
+static int encode_init(int chan, struct option_t *input_params)
+{
+    int      ret                             = 0;
+    AVCodec *enc_codec                       = NULL;
+    char    *cp                              = NULL;
+    char    *fiename_out                     = input_params->output;
+    char     fiename_out_prefix[MAX_STR_LEN] = { 0 };
+    static char filename_out_chn[MAX_STR_LEN] = { 0 };
+
+    if (input_params->save) {
+        cp = strstr(fiename_out, ".");
+        if (NULL == cp)
+            cp = fiename_out;
+        strncpy(fiename_out_prefix, fiename_out, cp - fiename_out);
+
+        if (!strcmp(input_params->encoder, "mjpeg_vastapi")) {
+            sprintf(filename_out_chn, "%s_%d_%%4d%s", fiename_out_prefix, chan, cp);
+        } else {
+            sprintf(filename_out_chn, "%s_%d%s", fiename_out_prefix, chan, cp);
+        }
+
+        input_params->output_file = filename_out_chn;
+        printf("================ output file: %s %s================\n", input_params->output_file, filename_out_chn);
+
+        if ((ret = (avformat_alloc_output_context2(&ofmt_ctx[chan], NULL, NULL, input_params->output_file))) < 0) {
+            fprintf(stderr, "Failed to deduce output format from file extension. Error code: %s\n", av_err2str(ret));
+            goto fail;
+        }
+
+        if (strcmp(input_params->encoder, "mjpeg_vastapi")) {
+            if ((ret = avio_open(&ofmt_ctx[chan]->pb, input_params->output_file, AVIO_FLAG_WRITE)) < 0) {
+                fprintf(stderr, "Cannot open output file. Error code: %s\n", av_err2str(ret));
+                goto fail;
+            }
+        }
+    } else {
+        AVOutputFormat *fmt = av_guess_format("null", NULL, NULL);
+        if (!fmt) {
+            fprintf(stderr, "Could not find null muxer.\n");
+            return -1;
+        }
+
+        // 分配AVFormatContext
+        ofmt_ctx[chan] = avformat_alloc_context();
+        if (!ofmt_ctx[chan]) {
+            fprintf(stderr, "Failed to alloc output format.\n");
+            return AVERROR_UNKNOWN;
+        }
+
+        // 设置输出格式
+        ofmt_ctx[chan]->oformat = fmt;
+    }
+
+    if (!(enc_codec = avcodec_find_encoder_by_name(input_params->encoder))) {
+        fprintf(stderr, "Could not find encoder '%s'\n", input_params->encoder);
+        ret = AVERROR(ENOENT);
+        goto fail;
+    }
+
+    if (!(encoder_ctx[chan] = avcodec_alloc_context3(enc_codec))) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    encoder_ctx[chan]->pix_fmt  = AV_PIX_FMT_VASTAPI;
+    encoder_ctx[chan]->width    = decoder_ctx[chan]->width;
+    encoder_ctx[chan]->height   = decoder_ctx[chan]->height;
+    encoder_ctx[chan]->bit_rate = input_params->bitrate;
+    encoder_ctx[chan]->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
+    encoder_ctx[chan]->get_format = get_vastapi_format;
+
+    if (input_params->vfr_fps) {
+        double     max_fps = input_params->fps > input_params->vfr_fps ? input_params->fps : input_params->vfr_fps;
+        AVRational max_framerate = av_d2q(max_fps, 4096);
+
+        encoder_ctx[chan]->time_base = av_inv_q(max_framerate);
+        encoder_ctx[chan]->framerate = max_framerate;
+        start_duration[chan]         = (double)AV_TIME_BASE / av_q2d(max_framerate);
+    } else {
+        if (input_params->fps) {
+            encoder_ctx[chan]->time_base = av_inv_q(input_params->frame_rate);
+            encoder_ctx[chan]->framerate = input_params->frame_rate;
+        } else {
+            encoder_ctx[chan]->time_base = av_inv_q(decoder_ctx[chan]->framerate);
+            encoder_ctx[chan]->framerate = decoder_ctx[chan]->framerate;
+            printf("encoder's time_base & framerate use decoder's\n");
+        }
+    }
+
+#ifdef FFMPEG_N26
+    av_opt_set_int(encoder_ctx[chan], "refcounted_frames", 1, 0);
+#endif
+
+    if (input_params->level)
+        encoder_ctx[chan]->level = input_params->level;
+
+    if (input_params->vast_params)
+        av_opt_set(encoder_ctx[chan]->priv_data, "vast-params", input_params->vast_params, 0);
+
+    if (set_user_profile(&encoder_ctx[chan]->profile, &input_params->profile, input_params->encoder) < 0) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+#ifdef FFMPEG_N26
+    encoder_ctx[chan]->hw_device_ctx = av_buffer_ref(hw_device_ctx);
+    if (!encoder_ctx[chan]->hw_device_ctx) {
+        fprintf(stderr, "A hardware device reference create failed.\n");
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+#endif
+
+#ifdef DMABUFFER_FD_ENCODE_TEST
+    if ((ret = set_hwframe_ctx(encoder_ctx[chan], hw_device_ctx, input_params, 2)) < 0)
+#elif defined EXTERNA_BUFFER_ENCODE_TEST
+    if ((ret = set_hwframe_ctx(encoder_ctx[chan], hw_device_ctx, input_params, 1)) < 0)
+#else
+    if ((ret = set_hwframe_ctx(encoder_ctx[chan], hw_device_ctx, input_params, 0)) < 0)
+#endif
+    {
+        fprintf(stderr, "Failed to set hwframe context.\n");
+        goto fail;
+    }
+
+    if (!encoder_ctx[chan]->hw_frames_ctx) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    if ((ret = avcodec_open2(encoder_ctx[chan], enc_codec, NULL)) < 0) {
+        fprintf(stderr, "Failed to open encode codec. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+#ifdef FFMPEG_N26
+    if (!(ost[chan] = avformat_new_stream(ofmt_ctx[chan], NULL)))
+#else
+    if (!(ost[chan] = avformat_new_stream(ofmt_ctx[chan], enc_codec)))
+#endif
+    {
+        fprintf(stderr, "Failed to allocate stream for output format.\n");
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    ost[chan]->time_base      = encoder_ctx[chan]->time_base;
+    ost[chan]->duration       = av_rescale_q(ist[chan]->duration, ist[chan]->time_base, ost[chan]->time_base);
+    ost[chan]->avg_frame_rate = encoder_ctx[chan]->framerate;
+
+#ifdef FFMPEG_N26
+    if ((ret = avcodec_copy_context(ost[chan]->codec, encoder_ctx[chan])) < 0)
+#else
+    if ((ret = avcodec_parameters_from_context(ost[chan]->codecpar, encoder_ctx[chan])) < 0)
+#endif
+    {
+        fprintf(stderr, "Failed to copy the stream parameters. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+    /* write the stream header */
+    if ((ret = avformat_write_header(ofmt_ctx[chan], NULL)) < 0) {
+        fprintf(stderr, "Error while writing stream header. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+#ifdef FFMPEG_N26
+    if ((ret = encoder_ctx[chan]->codec->init(encoder_ctx[chan])) < 0) {
+        fprintf(stderr, "init encoder failed. Error code: %d\n", ret);
+        goto fail;
+    }
+
+    av_buffer_unref(&ost[chan]->codec->hw_frames_ctx);
+#endif
+
+    return 0;
+
+fail:
+    if (encoder_ctx[chan]) {
+#ifdef FFMPEG_N26
+        avcodec_close(encoder_ctx[chan]);
+#endif
+
+        avcodec_free_context(&encoder_ctx[chan]);
+        encoder_ctx[chan] = NULL;
+    }
+
+    if (ofmt_ctx[chan]) {
+        avio_closep(&ofmt_ctx[chan]->pb);
+        avformat_close_input(&ofmt_ctx[chan]);
+        ofmt_ctx[chan] = NULL;
+    }
+
+    return ret;
+}
+
+//打开输入输出文件，获取信息，找到decoder和encoder，初始化decoder_ctx和encoder_ctx，打开decoder和encoder。
+static int init_dec_enc(int chan, struct option_t *input_params)
+{
+    int ret = 0;
+
+#ifdef FFMPEG_N26
+    av_register_all();
+#endif
+
+    if ((ret = decode_init(chan, input_params)) < 0) {
+        fprintf(stderr, "Init decode failed. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+
+    if ((ret = encode_init(chan, input_params)) < 0) {
+        fprintf(stderr, "Init encode failed. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+
+    return 0;
+}
+
+static int encode_write(AVFrame *frame, int chan, struct option_t *input_params)
+{
+    int      ret     = 0;
+    int      inc     = 0;
+    AVPacket enc_pkt = { 0 };
+    int      rawyuv  = strstr(input_params->input, ".yuv") || strstr(input_params->input, ".rgb");
+
+    av_init_packet(&enc_pkt);
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+    enc_pkt.pts  = 0;
+
+    if (frame && input_params->vfr_fps) {
+        if (!(frame_cnt[chan] / 100 % 2) && frame_cnt[chan] % 100 >= 0) {
+            frame->pkt_duration = (double)AV_TIME_BASE / input_params->vfr_fps;
+            if (frame_cnt[chan] ==
+                (int)(input_params->fps > input_params->vfr_fps ? input_params->vfr_fps : input_params->fps)) {
+                frame->pkt_duration = (double)AV_TIME_BASE / av_q2d(input_params->frame_rate);
+            }
+        } else {
+            frame->pkt_duration = (double)AV_TIME_BASE / av_q2d(input_params->frame_rate);
+        }
+
+        inc              = (int)((double)frame->pkt_duration / start_duration[chan] + 0.5);
+        frame->pts       = frame_pts[chan] + inc;
+        frame->time_base = AV_TIME_BASE_Q;
+
+        if (frame_cnt[chan] == 1) {
+            frame->pts = 0;
+        }
+
+        frame_pts[chan] = frame->pts;
+    }
+
+#ifdef FFMPEG_N26
+    int got_frame = 0;
+#else
+    if ((ret = avcodec_send_frame(encoder_ctx[chan], frame)) < 0) {
+        if (ret != AVERROR_EOF)
+            fprintf(stderr, "Error during encoding. Error code: %d %s\n", ret, av_err2str(ret));
+        goto end;
+    }
+#endif
+
+    while (1) {
+#ifdef FFMPEG_N26
+        if ((ret = avcodec_encode_video2(encoder_ctx[chan], &enc_pkt, frame, &got_frame)) < 0)
+#else
+        if ((ret = avcodec_receive_packet(encoder_ctx[chan], &enc_pkt)) < 0)
+#endif
+        {
+            goto end;
+        }
+
+        if (frame_cnt[chan] == input_params->frame_cnt + 1) {
+            printf("finish frame encode, count: %d\n", frame_cnt[chan]);
+            ret = -1;
+            break;
+        }
+
+#ifdef FFMPEG_N26
+        if (!got_frame) {
+            printf("&got_frame=%p, got_frame:%d\n", &got_frame, got_frame);
+            return 0;
+        }
+
+        if (enc_pkt.data) {
+            enc_pkt.data += ret;
+            enc_pkt.size -= ret;
+        }
+#endif
+
+        enc_pkt.stream_index = 0;
+
+        if (rawyuv) {
+            if (input_params->vfr_fps) {
+                enc_pkt.pts =
+                    av_rescale_q(enc_pkt.pts, encoder_ctx[chan]->time_base, ofmt_ctx[chan]->streams[0]->time_base);
+                enc_pkt.dts =
+                    av_rescale_q(enc_pkt.dts, encoder_ctx[chan]->time_base, ofmt_ctx[chan]->streams[0]->time_base);
+            } else {
+                enc_pkt.pts = enc_pkt.dts = enc_frame_cnt[chan] * ofmt_ctx[chan]->streams[0]->time_base.den /
+                                            ofmt_ctx[chan]->streams[0]->time_base.num /
+                                            (encoder_ctx[chan]->framerate.num / encoder_ctx[chan]->framerate.den);
+            }
+        } else {
+            if ((!input_params->vfr_fps) && (strcmp(input_params->encoder, "av1_vastapi") != 0))
+                av_packet_rescale_ts(&enc_pkt, ifmt_ctx[chan]->streams[video_stream[chan]]->time_base,
+                                     ofmt_ctx[chan]->streams[0]->time_base);
+        }
+
+#ifdef USER_GET_PSNR_TEST
+        PsnrSsimInfo info;
+        avcodec_vastapi_get_psnr(encoder_ctx[chan], 0, &info);
+        av_log(encoder_ctx[chan], AV_LOG_ERROR,
+            "display_order %ld  psnr=%lf %lf %lf %lf ssim=%lf %lf %lf %lf\n",
+            info.display_order, info.psnr[0], info.psnr[1], info.psnr[2], info.psnr[3], info.ssim[0], info.ssim[1], info.ssim[2], info.ssim[3]);
+#endif
+        if ((ret = av_interleaved_write_frame(ofmt_ctx[chan], &enc_pkt)) < 0) {
+            fprintf(stderr, "Error during writing data to output file. Error code: %s line: %d\n", av_err2str(ret),
+                    __LINE__);
+            return ret;
+        }
+
+        enc_frame_cnt[chan]++;
+
+#ifdef FFMPEG_N26
+        return 0;
+#endif
+    }
+
+end:
+    ret = ((ret == AVERROR(EAGAIN)) ? 0 : ret);
+    return ret;
+}
+
+#ifdef DUMP_YUV_WITH_PADDING
+static int dump_yuv_by_user_buffer(AVFrame *hw_frame)
+{
+
+    int                ret  = -1;
+    void              *data = NULL, *data_tmp = NULL;
+    AVFrame           *dst_frame;
+    AVHWFramesContext *frames_ctx = NULL;
+
+    if (!hw_frame || !hw_frame->hw_frames_ctx) {
+        av_log(NULL, AV_LOG_ERROR, "invalid input hw frame!\n");
+        return AVERROR(EIO);
+    }
+
+    dst_frame = av_frame_alloc();
+    if (!dst_frame) {
+        av_log(NULL, AV_LOG_ERROR, "%s %d malloc av frame failed\n", __func__, __LINE__);
+        return AVERROR(ENOMEM);
+    }
+
+    // transfer data from device to host user buffer
+    if ((ret = av_hwframe_transfer_data_ex(dst_frame, hw_frame, 1)) < 0) {
+        av_log(NULL, AV_LOG_ERROR, "%s %d failed to transfer data to device: %d.\n", __func__, __LINE__, ret);
+        av_frame_free(&dst_frame);
+        free(data_tmp);
+        data_tmp = NULL;
+        return AVERROR(EIO);
+    }
+
+    av_log(NULL, AV_LOG_DEBUG, "width=%d height=%d pix_fmt=%d, linesize[%d %d %d] datasize=%d\n", dst_frame->width,
+           dst_frame->height, dst_frame->format, dst_frame->linesize[0], dst_frame->linesize[1], dst_frame->linesize[2],
+           dst_frame->linesize[0] * 1088 + dst_frame->linesize[1] / 2 * 1088);
+
+    // FILE* fp = fopen("/data/work/output1.yuv", "ab+");
+    // fwrite(dst_frame->data[0], dst_frame->linesize[0] * 1088 + dst_frame->linesize[1] / 2 * 1088, 1, fp);
+    // fclose(fp);
+
+    av_frame_free(&dst_frame);
+
+    return 0;
+}
+#endif
+
+static int dec_enc(AVPacket *pkt, int chan, int rawyuv)
+{
+    int      ret          = 0;
+    Usrdata  da1          = { 0 };
+    AVFrame *hw_frame_dec = NULL;
+    AVFrame *hw_frame_enc = NULL;
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+    uint64_t frame_addr;
+#endif
+
+    da1.chn    = chan;
+    da1.cnt    = cnt[chan];
+    da1.endflg = 0;
+
+#ifndef FFMPEG_N26
+    if ((ret = avcodec_send_packet(decoder_ctx[chan], pkt)) < 0) {
+        fprintf(stderr, "Error during decoding. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+#endif
+
+#ifdef FFMPEG_N26
+    int got_frame = 1;
+
+    while (pkt->size > 0 || (!pkt->data && got_frame))
+#else
+    while (ret >= 0)
+#endif
+    {
+        if (!(da1.frame = av_frame_alloc()))
+            return AVERROR(ENOMEM);
+
+#ifdef FFMPEG_N26
+        ret = avcodec_decode_video2(decoder_ctx[chan], da1.frame, &got_frame, pkt);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF || got_frame <= 0)
+#else
+        ret = avcodec_receive_frame(decoder_ctx[chan], da1.frame);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+#endif
+        {
+            av_frame_free(&da1.frame);
+            return 0;
+        } else if (ret < 0) {
+            fprintf(stderr, "Error while decoding. Error code: %s\n", av_err2str(ret));
+            goto fail;
+        }
+
+#ifdef FFMPEG_N26
+        if (pkt->data) {
+            pkt->data += ret;
+            pkt->size -= ret;
+        }
+#endif
+
+        da1.hw_frame_dec     = NULL;
+        da1.frame->pict_type = AV_PICTURE_TYPE_NONE;
+        cnt[chan]++;
+
+        if (rawyuv) {
+            if (!(hw_frame_dec = av_frame_alloc())) {
+                fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+                return AVERROR(ENOMEM);
+            }
+
+            if ((ret = av_hwframe_get_buffer(decoder_ctx[chan]->hw_frames_ctx, hw_frame_dec, 0)) < 0) {
+                fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+                goto fail;
+            }
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+            uint64_t addr = EXTERNAL_BUFFER_START_ADDR + (cnt[chan] % 200) * 10 * 1024 * 1024;
+            av_hwframe_set_addr_to_surfaceid(hw_frame_dec, addr);
+#endif
+
+            if ((ret = av_hwframe_transfer_data(hw_frame_dec, da1.frame, 0)) < 0) {
+                fprintf(stderr, "Failed to transfer frame data to surface, Error: %s.\n", av_err2str(ret));
+                goto fail;
+            }
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+            ret = av_hwframe_get_addr_from_surfaceid(hw_frame_dec, &frame_addr);
+
+            if (!(hw_frame_enc = av_frame_alloc())) {
+                fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+                ret = AVERROR(ENOMEM);
+                goto fail;
+            }
+
+            if ((ret = av_hwframe_get_buffer(encoder_ctx[chan]->hw_frames_ctx, hw_frame_enc, 0)) < 0) {
+                fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+                goto fail;
+            }
+            printf("hw frame add 0x%lx\n", frame_addr);
+            av_hwframe_set_addr_to_surfaceid(hw_frame_enc, frame_addr);
+
+            da1.hw_frame_dec = hw_frame_dec; // if free hw_frame_dec here, yuv buffer may be released.
+#else
+            hw_frame_enc = hw_frame_dec;
+#endif
+            av_frame_free(&da1.frame);
+            da1.frame = hw_frame_enc;
+        }
+
+        av_hwframe_sync_surface(da1.frame);
+
+#ifdef DUMP_YUV_WITH_PADDING
+        dump_yuv_by_user_buffer(da1.frame);
+#endif
+
+        en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+
+    fail:
+        if (ret < 0)
+            return ret;
+    }
+
+    return 0;
+}
+
+#ifdef VASTAI_AVFRAME_TEST
+/* Read yuv data to AVFrame from file directly */
+static int dec_enc_test_avframe(struct option_t *input_params, int chan)
+{
+    int                ret = 0, i = 0;
+    FILE              *fd;
+    AVHWFramesContext *frames_ctx = (AVHWFramesContext *)(encoder_ctx[chan]->hw_frames_ctx->data);
+    AVFrame           *hw_frame;
+    AVFrame           *dma_frame[4];
+    VastFrameInfo      info;
+
+    fd = fopen(input_params->input, "r+");
+
+    info.format = frames_ctx->sw_format;
+    info.width  = frames_ctx->width;
+    info.height = frames_ctx->height;
+
+    for (i = 0; i < DMA_BUFFER_NUM_MAX; i++) {
+        dma_frame[i] = av_frame_alloc_vastai(encoder_ctx[chan]->hw_frames_ctx, &info);
+    }
+
+    while (feof(fd) == 0) {
+        Usrdata da1;
+        da1.chn    = chan;
+        da1.cnt    = cnt[chan];
+        da1.endflg = 0;
+        da1.frame  = dma_frame[cnt[chan] % DMA_BUFFER_NUM_MAX];
+
+        cnt[chan]++;
+
+        if (!(hw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+            return AVERROR(ENOMEM);
+        }
+
+        if ((ret = av_hwframe_get_buffer(encoder_ctx[chan]->hw_frames_ctx, hw_frame, 0)) < 0) {
+            fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+            av_frame_free(&hw_frame);
+            return -1;
+        }
+
+        int plane_number = 0;
+        int src_linesizes[3];
+        src_linesizes[0] = frames_ctx->width;
+        if (da1.frame->format == AV_PIX_FMT_YUV420P) {
+            plane_number     = 3;
+            src_linesizes[1] = frames_ctx->width / 2;
+            src_linesizes[2] = frames_ctx->width / 2;
+        } else if (da1.frame->format == AV_PIX_FMT_NV12) {
+            plane_number     = 2;
+            src_linesizes[1] = frames_ctx->width;
+            src_linesizes[2] = 0;
+        } else {
+            fprintf(stderr, "%s Unsupported format: %d.\n", __func__, da1.frame->format);
+            return -1;
+        }
+
+        int height = da1.frame->height;
+        int plane  = 0;
+        for (; plane < plane_number; plane++) {
+            uint8_t *dst          = da1.frame->data[plane];
+            int      dst_linesize = da1.frame->linesize[plane];
+            int      src_linesize = src_linesizes[plane];
+            int      tmp_height;
+            tmp_height = plane > 0 ? height / 2 : height;
+            for (; tmp_height > 0; tmp_height--) {
+                ret = fread(dst, src_linesize, 1, fd);
+                if (!ret) {
+                    av_frame_free(&hw_frame);
+                    goto fail;
+                }
+                dst += dst_linesize;
+            }
+        }
+
+        if ((ret = av_hwframe_transfer_data(hw_frame, da1.frame, 0)) < 0) {
+            fprintf(stderr, "Failed to transfer frame data to surface, Error: %s.\n", av_err2str(ret));
+            av_frame_free(&da1.frame);
+            return -1;
+        }
+
+        da1.frame = hw_frame;
+
+        en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+    }
+
+fail:
+    for (i = 0; i < DMA_BUFFER_NUM_MAX; i++) {
+        av_frame_free(&dma_frame[i]);
+    }
+
+    fclose(fd);
+
+    return 0;
+}
+#endif
+
+#ifdef DMABUFFER_FD_ENCODE_TEST
+static int get_dmabuffer_fd()
+{
+    return 0;
+}
+
+static int dec_enc_test_dmabuffer(struct option_t *input_params, int chan)
+{
+    int                ret = 0, i = 0;
+    FILE              *fd;
+    AVHWFramesContext *frames_ctx = (AVHWFramesContext *)(encoder_ctx[chan]->hw_frames_ctx->data);
+    AVFrame           *hw_frame, *src_frame;
+    VastFrameInfo      info;
+    int                dmabuffer_fd = 0;
+    void              *data = NULL, *data_tmp = NULL;
+
+    fd = fopen(input_params->input, "r+");
+
+    while (feof(fd) == 0) {
+        Usrdata da1;
+        da1.chn    = chan;
+        da1.cnt    = cnt[chan];
+        da1.endflg = 0;
+
+        cnt[chan]++;
+
+        // prepare hw frame
+        if (!(hw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+            return AVERROR(ENOMEM);
+        }
+
+        if ((ret = av_hwframe_get_buffer(encoder_ctx[chan]->hw_frames_ctx, hw_frame, 0)) < 0) {
+            fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+            av_frame_free(&hw_frame);
+            return -1;
+        }
+
+        // prepare src frame from dmabuffer fd
+        src_frame = av_frame_alloc();
+        if (!src_frame) {
+            av_log(frames_ctx, "%s %d Cannot alloc src frame. Error: %s.\n", __func__, __LINE__);
+            return AVERROR(ENOMEM);
+        }
+
+        src_frame->width       = frames_ctx->width;
+        src_frame->height      = frames_ctx->height;
+        src_frame->linesize[0] = frames_ctx->width;
+        src_frame->linesize[1] = frames_ctx->width / 2;
+
+#if 0
+        // dmabuffer_fd = get_dmabuffer_fd();
+        // src_frame->opaque = (void*)&dmabuffer_fd;
+        // transfer dmabuffer data to device
+        if ((ret = av_hwframe_transfer_data_ex(hw_frame, src_frame, INPUT_TYPE_FD)) < 0)
+        {
+            av_log(frames_ctx, "%s %d failed to transfer data to device: %d.\n", __func__, __LINE__, ret);
+            av_frame_free(&src_frame);
+            av_frame_free(&hw_frame);
+            return AVERROR(EIO);
+        }
+#else
+        data_tmp = malloc(4 * 1024 * 1024 + 1);
+        data     = data_tmp + 1;
+        if (ret) {
+            av_log(frames_ctx, "%s %d malloc failed, ret = %d\n", __func__, __LINE__, ret);
+            return AVERROR(ENOMEM);
+        }
+        printf("malloc data = %p\n", data);
+
+        fread(data, frames_ctx->width * frames_ctx->height * 3 / 2, 1, fd);
+
+        src_frame->opaque = data;
+        hw_frame->opaque  = data;
+
+        // transfer dmabuffer data to device
+        if ((ret = av_hwframe_transfer_data_ex(hw_frame, src_frame, INPUT_TYPE_ADDR)) < 0) {
+            av_log(frames_ctx, "%s %d failed to transfer data to device: %d.\n", __func__, __LINE__, ret);
+            av_frame_free(&src_frame);
+            av_frame_free(&hw_frame);
+            free(data_tmp);
+            data_tmp = NULL;
+            return AVERROR(EIO);
+        }
+
+        free(data_tmp);
+        data_tmp = NULL;
+#endif
+
+        da1.frame = hw_frame;
+
+        en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+
+        av_frame_free(&src_frame);
+    }
+
+    fclose(fd);
+
+    return 0;
+}
+#endif
+
+// 编码-transcoding 子线程
+static void *process_enc(void *arg)
+{
+    int                 chan = 0, ret = 0;
+    struct thread_info *ti           = (struct thread_info *)arg;
+    struct option_t    *input_params = (struct option_t *)ti->handle;
+    chan                             = ti->thread_chn;
+
+    while (1) {
+        Usrdata *dap;
+        int      endflg = 0;
+        dap             = read_queue((void *)queue_g[chan]);
+
+        endflg = dap->endflg;
+        if (!endflg)
+            frame_cnt[chan]++;
+
+#ifdef INSERTIDR_TEST
+        if (input_params->enable_idr) {
+            if (dap->frame && frame_cnt[chan] % 20 == 0)
+                dap->frame->pict_type = AV_PICTURE_TYPE_I;
+        }
+#endif
+
+#ifdef DYNAMIC_BITRATE_TEST
+        if (input_params->enable_dynamic_bitrate) {
+            if (frame_cnt[chan] % 20 == 0 && dap->frame) {
+                AVFrameSideData *br_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATE_VASTAI_BITRATE_EXT1);
+                br_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATE_VASTAI_BITRATE_EXT1, sizeof(uint32_t) * 3);
+                if (br_side) {
+                    uint32_t *data = (uint32_t *)br_side->data;
+                    data[0]        = (frame_cnt[chan] + 8001) % 2000; // target bitrate, kbps
+                    data[1]        = 0; // vbvMaxrate,  kbps, need set to 0 if use default;
+                    data[2]        = 0; // hrd bufsize, kbps, need set to 0 if use default;
+                }
+            }
+        }
+#endif
+
+#ifdef DYNAMIC_FRAMERATE_TEST
+        if (input_params->enable_dynamic_fps) {
+            if (frame_cnt[chan] % 100 == 0 && dap->frame) {
+                AVFrameSideData *fr_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_VASTAI_FRAMERATE);
+                fr_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_VASTAI_FRAMERATE, sizeof(uint32_t));
+                if (fr_side) {
+                    uint32_t *data = (uint32_t *)fr_side->data;
+                    data[0]        = 60; // target bitrate, kbps
+                }
+            }
+        }
+#endif
+
+#ifdef DYNAMIC_CRF_TEST
+        if (input_params->enable_dynamic_crf) {
+            if (dap->frame) {
+                AVFrameSideData *crf_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_VASTAI_CRF);
+                crf_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_VASTAI_CRF, 3 * sizeof(int32_t));
+                if (crf_side) {
+                    int32_t *data = (int32_t *)crf_side->data;
+                    data[0]       = 10 + (frame_cnt[chan] % 2) * 20; // change crf every frames
+                    data[1]       = frame_cnt[chan] / 100 * 1000;    // vbvMaxRate kbps
+                    data[2]       = frame_cnt[chan] / 100 * 2000;    // vbvBufSize kbps
+                }
+            }
+        }
+#endif // DYNAMIC_CRF_TEST
+
+#ifdef SEI_TEST
+        if (input_params->enable_sei) {
+            if (dap->frame != NULL) {
+                int              index;
+                uint8_t         *buffer    = NULL;
+                AVFrameSideData *side_data = NULL;
+                struct timeval   tv;
+                uint64_t         encode_start_ms;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_UDU_SEI);
+
+                for (index = 0; index < SEI_COUNT; index++) {
+                    side_data = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_UDU_SEI, SEI_BUFFER_SIZE);
+                    if (!side_data) {
+                        fprintf(stderr, "failed to create new side data\n");
+                        return NULL;
+                    }
+
+                    buffer = side_data->data;
+                    memcpy(buffer, encode_h264_sei_appdata_uuid[index % 2],
+                           sizeof(encode_h264_sei_appdata_uuid[index % 2]));
+                    buffer += sizeof(encode_h264_sei_appdata_uuid[index % 2]);
+
+                    memcpy(buffer, &frame_cnt[chan], sizeof(frame_cnt[chan]));
+                    buffer += sizeof(frame_cnt[chan]);
+
+                    gettimeofday(&tv, NULL);
+                    encode_start_ms = tv.tv_sec * 1000 + tv.tv_usec / 1000;
+                    memcpy(buffer, &encode_start_ms, sizeof(encode_start_ms));
+                    buffer += sizeof(encode_start_ms);
+                }
+            }
+        }
+#endif
+
+#ifdef ROIMAP_TEST
+        if (input_params->enable_roi) {
+            if (dap->frame != NULL) {
+                int32_t roimap_value[3] = { -31, 31, 0 };
+                int32_t roimap_index;
+                int     x = 0, y = 0;
+                roimap_index = (frame_cnt[chan] / 10) % 3;
+                // static int32_t roimap_last_value = 0;
+
+                // if(roimap_value[roimap_index] != roimap_last_value)
+                {
+                    AVFrameSideData *side_data = NULL;
+
+                    uint32_t width, height;
+                    uint32_t roimap_block_unit;
+                    uint32_t blksize;
+                    uint32_t roiwidth, roiheight, roimap_size;
+                    uint8_t *buffer = NULL;
+
+                    char *p;
+                    width = strtol(input_params->video_size, (void *)&p, 10);
+                    if (*p)
+                        p++;
+                    height = strtol(p, (void *)&p, 10);
+
+                    p                 = strstr(input_params->vast_params, "roiMapDeltaQpBlockUnit");
+                    p                 = strchr(p, '=');
+                    roimap_block_unit = atoi(p + 1);
+
+                    blksize     = 64 >> (roimap_block_unit & 3);
+                    roiwidth    = (width + blksize - 1) / blksize;
+                    roiheight   = (height + blksize - 1) / blksize;
+                    roimap_size = roiwidth * roiheight;
+
+                    if (!side_data) {
+                        side_data = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_ROIMAP, roimap_size);
+                        if (!side_data) {
+                            fprintf(stderr, "failed to create new roimap side data\n");
+                            return NULL;
+                        }
+                    }
+
+                    buffer = side_data->data;
+                    memset(buffer, 0, roiwidth * roiheight);
+                    for (y = 0; y < roiheight / 3; y++) {
+                        for (x = 0; x < roiwidth / 2; x++) {
+                            buffer[y * roiwidth + x] = -roimap_value[roimap_index];
+                        }
+                    }
+
+                    for (y = roiheight / 3; y < roiheight; y++) {
+                        for (x = 3 * roiwidth / 4; x < roiwidth; x++) {
+                            buffer[y * roiwidth + x] = roimap_value[roimap_index];
+                        }
+                    }
+                    // roimap_last_value = roimap_value[roimap_index];
+                }
+            }
+        }
+#endif
+
+        if (input_params->enable_dynamic_keyint) {
+            if (frame_cnt[chan] % 100 == 0 && dap->frame) {
+                AVFrameSideData *fr_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_VASTAI_KEYINT);
+                fr_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_VASTAI_KEYINT, sizeof(uint32_t));
+                if (fr_side) {
+                    uint32_t *data = (uint32_t *)fr_side->data;
+                    data[0]        = (frame_cnt[chan] / 100 % 10) * 10; // target keyint
+                }
+            }
+        }
+
+        if (dap->frame) {
+            if ((ret = encode_write(dap->frame, chan, input_params)) < 0) {
+                if (ret != AVERROR_EOF) {
+                    fprintf(stderr, "Error during encoding and writing. %d %s\n", ret, av_err2str(ret));
+                    thread_end[chan] = 1;
+                }
+            }
+        }
+
+        if (dap->frame) {
+            av_frame_free(&dap->frame);
+        }
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+        if (dap->hw_frame_dec)
+            av_frame_free(&dap->hw_frame_dec);
+#endif
+
+        de_queue((void *)queue_g[chan]);
+
+        if (endflg == 1 || thread_end[chan]) {
+            printf("chan %d here will end -------------------\n", chan);
+
+            // flush encoder
+            while (1) {
+                if ((ret = encode_write(NULL, chan, input_params)) < 0) {
+                    if (ret != AVERROR_EOF)
+                        fprintf(stderr, "Error during flush encoding and writing. %d %s\n", ret, av_err2str(ret));
+                    break;
+                }
+            }
+
+            av_write_trailer(ofmt_ctx[chan]);
+
+            if (thread_end[chan]) {
+                do {
+                    de_queue((void *)queue_g[chan]);
+                } while (!is_empty((void *)queue_g[chan]));
+            }
+
+            printf("chan %d transcode success! total frame_cnt %d, cnt %ld\n", chan, frame_cnt[chan], cnt[chan]);
+
+            break;
+        }
+    }
+
+    return NULL;
+}
+
+// 解码-transcoding 子线程
+static void *process_dec(void *arg)
+{
+    int                 chan         = 0;
+    int                 ret          = 0;
+    AVPacket            dec_pkt      = { 0 };
+    Usrdata             da1          = { 0 };
+    struct thread_info *ti           = (struct thread_info *)arg;
+    struct option_t    *input_params = (struct option_t *)ti->handle;
+    char               *fiename_in   = input_params->input;
+    int                 rawyuv       = 0;
+
+    rawyuv = (strstr(fiename_in, ".yuv") || strstr(fiename_in, ".rgb")) ? 1 : 0;
+    chan   = ti->thread_chn;
+
+    if (thread_end[chan])
+        return NULL;
+
+        /* read all packets and only transcoding video */
+#ifdef VASTAI_AVFRAME_TEST
+    dec_enc_test_avframe(input_params, chan);
+#elif defined DMABUFFER_FD_ENCODE_TEST
+    dec_enc_test_dmabuffer(input_params, chan);
+#else
+    while (ret >= 0 && !thread_end[chan]) {
+        if ((ret = av_read_frame(ifmt_ctx[chan], &dec_pkt)) < 0) {
+            if (loop[chan]) {
+                avio_closep(&ofmt_ctx[chan]->pb);
+
+                if ((ret = avio_open(&ofmt_ctx[chan]->pb, input_params->output_file, AVIO_FLAG_WRITE)) < 0) {
+                    fprintf(stderr, "Cannot open output file. Error code: %s\n", av_err2str(ret));
+                    break;
+                }
+
+                if (loop[chan] == -1)
+                    loop[chan] = 0;
+
+                printf("thread %d looping %d................................ \n", chan, loop[chan]);
+                loop[chan]--;
+
+                av_seek_frame(ifmt_ctx[chan], video_stream[chan], 0, AVSEEK_FLAG_BYTE);
+
+                if ((ret = av_read_frame(ifmt_ctx[chan], &dec_pkt)) < 0) {
+                    fprintf(stderr, "looping fail!!!\n");
+                    break;
+                }
+            } else {
+                break;
+            }
+        }
+
+        if (video_stream[chan] == dec_pkt.stream_index)
+            ret = dec_enc(&dec_pkt, chan, rawyuv);
+
+        av_packet_unref(&dec_pkt);
+    }
+
+    /* flush decoder */
+    dec_pkt.data = NULL;
+    dec_pkt.size = 0;
+    ret          = dec_enc(&dec_pkt, chan, rawyuv);
+
+    av_packet_unref(&dec_pkt);
+#endif
+
+    da1.chn    = chan;
+    da1.cnt    = cnt[chan];
+    da1.endflg = 1;
+    da1.frame  = NULL;
+
+    en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+
+    return NULL;
+}
+
+static int transcode(struct option_t *input_params)
+{
+    int                ret                        = 0;
+    int                chan                       = 0; // 线程号
+    int                thread_sum                 = input_params->thread_num;
+    struct thread_info usrarg_enc[MAX_THREAD_NUM] = { 0 };
+    struct thread_info usrarg_dec[MAX_THREAD_NUM] = { 0 };
+
+    // 初始化变量
+    for (chan = 0; chan < thread_sum; chan++) {
+        ifmt_ctx[chan]     = NULL;
+        ofmt_ctx[chan]     = NULL;
+        decoder_ctx[chan]  = NULL;
+        encoder_ctx[chan]  = NULL;
+        video_stream[chan] = -1;
+        cnt[chan]          = 0;
+        queue_g[chan]      = init_queue();
+        thread_end[chan]   = 0;
+        loop[chan]         = input_params->loop;
+        frame_pts[chan]    = 0;
+        frame_cnt[chan]    = 0;
+    }
+
+    for (chan = 0; chan < thread_sum; chan++) {
+        if ((ret = init_dec_enc(chan, input_params)) < 0) {
+            printf("init dec and enc error! %d\n", ret);
+            return ret;
+        }
+
+        usrarg_dec[chan].thread_chn = chan;
+        usrarg_dec[chan].thread_id  = chan;
+        usrarg_dec[chan].handle     = input_params;
+        if ((pthread_create(&usrarg_dec[chan].thread_id, NULL, process_dec, (void *)&usrarg_dec[chan])) == -1) {
+            printf("create process dec error!\n");
+            return -1;
+        }
+
+        usrarg_enc[chan].thread_chn = chan;
+        usrarg_enc[chan].thread_id  = chan;
+        usrarg_enc[chan].handle     = input_params;
+        if ((pthread_create(&usrarg_enc[chan].thread_id, NULL, process_enc, (void *)&usrarg_enc[chan])) == -1) {
+            printf("create process enc error!\n");
+            return -1;
+        }
+    }
+
+    for (chan = 0; chan < thread_sum; chan++) {
+        pthread_join(usrarg_dec[chan].thread_id, NULL);
+        pthread_join(usrarg_enc[chan].thread_id, NULL);
+    }
+
+    for (chan = 0; chan < thread_sum; chan++) {
+        destroy_queue((void *)queue_g[chan]);
+
+        if (ofmt_ctx[chan]->pb)
+            avio_closep(&ofmt_ctx[chan]->pb);
+
+#ifdef FFMPEG_N26
+        avcodec_close(decoder_ctx[chan]);
+        avcodec_close(encoder_ctx[chan]);
+        avformat_close_input(&ifmt_ctx[chan]);
+        avformat_close_input(&ofmt_ctx[chan]);
+        avcodec_free_context(&encoder_ctx[chan]);
+#else
+        avformat_close_input(&ifmt_ctx[chan]);
+        avformat_close_input(&ofmt_ctx[chan]);
+        avcodec_free_context(&decoder_ctx[chan]);
+        avcodec_free_context(&encoder_ctx[chan]);
+#endif
+
+        decoder_ctx[chan] = NULL;
+        encoder_ctx[chan] = NULL;
+        ifmt_ctx[chan]    = NULL;
+        ofmt_ctx[chan]    = NULL;
+        thread_end[chan]  = 1;
+        frame_pts[chan]   = 0;
+        frame_cnt[chan]   = 0;
+    }
+
+    av_buffer_unref(&hw_device_ctx); //释放硬件资源
+
+    return 0;
+}
+
+static void usage(const char *program)
+{
+    fprintf(stderr, "\nUsage: %s [options]\n", program);
+    fprintf(stderr, "\n");
+    fprintf(stderr, "\t-i    input video file.  e.g. "
+                    "/video-case/video_xiaoling/test_encode/BQTerrace_yuv420p_1920x1080_60_50.yuv\n");
+    fprintf(stderr, "\t-o    output video file. e.g. /home/xiaoling/video/out.h264\n");
+    fprintf(stderr, "\t-r    render node.       e.g. /dev/vastai_video0\n");
+    fprintf(stderr, "\t-f    encode fps.        e.g. 30.0\n");
+    fprintf(stderr, "\t-b    encode bitrate.    e.g. 2000000\n");
+    fprintf(stderr, "\t-s    input video size.  e.g. 1920x1080\n");
+    fprintf(stderr, "\t-e    encoder.           e.g. h264_vastapi\n");
+    fprintf(stderr, "\t-p    encode profile.    e.g. main\n");
+    fprintf(stderr, "\t-l    encode levle.      e.g. 1.0\n");
+    fprintf(stderr, "\t-n    thread cnt.        default 1, max 32\n");
+    fprintf(stderr, "\t-c    number of actual transcoding frames.   default -1, means end of file\n");
+    fprintf(stderr, "\t-d    enable AV_LOG_DEBUG\n");
+
+    fprintf(stderr, "\t--vast_params        encode params\n");
+    fprintf(stderr, "\t--pix_fmt            input video pixel format.       e.g. nv12\n");
+    fprintf(stderr, "\t--loop               loop count.                     default 0, -1 means infinite loop\n");
+    fprintf(stderr, "\t--vfr                vfr interval.                   default 0(disenable)\n");
+    fprintf(stderr, "\t--roi                enable roi.                     default 0(disenable)\n");
+    fprintf(stderr, "\t--sei                enable sei.                     default 0(disenable)\n");
+    fprintf(stderr, "\t--idr                enable idr.                     default 0(disenable)\n");
+    fprintf(stderr, "\t--dynamic_bitrate    enable dynamic bitrate.         default 0(disenable)\n");
+    fprintf(stderr, "\t--dynamic_fps        enable dynamic fps.             default 0(disenable)\n");
+    fprintf(stderr, "\t--dynamic_crf        enable dynamic crf.             default 0(disenable)\n");
+    fprintf(stderr, "\t--dynamic_keyint     enable dynamic keyint.          default 0(disenable)\n");
+    fprintf(stderr, "\t--save               save file.                      default 1(enable)\n");
+    fprintf(stderr, "\t--help               help manuals\n");
+}
+
+static int parse_options(int argc, char **argv, struct option_t *input_params)
+{
+    static const char    optstr[]       = "i:o:r:f:b:s:e:p:n:l:c:d";
+    static struct option long_options[] = { { "vast_params", required_argument, 0, 0 },
+                                            { "pix_fmt", required_argument, 0, 0 },
+                                            { "loop", required_argument, 0, 0 },
+                                            { "vfr", required_argument, 0, 0 },
+                                            { "roi", required_argument, 0, 0 },
+                                            { "sei", required_argument, 0, 0 },
+                                            { "idr", required_argument, 0, 0 },
+                                            { "dynamic_bitrate", required_argument, 0, 0 },
+                                            { "dynamic_fps", required_argument, 0, 0 },
+                                            { "dynamic_crf", required_argument, 0, 0 },
+                                            { "dynamic_keyint", required_argument, 0, 0 },
+                                            { "save", required_argument, 0, 0 },
+                                            { "help", no_argument, 0, 'h' },
+                                            { 0, 0, 0, 0 } };
+
+    int c = 0, option_index = 0;
+
+    /* Formerly, initialization of getopt depended on optind==0,
+    which causes problems with re-calling getopt as programs generally don't know that. */
+    optind = 0;
+
+    while ((c = getopt_long(argc, argv, optstr, long_options, &option_index)) != -1) {
+        switch (c) {
+        case 0:
+            if (optarg && strcmp(long_options[option_index].name, "vast_params") == 0) {
+                input_params->vast_params = optarg;
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "pix_fmt") == 0) {
+                input_params->pixel_format = optarg;
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "loop") == 0) {
+                input_params->loop = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "vfr") == 0) {
+                input_params->vfr_fps = atof(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "roi") == 0) {
+                input_params->enable_roi = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "sei") == 0) {
+                input_params->enable_sei = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "idr") == 0) {
+                input_params->enable_idr = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "dynamic_bitrate") == 0) {
+                input_params->enable_dynamic_bitrate = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "dynamic_fps") == 0) {
+                input_params->enable_dynamic_fps = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "dynamic_crf") == 0) {
+                input_params->enable_dynamic_crf = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "dynamic_keyint") == 0) {
+                input_params->enable_dynamic_keyint = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "save") == 0) {
+                input_params->save = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            }
+
+            break;
+        case 'i':
+            input_params->input = optarg;
+            printf("========= %c with args %s\n", c, input_params->input);
+            break;
+        case 'o':
+            input_params->output = optarg;
+            printf("========= %c with args %s\n", c, input_params->output);
+            break;
+        case 'r':
+            input_params->render = optarg;
+            printf("========= %c with args %s\n", c, input_params->render);
+            break;
+        case 'f':
+            input_params->fps        = atof(optarg);
+            input_params->frame_rate = av_d2q(input_params->fps, 4096);
+            printf("========= %c with args %f %d\n", c, input_params->fps, input_params->frame_rate.num);
+            break;
+        case 'b':
+            input_params->bitrate = atoi(optarg);
+            printf("========= %c with args %d\n", c, input_params->bitrate);
+            break;
+        case 's':
+            input_params->video_size = optarg;
+            printf("========= %c with args %s\n", c, input_params->video_size);
+            break;
+        case 'e':
+            input_params->encoder = optarg;
+            printf("========= %c with args %s\n", c, input_params->encoder);
+            break;
+        case 'p':
+            input_params->profile = optarg;
+            printf("========= %c with args %s\n", c, input_params->profile);
+            break;
+        case 'l':
+            input_params->level = atof(optarg);
+            printf("========= %c with args %f\n", c, input_params->level);
+            break;
+        case 'n':
+            input_params->thread_num = atoi(optarg);
+            printf("========= %c with args %d\n", c, input_params->thread_num);
+            break;
+        case 'c':
+            input_params->frame_cnt = atoi(optarg);
+            printf("========= %c with args %d\n", c, input_params->frame_cnt);
+            break;
+        case 'd':
+            av_log_set_level(AV_LOG_DEBUG);
+            printf("========= %c enable debug log\n", c);
+            break;
+        case 'h':
+            usage(argv[0]);
+            return -1;
+        case '?':
+        default:
+            printf("  unsupported option %c\n", c);
+            usage(argv[0]);
+            return -1;
+        }
+    }
+
+    if (optind < argc) {
+        usage(argv[0]);
+        return -1;
+    }
+
+    return 0;
+}
+
+static void set_default_params(struct option_t *input_params)
+{
+    input_params->input        = "/video-case/video_xiaoling/test_encode/BQTerrace_yuv420p_1920x1080_60_50.yuv";
+    input_params->output       = "out.h264";
+    input_params->render       = NULL;
+    input_params->fps          = 60.0;
+    input_params->frame_rate   = av_d2q(input_params->fps, 4096);
+    input_params->bitrate      = 5000000;
+    input_params->encoder      = "h264_vastapi";
+    input_params->video_size   = "1920x1080";
+    input_params->pixel_format = "yuv420p";
+    input_params->vast_params  = NULL;
+    input_params->profile      = NULL;
+    input_params->level        = 0.0;
+    input_params->thread_num   = 1;
+    input_params->frame_cnt    = -1;
+    input_params->loop         = 0;
+    input_params->save         = 1;
+    input_params->vfr_fps      = 0;
+    input_params->enable_roi   = 0;
+    input_params->enable_sei   = 0;
+    input_params->enable_idr   = 0;
+    input_params->enable_dynamic_bitrate = 0;
+    input_params->enable_dynamic_fps     = 0;
+    input_params->enable_dynamic_crf     = 0;
+    input_params->enable_dynamic_keyint  = 0;
+}
+
+int main(int argc, char **argv)
+{
+    int             ret          = 0;
+    struct option_t input_params = { 0 };
+
+    set_default_params(&input_params);
+
+    if ((ret = parse_options(argc, argv, &input_params)) < 0) {
+        printf("parse_options failed\n");
+        return ret;
+    }
+
+    int count = 1;
+
+    while (!ret && count) {
+        ret = transcode(&input_params);
+        count--;
+        printf("-------- remain count = %d, ret %d --------\n\n", count, ret);
+    }
+
+    return ret;
+}
diff --git a/doc/examples/vastapi_varres_transcode.c b/doc/examples/vastapi_varres_transcode.c
new file mode 100644
index 0000000..b9b8707
--- /dev/null
+++ b/doc/examples/vastapi_varres_transcode.c
@@ -0,0 +1,1868 @@
+#define CONFIG_VASTAPI 1
+#include <stdio.h>
+#include <errno.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <pthread.h>
+#include <unistd.h>
+#include <string.h>
+#include <semaphore.h>
+#include <getopt.h>
+#include <sys/time.h>
+#include "libavutil/hwcontext.h"
+#include "libavcodec/avcodec.h"
+#include "libavformat/avformat.h"
+#include "libavutil/opt.h"
+
+#define RESET_TEST
+// #define VASTAI_AVFRAME_TEST
+// #define EXTERNA_BUFFER_ENCODE_TEST
+// #define DMABUFFER_FD_ENCODE_TEST
+
+/*系统声明的全局变量 */
+extern char *optarg;
+extern int   optind, opterr, optopt;
+
+#define MAX_STR_LEN 1024  // string len
+#define MAX_QUEUE_LEN 20  // queue len
+#define MAX_THREAD_NUM 32 // thread num
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+#define EXTERNAL_BUFFER_START_ADDR 0x900000000 /*Reserved for sv 100 GPU ddr addr*/
+#endif
+
+#ifdef VASTAI_AVFRAME_TEST
+#define DMA_BUFFER_NUM_MAX 4
+#endif
+
+#ifdef DMABUFFER_FD_ENCODE_TEST
+#define INPUT_TYPE_FD 0
+#define INPUT_TYPE_ADDR 1
+#endif
+
+static AVFormatContext *ifmt_ctx[MAX_THREAD_NUM] = { NULL }, *ofmt_ctx[MAX_THREAD_NUM] = { NULL };
+#ifdef RESET_TEST
+static AVFormatContext *ifmt_ctx2[MAX_THREAD_NUM] = { NULL };
+#endif
+static AVBufferRef    *hw_device_ctx[MAX_THREAD_NUM] = { NULL };
+static AVCodecContext *decoder_ctx[MAX_THREAD_NUM] = { NULL }, *encoder_ctx[MAX_THREAD_NUM] = { NULL };
+static int             video_stream[MAX_THREAD_NUM] = { 0 };
+static AVStream       *ist[MAX_THREAD_NUM]          = { NULL };
+static AVStream       *ost[MAX_THREAD_NUM]          = { NULL };
+static int             cnt[MAX_THREAD_NUM]          = { 0 };
+struct Queue          *queue_g[MAX_THREAD_NUM]      = { NULL };
+static int             frame_cnt[MAX_THREAD_NUM] = { 0 }, enc_frame_cnt[MAX_THREAD_NUM] = { 0 };
+static long            frame_pts[MAX_THREAD_NUM]      = { 0 };
+static int             thread_end[MAX_THREAD_NUM]     = { 0 };
+static int             decode_end[MAX_THREAD_NUM]     = { 0 };
+static int             decode_num[MAX_THREAD_NUM]     = { 0 };
+static int             loop[MAX_THREAD_NUM]           = { 0 };
+static int             input_cnt[MAX_THREAD_NUM]      = { 0 };
+static int64_t         start_duration[MAX_THREAD_NUM] = { 0 };
+
+#define SEI_COUNT 2
+#define SEI_BUFFER_SIZE 28
+static const uint8_t encode_h264_sei_appdata_uuid[2][16] = {
+    { 0x9e, 0x03, 0xef, 0xfd, 0x23, 0x95, 0x41, 0x01, 0xb6, 0xc2, 0x0c, 0x02, 0xbb, 0x0d, 0xa8, 0xae },
+    { 0x9f, 0x03, 0xef, 0xfd, 0x23, 0x95, 0x41, 0x01, 0xb6, 0xc2, 0x0c, 0x02, 0xbb, 0x0d, 0xa8, 0xae }
+};
+
+typedef struct option_t {
+    char      *input;
+    char      *output;
+    char      *output_file;
+    char      *render;
+    double     fps;
+    AVRational frame_rate;
+    int        bitrate;
+    char      *vast_params;
+    char      *video_size;
+    char      *pixel_format;
+    char      *encoder;
+    char      *profile;
+    double     level;
+    int        thread_num;
+    int        frame_cnt;
+    int        loop;
+    int        count;
+    int        save;
+    double     vfr_fps;
+
+    char *reset_input;
+    char *reset_video_size;
+    int   reset_frame_num;
+
+    int enable_roi;
+    int enable_sei;
+    int enable_idr;
+    int enable_dynamic_bitrate;
+    int enable_dynamic_fps;
+    int crf;
+    int enable_reset_resolution;
+    int enable_dynamic_keyint;
+} option_t;
+
+struct thread_info {
+    pthread_t thread_id;  /* ID returned by pthread_create() */
+    int       thread_chn; /* Application-defined thread id # */
+    void     *handle;
+};
+
+typedef struct {
+    void        *data;
+    struct Node *next;
+} Node;
+
+typedef struct {
+    Node           *front; // head
+    Node           *rear;  // tail
+    int             len;
+    int             max_len;
+    pthread_mutex_t q_lock;
+    pthread_cond_t  not_empty;
+    pthread_cond_t  not_full;
+} Queue;
+
+typedef struct Usrdata {
+    int      chn;
+    int      cnt;
+    char     endflg;
+    AVFrame *frame;
+    AVFrame *hw_frame_dec;
+} Usrdata;
+
+static void *init_queue(void)
+{
+    Queue *queue = (Queue *)malloc(sizeof(Queue));
+    if (!queue) {
+        printf("not enough mem\n");
+        exit(1);
+    }
+
+    queue->rear = queue->front = (Node *)malloc(sizeof(Node));
+    queue->front->next         = NULL;
+    queue->len                 = 0;
+    queue->max_len             = MAX_QUEUE_LEN;
+
+    pthread_mutex_init(&queue->q_lock, NULL);
+    pthread_cond_init(&queue->not_empty, NULL);
+    pthread_cond_init(&queue->not_full, NULL);
+
+    return queue;
+}
+
+static void en_queue(Queue *q, void *data, size_t len)
+{
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == MAX_QUEUE_LEN) {
+        // printf("en queue is full\n");
+        pthread_cond_wait(&q->not_full, &q->q_lock);
+    }
+
+    Node *newnode = (Node *)malloc(sizeof(Node));
+    newnode->data = malloc(len);
+    memcpy(newnode->data, data, len);
+    newnode->next = NULL;
+
+    q->rear->next = (void *)newnode;
+    q->rear       = newnode;
+    q->len        = q->len + 1;
+
+    pthread_cond_signal(&q->not_empty);
+    pthread_mutex_unlock(&q->q_lock);
+}
+
+static void de_queue(Queue *q)
+{
+    Node *newnode;
+
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == 0) {
+        // printf("de queue is empty\n");
+        pthread_cond_wait(&q->not_empty, &q->q_lock);
+    }
+
+    newnode        = (void *)q->front->next;
+    q->front->next = newnode->next;
+
+    if (q->rear == newnode)
+        q->rear = q->front;
+
+    free(newnode->data);
+    free(newnode);
+
+    q->len = q->len - 1;
+
+    pthread_cond_signal(&q->not_full);
+    pthread_mutex_unlock(&q->q_lock);
+    return;
+}
+
+static void *read_queue(Queue *q)
+{
+    Node *read_node;
+
+    pthread_mutex_lock(&q->q_lock);
+    while (q->len == 0) {
+        // printf("read queue is empty\n");
+        pthread_cond_wait(&q->not_empty, &q->q_lock);
+    }
+
+    read_node = (void *)q->front->next;
+    if (read_node == NULL) {
+        printf("q->front->next is empty\n");
+        return NULL;
+    }
+
+    pthread_cond_signal(&q->not_empty);
+    pthread_mutex_unlock(&q->q_lock);
+    return read_node->data;
+}
+
+static int is_empty(Queue *q)
+{
+    return (q->len == 0);
+}
+
+static int destroy_queue(Queue *q)
+{
+    while (q->front) {
+        q->rear = (void *)q->front->next;
+        free(q->front);
+        q->front = q->rear;
+    }
+
+    return 0;
+}
+
+#ifdef FFMPEG_N311
+static int get_vast_buffer(AVCodecContext *avctx, AVFrame *frame, int flags)
+{
+    int ret = 0;
+
+    if ((ret = av_hwframe_get_buffer(avctx->hw_frames_ctx, frame, 0)) < 0) {
+        printf("Failed to allocate decoder surface.\n");
+    }
+
+    return ret;
+}
+#endif
+
+// 获取formart
+static enum AVPixelFormat get_vastapi_format(AVCodecContext *ctx, const enum AVPixelFormat *pix_fmts)
+{
+    const enum AVPixelFormat *p;
+    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
+        if (*p == AV_PIX_FMT_VASTAPI)
+            return *p;
+    }
+
+    fprintf(stderr, "Unable to decode this file using VASTAPI.\n");
+    return AV_PIX_FMT_NONE;
+}
+
+static int set_hwframe_ctx(AVCodecContext *ctx, AVBufferRef *hw_device_ctx, struct option_t *input_params, int flag)
+{
+    AVBufferRef       *hw_frames_ref = NULL;
+    AVHWFramesContext *frames_ctx    = NULL;
+    int                ret           = 0;
+
+    if (!(hw_frames_ref = av_hwframe_ctx_alloc(hw_device_ctx))) {
+        fprintf(stderr, "Failed to create VASTAPI frame context.\n");
+        return -1;
+    }
+
+    frames_ctx = (AVHWFramesContext *)(hw_frames_ref->data);
+
+    if (strcmp(input_params->pixel_format, "yuv420p") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_YUV420P;
+    else if (strcmp(input_params->pixel_format, "nv12") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_NV12;
+    else if (strcmp(input_params->pixel_format, "nv21") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_NV21;
+    else if (strcmp(input_params->pixel_format, "rgb") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_RGB0;
+    else if (strcmp(input_params->pixel_format, "yuv420p10le") == 0)
+        frames_ctx->sw_format = AV_PIX_FMT_YUV420P10LE;
+    else
+        frames_ctx->sw_format = AV_PIX_FMT_NONE;
+
+    frames_ctx->format            = AV_PIX_FMT_VASTAPI;
+    frames_ctx->width             = ctx->width;
+    frames_ctx->height            = ctx->height;
+    frames_ctx->initial_pool_size = 32;
+    frames_ctx->frame_buffer_flag = flag;
+
+    if ((ret = av_hwframe_ctx_init(hw_frames_ref)) < 0) {
+        fprintf(stderr, "Failed to initialize VASTAPI frame context. Error code: %s\n", av_err2str(ret));
+        av_buffer_unref(&hw_frames_ref);
+        return ret;
+    }
+
+    ctx->hw_frames_ctx = av_buffer_ref(hw_frames_ref);
+    if (!ctx->hw_frames_ctx)
+        ret = AVERROR(ENOMEM);
+
+    av_buffer_unref(&hw_frames_ref);
+    return ret;
+}
+
+static int decode_init(int chan, struct option_t *input_params)
+{
+    int           ret = 0, rawyuv = 0;
+    AVCodec      *decoder     = NULL;
+    AVStream     *video       = NULL;
+    AVDictionary *format_opts = NULL;
+    char         *fiename_in  = input_params->input;
+
+    rawyuv = strstr(fiename_in, ".yuv") || strstr(fiename_in, ".rgb");
+    if (rawyuv) {
+        av_dict_set(&format_opts, "video_size", input_params->video_size, 0);
+        av_dict_set(&format_opts, "pixel_format", input_params->pixel_format, 0);
+
+        if ((ret = avformat_open_input(&ifmt_ctx[chan], fiename_in, NULL, &format_opts)) < 0) {
+            fprintf(stderr, "Cannot open input file '%s', Error code: %s\n", fiename_in, av_err2str(ret));
+            goto fail;
+        }
+    } else {
+        if ((ret = avformat_open_input(&ifmt_ctx[chan], fiename_in, NULL, NULL)) < 0) {
+            fprintf(stderr, "Cannot open input file %s, Error code: %s\n", fiename_in, av_err2str(ret));
+            goto fail;
+        }
+    }
+
+    if ((ret = avformat_find_stream_info(ifmt_ctx[chan], NULL)) < 0) {
+        fprintf(stderr, "Cannot find input stream information. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+    if ((ret = av_find_best_stream(ifmt_ctx[chan], AVMEDIA_TYPE_VIDEO, -1, -1, &decoder, 0)) < 0) {
+        fprintf(stderr, "Cannot find a video stream in the input file. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+    video_stream[chan] = ret;
+
+#ifndef FFMPEG_N26
+    if (!(decoder_ctx[chan] = avcodec_alloc_context3(decoder))) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+#endif
+
+    video     = ifmt_ctx[chan]->streams[video_stream[chan]];
+    ist[chan] = video;
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    decoder_ctx[chan] = video->codec;
+    av_opt_set_int(decoder_ctx[chan], "refcounted_frames", 1, 0);
+#else
+    if ((ret = avcodec_parameters_to_context(decoder_ctx[chan], video->codecpar)) < 0) {
+        fprintf(stderr, "avcodec_parameters_to_context error. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+#endif
+
+    ret = av_hwdevice_ctx_create(&hw_device_ctx[chan], AV_HWDEVICE_TYPE_VASTAPI, input_params->render, NULL, 0);
+    if (ret < 0) {
+        fprintf(stderr, "Failed to create a VASTAPI device. Error code: %s\n", av_err2str(ret));
+        return -1;
+    }
+
+    if (!(decoder_ctx[chan]->hw_device_ctx = av_buffer_ref(hw_device_ctx[chan]))) {
+        fprintf(stderr, "A hardware device reference create failed.\n");
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    decoder_ctx[chan]->get_format = get_vastapi_format;
+    decoder_ctx[chan]->framerate  = av_guess_frame_rate(ifmt_ctx[chan], video, NULL);
+
+    if ((ret = avcodec_open2(decoder_ctx[chan], decoder, NULL)) < 0) {
+        fprintf(stderr, "Failed to open codec for decoding. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+#ifdef FFMPEG_N311
+    decoder_ctx[chan]->get_buffer2 = get_vast_buffer;
+#endif
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+    set_hwframe_ctx(decoder_ctx[chan], hw_device_ctx[chan], input_params, 1);
+#else
+    set_hwframe_ctx(decoder_ctx[chan], hw_device_ctx[chan], input_params, 0);
+#endif
+
+    return 0;
+
+fail:
+    if (decoder_ctx[chan]) {
+#ifdef FFMPEG_N26
+        avcodec_close(decoder_ctx[chan]);
+#else
+        avcodec_free_context(&decoder_ctx[chan]);
+#endif
+        decoder_ctx[chan] = NULL;
+    }
+
+    if (ifmt_ctx[chan])
+        avformat_close_input(&ifmt_ctx[chan]);
+
+    return ret;
+}
+
+static int set_user_profile(int *profile, char **cmd_profile, char *encoder_name)
+{
+    if (*cmd_profile == NULL) {
+        return 0;
+    }
+
+    if (strcmp(encoder_name, "h264_vastapi") == 0) {
+        if (strcmp(*cmd_profile, "main") == 0) {
+            *profile = FF_PROFILE_H264_MAIN;
+        } else if (strcmp(*cmd_profile, "baseline") == 0) {
+            *profile = FF_PROFILE_H264_CONSTRAINED_BASELINE;
+        } else if (strcmp(*cmd_profile, "high") == 0) {
+            *profile = FF_PROFILE_H264_HIGH;
+        } else if (strcmp(*cmd_profile, "high10") == 0) {
+            *profile = FF_PROFILE_H264_HIGH_10;
+        }
+    } else if (strcmp(encoder_name, "hevc_vastapi") == 0) {
+        if (strcmp(*cmd_profile, "main") == 0) {
+            *profile = FF_PROFILE_HEVC_MAIN;
+        } else if (strcmp(*cmd_profile, "main10") == 0) {
+            *profile = FF_PROFILE_HEVC_MAIN_10;
+        }
+        printf("hevc_vastapi profile only can set main\n");
+    } else if (strcmp(encoder_name, "av1_vastapi") == 0) {
+        if (strcmp(*cmd_profile, "main") == 0) {
+            *profile = FF_PROFILE_AV1_MAIN;
+        }
+        printf("av1_vastapi profile only can set main\n");
+    } else {
+        printf("warnning: encoder set error!\n");
+    }
+
+    return 0;
+}
+
+static int encode_init(int chan, struct option_t *input_params)
+{
+    int      ret                             = 0;
+    AVCodec *enc_codec                       = NULL;
+    char    *cp                              = NULL;
+    char    *fiename_out                     = input_params->output;
+    char     fiename_out_prefix[MAX_STR_LEN] = { 0 };
+    char     filename_out_chn[MAX_STR_LEN]   = { 0 };
+
+    if (input_params->save) {
+        cp = strstr(fiename_out, ".");
+        if (NULL == cp)
+            cp = fiename_out;
+        strncpy(fiename_out_prefix, fiename_out, cp - fiename_out);
+
+        if (!strcmp(input_params->encoder, "mjpeg_vastapi")) {
+            sprintf(filename_out_chn, "%s_%d_%%4d%s", fiename_out_prefix, chan, cp);
+        } else {
+            sprintf(filename_out_chn, "%s_%d%s", fiename_out_prefix, chan, cp);
+        }
+
+        input_params->output_file = filename_out_chn;
+        printf("================ output file: %s %s================\n", input_params->output_file, filename_out_chn);
+
+        if ((ret = (avformat_alloc_output_context2(&ofmt_ctx[chan], NULL, NULL, input_params->output_file))) < 0) {
+            fprintf(stderr, "Failed to deduce output format from file extension. Error code: %s\n", av_err2str(ret));
+            goto fail;
+        }
+
+        if (strcmp(input_params->encoder, "mjpeg_vastapi")) {
+            if ((ret = avio_open(&ofmt_ctx[chan]->pb, input_params->output_file, AVIO_FLAG_WRITE)) < 0) {
+                fprintf(stderr, "Cannot open output file. Error code: %s\n", av_err2str(ret));
+                goto fail;
+            }
+        }
+    } else {
+        AVOutputFormat *fmt = av_guess_format("null", NULL, NULL);
+        if (!fmt) {
+            fprintf(stderr, "Could not find null muxer.\n");
+            return -1;
+        }
+
+        // 分配AVFormatContext
+        ofmt_ctx[chan] = avformat_alloc_context();
+        if (!ofmt_ctx[chan]) {
+            fprintf(stderr, "Failed to alloc output format.\n");
+            return AVERROR_UNKNOWN;
+        }
+
+        // 设置输出格式
+        ofmt_ctx[chan]->oformat = fmt;
+    }
+
+    if (!(enc_codec = avcodec_find_encoder_by_name(input_params->encoder))) {
+        fprintf(stderr, "Could not find encoder '%s'\n", input_params->encoder);
+        ret = AVERROR(ENOENT);
+        goto fail;
+    }
+
+    if (!(encoder_ctx[chan] = avcodec_alloc_context3(enc_codec))) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    encoder_ctx[chan]->pix_fmt  = AV_PIX_FMT_VASTAPI;
+    encoder_ctx[chan]->width    = decoder_ctx[chan]->width;
+    encoder_ctx[chan]->height   = decoder_ctx[chan]->height;
+    encoder_ctx[chan]->bit_rate = input_params->bitrate;
+    encoder_ctx[chan]->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
+    encoder_ctx[chan]->get_format = get_vastapi_format;
+
+    if (input_params->vfr_fps) {
+        double     max_fps = input_params->fps > input_params->vfr_fps ? input_params->fps : input_params->vfr_fps;
+        AVRational max_framerate = av_d2q(max_fps, 4096);
+
+        encoder_ctx[chan]->time_base = av_inv_q(max_framerate);
+        encoder_ctx[chan]->framerate = max_framerate;
+        start_duration[chan]         = (double)AV_TIME_BASE / av_q2d(max_framerate);
+    } else {
+        if (input_params->fps) {
+            encoder_ctx[chan]->time_base = av_inv_q(input_params->frame_rate);
+            encoder_ctx[chan]->framerate = input_params->frame_rate;
+        } else {
+            encoder_ctx[chan]->time_base = av_inv_q(decoder_ctx[chan]->framerate);
+            encoder_ctx[chan]->framerate = decoder_ctx[chan]->framerate;
+            printf("encoder's time_base & framerate use decoder's\n");
+        }
+    }
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    av_opt_set_int(encoder_ctx[chan], "refcounted_frames", 1, 0);
+#endif
+
+    if (input_params->level)
+        encoder_ctx[chan]->level = input_params->level;
+
+    if (input_params->vast_params)
+        av_opt_set(encoder_ctx[chan]->priv_data, "vast-params", input_params->vast_params, 0);
+
+    if (set_user_profile(&encoder_ctx[chan]->profile, &input_params->profile, input_params->encoder) < 0) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    encoder_ctx[chan]->hw_device_ctx = av_buffer_ref(hw_device_ctx[chan]);
+    if (!encoder_ctx[chan]->hw_device_ctx) {
+        fprintf(stderr, "A hardware device reference create failed.\n");
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+#endif
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+    if ((ret = set_hwframe_ctx(encoder_ctx[chan], hw_device_ctx[chan], input_params, 1)) < 0)
+#else
+    if ((ret = set_hwframe_ctx(encoder_ctx[chan], hw_device_ctx[chan], input_params, 0)) < 0)
+#endif
+    {
+        fprintf(stderr, "Failed to set hwframe context.\n");
+        goto fail;
+    }
+
+    if (!encoder_ctx[chan]->hw_frames_ctx) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    if ((ret = avcodec_open2(encoder_ctx[chan], enc_codec, NULL)) < 0) {
+        fprintf(stderr, "Failed to open encode codec. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    if (!(ost[chan] = avformat_new_stream(ofmt_ctx[chan], NULL)))
+#else
+    if (!(ost[chan] = avformat_new_stream(ofmt_ctx[chan], enc_codec)))
+#endif
+    {
+        fprintf(stderr, "Failed to allocate stream for output format.\n");
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    ost[chan]->time_base      = encoder_ctx[chan]->time_base;
+    ost[chan]->duration       = av_rescale_q(ist[chan]->duration, ist[chan]->time_base, ost[chan]->time_base);
+    ost[chan]->avg_frame_rate = encoder_ctx[chan]->framerate;
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    if ((ret = avcodec_copy_context(ost[chan]->codec, encoder_ctx[chan])) < 0)
+#else
+    if ((ret = avcodec_parameters_from_context(ost[chan]->codecpar, encoder_ctx[chan])) < 0)
+#endif
+    {
+        fprintf(stderr, "Failed to copy the stream parameters. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+    /* write the stream header */
+    if ((ret = avformat_write_header(ofmt_ctx[chan], NULL)) < 0) {
+        fprintf(stderr, "Error while writing stream header. Error code: %s\n", av_err2str(ret));
+        goto fail;
+    }
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    if ((ret = encoder_ctx[chan]->codec->init(encoder_ctx[chan])) < 0) {
+        fprintf(stderr, "init encoder failed. Error code: %d\n", ret);
+        goto fail;
+    }
+
+    av_buffer_unref(&ost[chan]->codec->hw_frames_ctx);
+#endif
+
+    return 0;
+
+fail:
+    if (encoder_ctx[chan]) {
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+        avcodec_close(encoder_ctx[chan]);
+#endif
+
+        avcodec_free_context(&encoder_ctx[chan]);
+        encoder_ctx[chan] = NULL;
+    }
+
+    if (ofmt_ctx[chan]) {
+        avio_closep(&ofmt_ctx[chan]->pb);
+        avformat_close_input(&ofmt_ctx[chan]);
+        ofmt_ctx[chan] = NULL;
+    }
+
+    return ret;
+}
+
+//打开输入输出文件，获取信息，找到decoder和encoder，初始化decoder_ctx和encoder_ctx，打开decoder和encoder。
+static int init_dec_enc(int chan, struct option_t *input_params)
+{
+    int ret = 0;
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    av_register_all();
+#endif
+
+    if ((ret = decode_init(chan, input_params)) < 0) {
+        fprintf(stderr, "Init decode failed. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+
+    if ((ret = encode_init(chan, input_params)) < 0) {
+        fprintf(stderr, "Init encode failed. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+
+    return 0;
+}
+
+static int flush_encoder(int chan, struct option_t *input_params)
+{
+    int      ret     = 0;
+    int      inc     = 0;
+    int      err     = 0;
+    AVPacket enc_pkt = { 0 };
+    int      rawyuv  = strstr(input_params->input, ".yuv") || strstr(input_params->input, ".rgb");
+
+    av_init_packet(&enc_pkt);
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+    enc_pkt.pts  = 0;
+    for (;;) {
+        while ((ret = avcodec_receive_packet(encoder_ctx[chan], &enc_pkt)) == AVERROR(EAGAIN)) {
+            int send_ret = avcodec_send_frame(encoder_ctx[chan], NULL);
+            if (send_ret < 0) {
+                return send_ret;
+            }
+        }
+
+        if (ret < 0 || (ret == AVERROR_EOF && enc_pkt.size == 0)) {
+            return ret;
+        }
+
+        enc_pkt.stream_index = 0;
+
+        if (rawyuv) {
+            if (input_params->vfr_fps) {
+                printf("bbout pts=%ld, dts=%ld\n", enc_pkt.pts, enc_pkt.dts);
+
+                enc_pkt.pts =
+                    av_rescale_q(enc_pkt.pts, encoder_ctx[chan]->time_base, ofmt_ctx[chan]->streams[0]->time_base);
+                enc_pkt.dts =
+                    av_rescale_q(enc_pkt.dts, encoder_ctx[chan]->time_base, ofmt_ctx[chan]->streams[0]->time_base);
+            } else {
+                enc_pkt.pts = enc_pkt.dts = enc_frame_cnt[chan] * ofmt_ctx[chan]->streams[0]->time_base.den /
+                                            ofmt_ctx[chan]->streams[0]->time_base.num /
+                                            (encoder_ctx[chan]->framerate.num / encoder_ctx[chan]->framerate.den);
+            }
+        } else {
+            if ((!input_params->vfr_fps) && (strcmp(input_params->encoder, "av1_vastapi") != 0))
+                av_packet_rescale_ts(&enc_pkt, ifmt_ctx[chan]->streams[video_stream[chan]]->time_base,
+                                     ofmt_ctx[chan]->streams[0]->time_base);
+        }
+        if ((err = av_interleaved_write_frame(ofmt_ctx[chan], &enc_pkt)) < 0) {
+            fprintf(stderr, "Error during writing data to output file. Error code: %s line: %d\n", av_err2str(err),
+                    __LINE__);
+            return err;
+        }
+
+        enc_frame_cnt[chan]++;
+        if (ret == AVERROR_EOF) {
+            break;
+        }
+    }
+    return ret;
+}
+
+static int encode_write(AVFrame *frame, int chan, struct option_t *input_params)
+{
+    int      ret     = 0;
+    int      inc     = 0;
+    AVPacket enc_pkt = { 0 };
+    int      rawyuv  = strstr(input_params->input, ".yuv") || strstr(input_params->input, ".rgb");
+
+    av_init_packet(&enc_pkt);
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+    enc_pkt.pts  = 0;
+
+    if (frame && input_params->vfr_fps) {
+        if (!(frame_cnt[chan] / 100 % 2) && frame_cnt[chan] % 100 >= 0) {
+            frame->pkt_duration = (double)AV_TIME_BASE / input_params->vfr_fps;
+            if (frame_cnt[chan] ==
+                (int)(input_params->fps > input_params->vfr_fps ? input_params->vfr_fps : input_params->fps)) {
+                frame->pkt_duration = (double)AV_TIME_BASE / av_q2d(input_params->frame_rate);
+            }
+        } else {
+            frame->pkt_duration = (double)AV_TIME_BASE / av_q2d(input_params->frame_rate);
+        }
+
+        inc              = (int)((double)frame->pkt_duration / start_duration[chan] + 0.5);
+        frame->pts       = frame_pts[chan] + inc;
+        frame->time_base = AV_TIME_BASE_Q;
+
+        if (frame_cnt[chan] == 1) {
+            frame->pts = 0;
+        }
+
+        frame_pts[chan] = frame->pts;
+    }
+
+#ifdef FFMPEG_N26
+    int got_frame = 0;
+#else
+    if ((ret = avcodec_send_frame(encoder_ctx[chan], frame)) < 0) {
+        if (ret != AVERROR_EOF)
+            fprintf(stderr, "Error during encoding. Error code: %d %s\n", ret, av_err2str(ret));
+        goto end;
+    }
+#endif
+
+    while (1) {
+#ifdef FFMPEG_N26
+        if ((ret = avcodec_encode_video2(encoder_ctx[chan], &enc_pkt, frame, &got_frame)) < 0)
+#else
+        if ((ret = avcodec_receive_packet(encoder_ctx[chan], &enc_pkt)) < 0)
+#endif
+        {
+            goto end;
+        }
+
+#ifndef RESET_TEST
+        if (frame_cnt[chan] == input_params->frame_cnt + 1) {
+            printf("finish frame encode, count: %d\n", frame_cnt[chan]);
+            ret = -1;
+            break;
+        }
+#endif
+#ifdef FFMPEG_N26
+        if (!got_frame) {
+            printf("&got_frame=%p, got_frame:%d\n", &got_frame, got_frame);
+            return 0;
+        }
+
+        if (enc_pkt.data) {
+            enc_pkt.data += ret;
+            enc_pkt.size -= ret;
+        }
+#endif
+
+        enc_pkt.stream_index = 0;
+
+        if (rawyuv) {
+            if (input_params->vfr_fps) {
+                enc_pkt.pts =
+                    av_rescale_q(enc_pkt.pts, encoder_ctx[chan]->time_base, ofmt_ctx[chan]->streams[0]->time_base);
+                enc_pkt.dts =
+                    av_rescale_q(enc_pkt.dts, encoder_ctx[chan]->time_base, ofmt_ctx[chan]->streams[0]->time_base);
+            } else {
+                enc_pkt.pts = enc_pkt.dts = enc_frame_cnt[chan] * ofmt_ctx[chan]->streams[0]->time_base.den /
+                                            ofmt_ctx[chan]->streams[0]->time_base.num /
+                                            (encoder_ctx[chan]->framerate.num / encoder_ctx[chan]->framerate.den);
+            }
+        } else {
+            if ((!input_params->vfr_fps) && (strcmp(input_params->encoder, "av1_vastapi") != 0))
+                av_packet_rescale_ts(&enc_pkt, ifmt_ctx[chan]->streams[video_stream[chan]]->time_base,
+                                     ofmt_ctx[chan]->streams[0]->time_base);
+        }
+
+        if ((ret = av_interleaved_write_frame(ofmt_ctx[chan], &enc_pkt)) < 0) {
+            fprintf(stderr, "Error during writing data to output file. Error code: %s line: %d\n", av_err2str(ret),
+                    __LINE__);
+            return ret;
+        }
+
+        enc_frame_cnt[chan]++;
+
+#ifdef FFMPEG_N26
+        return 0;
+#endif
+
+#ifdef RESET_TEST
+        // if (enc_frame_cnt[chan] == input_params->frame_cnt) {
+        //     printf("finish frame encode, count: %d\n", enc_frame_cnt[chan]);
+        //     ret = -1;
+        //     break;
+        // }
+#endif
+    }
+
+end:
+    ret = ((ret == AVERROR(EAGAIN)) ? 0 : ret);
+    return ret;
+}
+
+#ifdef RESET_TEST
+// vastai reset
+static int process_reset(int chan, struct option_t *input_params)
+{
+    int ret = 0;
+
+    printf("chan %d reset frame_cnt=%d, input_cnt=%d\n", chan, frame_cnt[chan], input_cnt[chan]);
+
+    // while (1) {
+    //     if ((ret = encode_write(NULL, chan, input_params)) < 0) {
+    //         if (ret != AVERROR_EOF)
+    //             fprintf(stderr, "Error during flush encoding and writing. %d %s\n", ret, av_err2str(ret));
+    //         break;
+    //     }
+    // }
+    ret = flush_encoder(chan, input_params);
+
+    encoder_ctx[chan]->width  = decoder_ctx[chan]->width;
+    encoder_ctx[chan]->height = decoder_ctx[chan]->height;
+
+    ret = avcodec_vastapi_reset_flush(encoder_ctx[chan]);
+    return ret;
+}
+#endif
+
+static int dec_enc(AVPacket *pkt, int chan, int rawyuv, struct option_t *input_params)
+{
+    int      ret          = 0;
+    Usrdata  da1          = { 0 };
+    AVFrame *hw_frame_dec = NULL;
+    AVFrame *hw_frame_enc = NULL;
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+    uint64_t frame_addr;
+#endif
+
+    da1.chn    = chan;
+    da1.cnt    = cnt[chan];
+    da1.endflg = 0;
+
+#if !defined FFMPEG_N26 && !defined FFMPEG_N311
+    if ((ret = avcodec_send_packet(decoder_ctx[chan], pkt)) < 0) {
+        fprintf(stderr, "Error during decoding. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+#endif
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+    int got_frame = 1;
+
+    while (pkt->size > 0 || (!pkt->data && got_frame))
+#else
+    while (ret >= 0)
+#endif
+    {
+        if (!(da1.frame = av_frame_alloc()))
+            return AVERROR(ENOMEM);
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+        ret = avcodec_decode_video2(decoder_ctx[chan], da1.frame, &got_frame, pkt);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF || got_frame <= 0)
+#else
+        ret = avcodec_receive_frame(decoder_ctx[chan], da1.frame);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+#endif
+        {
+            av_frame_free(&da1.frame);
+            return 0;
+        } else if (ret < 0) {
+            fprintf(stderr, "Error while decoding. Error code: %s\n", av_err2str(ret));
+            goto fail;
+        }
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+        if (pkt->data) {
+            pkt->data += ret;
+            pkt->size -= ret;
+        }
+#endif
+
+        da1.hw_frame_dec     = NULL;
+        da1.frame->pict_type = AV_PICTURE_TYPE_NONE;
+        cnt[chan]++;
+        input_cnt[chan]++;
+
+        if (rawyuv) {
+            if (!(hw_frame_dec = av_frame_alloc())) {
+                fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+                return AVERROR(ENOMEM);
+            }
+
+            if ((ret = av_hwframe_get_buffer(decoder_ctx[chan]->hw_frames_ctx, hw_frame_dec, 0)) < 0) {
+                fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+                goto fail;
+            }
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+            uint64_t addr = EXTERNAL_BUFFER_START_ADDR + (cnt[chan] % 200) * 10 * 1024 * 1024;
+            av_hwframe_set_addr_to_surfaceid(hw_frame_dec, addr);
+#endif
+
+            if ((ret = av_hwframe_transfer_data(hw_frame_dec, da1.frame, 0)) < 0) {
+                fprintf(stderr, "Failed to transfer frame data to surface, Error: %s.\n", av_err2str(ret));
+                goto fail;
+            }
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+            ret = av_hwframe_get_addr_from_surfaceid(hw_frame_dec, &frame_addr);
+
+            if (!(hw_frame_enc = av_frame_alloc())) {
+                fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+                ret = AVERROR(ENOMEM);
+                goto fail;
+            }
+
+            if ((ret = av_hwframe_get_buffer(encoder_ctx[chan]->hw_frames_ctx, hw_frame_enc, 0)) < 0) {
+                fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+                goto fail;
+            }
+            printf("hw frame add 0x%lx\n", frame_addr);
+            av_hwframe_set_addr_to_surfaceid(hw_frame_enc, frame_addr);
+
+            da1.hw_frame_dec = hw_frame_dec; // if free hw_frame_dec here, yuv buffer may be released.
+#else
+            hw_frame_enc = hw_frame_dec;
+#endif
+            av_frame_free(&da1.frame);
+            da1.frame = hw_frame_enc;
+        }
+
+        av_hwframe_sync_surface(da1.frame);
+
+        en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+        if (decode_num[chan]++ == input_params->frame_cnt - 1) {
+            printf("finish process dec, count: %d\n", decode_num[chan]);
+            // ret = -1;
+            decode_end[chan] = 1;
+            // break;
+        }
+    fail:
+        if (ret < 0)
+            return ret;
+    }
+
+    return 0;
+}
+
+#ifdef VASTAI_AVFRAME_TEST
+/* Read yuv data to AVFrame from file directly */
+static int dec_enc_test_avframe(struct option_t *input_params, int chan)
+{
+    int                ret = 0, i = 0;
+    FILE              *fd;
+    AVHWFramesContext *frames_ctx = (AVHWFramesContext *)(encoder_ctx[chan]->hw_frames_ctx->data);
+    AVFrame           *hw_frame;
+    AVFrame           *dma_frame[4];
+    VastFrameInfo      info;
+
+    fd = fopen(input_params->input, "r+");
+
+    info.format = frames_ctx->sw_format;
+    info.width  = frames_ctx->width;
+    info.height = frames_ctx->height;
+
+    for (i = 0; i < DMA_BUFFER_NUM_MAX; i++) {
+        dma_frame[i] = av_frame_alloc_vastai(encoder_ctx[chan]->hw_frames_ctx, &info);
+    }
+
+    while (feof(fd) == 0) {
+        Usrdata da1;
+        da1.chn    = chan;
+        da1.cnt    = cnt[chan];
+        da1.endflg = 0;
+        da1.frame  = dma_frame[cnt[chan] % DMA_BUFFER_NUM_MAX];
+
+        cnt[chan]++;
+
+        if (!(hw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+            return AVERROR(ENOMEM);
+        }
+
+        if ((ret = av_hwframe_get_buffer(encoder_ctx[chan]->hw_frames_ctx, hw_frame, 0)) < 0) {
+            fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+            av_frame_free(&hw_frame);
+            return -1;
+        }
+
+        int plane_number = 0;
+        int src_linesizes[3];
+        src_linesizes[0] = frames_ctx->width;
+        if (da1.frame->format == AV_PIX_FMT_YUV420P) {
+            plane_number     = 3;
+            src_linesizes[1] = frames_ctx->width / 2;
+            src_linesizes[2] = frames_ctx->width / 2;
+        } else if (da1.frame->format == AV_PIX_FMT_NV12) {
+            plane_number     = 2;
+            src_linesizes[1] = frames_ctx->width;
+            src_linesizes[2] = 0;
+        } else {
+            fprintf(stderr, "%s Unsupported format: %d.\n", __func__, da1.frame->format);
+            return -1;
+        }
+
+        int height = da1.frame->height;
+        int plane  = 0;
+        for (; plane < plane_number; plane++) {
+            uint8_t *dst          = da1.frame->data[plane];
+            int      dst_linesize = da1.frame->linesize[plane];
+            int      src_linesize = src_linesizes[plane];
+            int      tmp_height;
+            tmp_height = plane > 0 ? height / 2 : height;
+            for (; tmp_height > 0; tmp_height--) {
+                ret = fread(dst, src_linesize, 1, fd);
+                if (!ret) {
+                    av_frame_free(&hw_frame);
+                    goto fail;
+                }
+                dst += dst_linesize;
+            }
+        }
+
+        if ((ret = av_hwframe_transfer_data(hw_frame, da1.frame, 0)) < 0) {
+            fprintf(stderr, "Failed to transfer frame data to surface, Error: %s.\n", av_err2str(ret));
+            av_frame_free(&da1.frame);
+            return -1;
+        }
+
+        da1.frame = hw_frame;
+
+        en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+    }
+
+fail:
+    for (i = 0; i < DMA_BUFFER_NUM_MAX; i++) {
+        av_frame_free(&dma_frame[i]);
+    }
+
+    fclose(fd);
+
+    return 0;
+}
+#endif
+
+#ifdef DMABUFFER_FD_ENCODE_TEST
+static int get_dmabuffer_fd()
+{
+    return 0;
+}
+
+static int dec_enc_test_dmabuffer(struct option_t *input_params, int chan)
+{
+    int                ret = 0, i = 0;
+    FILE              *fd;
+    AVHWFramesContext *frames_ctx = (AVHWFramesContext *)(encoder_ctx[chan]->hw_frames_ctx->data);
+    AVFrame           *hw_frame, *src_frame;
+    VastFrameInfo      info;
+    int                dmabuffer_fd = 0;
+
+    fd = fopen(input_params->input, "r+");
+
+    while (feof(fd) == 0) {
+        Usrdata da1;
+        da1.chn    = chan;
+        da1.cnt    = cnt[chan];
+        da1.endflg = 0;
+
+        cnt[chan]++;
+
+        // prepare hw frame
+        if (!(hw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Cannot alloc hardware frame. Error: %s.\n", av_err2str(ret));
+            return AVERROR(ENOMEM);
+        }
+
+        if ((ret = av_hwframe_get_buffer(encoder_ctx[chan]->hw_frames_ctx, hw_frame, 0)) < 0) {
+            fprintf(stderr, "Failed to get hw frame buffer, Error: %s.\n", av_err2str(ret));
+            av_frame_free(&hw_frame);
+            return -1;
+        }
+
+        // prepare src frame from dmabuffer fd
+        src_frame = av_frame_alloc();
+        if (!src_frame) {
+            av_log(frames_ctx, "%s %d Cannot alloc src frame. Error: %s.\n", __func__, __LINE__);
+            return AVERROR(ENOMEM);
+        }
+
+        dmabuffer_fd      = get_dmabuffer_fd();
+        src_frame->opaque = (void *)&dmabuffer_fd;
+
+        // transfer dmabuffer data to device
+        if ((ret = av_hwframe_transfer_data_ex(hw_frame, src_frame, INPUT_TYPE_FD)) < 0) {
+            av_log(frames_ctx, "%s %d failed to transfer data to device: %d.\n", __func__, __LINE__, ret);
+            av_frame_free(&src_frame);
+            av_frame_free(&hw_frame);
+            return -1;
+        }
+
+        da1.frame = hw_frame;
+
+        en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+    }
+
+fail:
+    fclose(fd);
+
+    return 0;
+}
+#endif
+
+// 编码-transcoding 子线程
+static void *process_enc(void *arg)
+{
+    int                 chan = 0, ret = 0;
+    struct thread_info *ti           = (struct thread_info *)arg;
+    struct option_t    *input_params = (struct option_t *)ti->handle;
+    chan                             = ti->thread_chn;
+
+    while (1) {
+        Usrdata *dap;
+        dap = read_queue((void *)queue_g[chan]);
+        if (!dap->endflg)
+            frame_cnt[chan]++;
+
+        if (input_params->enable_idr) {
+            if (dap->frame && frame_cnt[chan] % 20 == 0)
+                dap->frame->pict_type = AV_PICTURE_TYPE_I;
+        }
+
+        if (input_params->enable_dynamic_bitrate) {
+            if (frame_cnt[chan] % 20 == 0 && dap->frame) {
+                AVFrameSideData *br_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATE_VASTAI_BITRATE_EXT1);
+                br_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATE_VASTAI_BITRATE_EXT1, sizeof(uint32_t) * 3);
+                if (br_side) {
+                    uint32_t *data = (uint32_t *)br_side->data;
+                    data[0]        = (frame_cnt[chan] + 8001) % 2000; // target bitrate, kbps
+                    data[1]        = 0; // vbvMaxrate,  kbps, need set to 0 if use default;
+                    data[2]        = 0; // hrd bufsize, kbps, need set to 0 if use default;
+                }
+            }
+        }
+
+        if (input_params->enable_dynamic_fps) {
+            if (frame_cnt[chan] % 100 == 0 && dap->frame) {
+                AVFrameSideData *fr_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_VASTAI_FRAMERATE);
+                fr_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_VASTAI_FRAMERATE, sizeof(uint32_t));
+                if (fr_side) {
+                    uint32_t *data = (uint32_t *)fr_side->data;
+                    data[0]        = 60; // target bitrate, kbps
+                }
+            }
+        }
+
+        if (input_params->crf) {
+            if (dap->frame) {
+                AVFrameSideData *crf_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_VASTAI_CRF);
+                crf_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_VASTAI_CRF, 2 * sizeof(int32_t));
+                if (crf_side) {
+                    int32_t *data = (int32_t *)crf_side->data;
+                    data[0]       = input_params->crf + (frame_cnt[chan] % 2) * 20; // change crf every frames
+                    data[1]       = frame_cnt[chan] / 100 % 2;                      // crf rc reset
+                }
+            }
+        }
+
+        if (input_params->enable_dynamic_keyint) {
+            if (frame_cnt[chan] % 100 == 0 && dap->frame) {
+                AVFrameSideData *fr_side = NULL;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_VASTAI_KEYINT);
+                fr_side = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_VASTAI_KEYINT, sizeof(uint32_t));
+                if (fr_side) {
+                    uint32_t *data = (uint32_t *)fr_side->data;
+                    data[0]        = (frame_cnt[chan] / 100 % 10) * 10; // target keyint
+                }
+            }
+        }
+
+        if (input_params->enable_sei) {
+            if (dap->frame != NULL) {
+                int              index;
+                uint8_t         *buffer    = NULL;
+                AVFrameSideData *side_data = NULL;
+                struct timeval   tv;
+                uint64_t         encode_start_ms;
+                av_frame_remove_side_data(dap->frame, AV_FRAME_DATA_UDU_SEI);
+
+                for (index = 0; index < SEI_COUNT; index++) {
+                    side_data = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_UDU_SEI, SEI_BUFFER_SIZE);
+                    if (!side_data) {
+                        fprintf(stderr, "failed to create new side data\n");
+                        return NULL;
+                    }
+
+                    buffer = side_data->data;
+                    memcpy(buffer, encode_h264_sei_appdata_uuid[index % 2],
+                           sizeof(encode_h264_sei_appdata_uuid[index % 2]));
+                    buffer += sizeof(encode_h264_sei_appdata_uuid[index % 2]);
+
+                    memcpy(buffer, &frame_cnt[chan], sizeof(frame_cnt[chan]));
+                    buffer += sizeof(frame_cnt[chan]);
+
+                    gettimeofday(&tv, NULL);
+                    encode_start_ms = tv.tv_sec * 1000 + tv.tv_usec / 1000;
+                    memcpy(buffer, &encode_start_ms, sizeof(encode_start_ms));
+                    buffer += sizeof(encode_start_ms);
+                }
+            }
+        }
+
+        if (input_params->enable_roi) {
+            if (dap->frame != NULL) {
+                int32_t roimap_value[3] = { -31, 31, 0 };
+                int32_t roimap_index;
+                int     x = 0, y = 0;
+                roimap_index = (frame_cnt[chan] / 10) % 3;
+                // static int32_t roimap_last_value = 0;
+
+                // if(roimap_value[roimap_index] != roimap_last_value)
+                {
+                    AVFrameSideData *side_data = NULL;
+
+                    uint32_t width, height;
+                    uint32_t roimap_block_unit;
+                    uint32_t blksize;
+                    uint32_t roiwidth, roiheight, roimap_size;
+                    uint8_t *buffer = NULL;
+
+                    char *p;
+                    width = strtol(input_params->video_size, (void *)&p, 10);
+                    if (*p)
+                        p++;
+                    height = strtol(p, (void *)&p, 10);
+
+                    p                 = strstr(input_params->vast_params, "roiMapDeltaQpBlockUnit");
+                    p                 = strchr(p, '=');
+                    roimap_block_unit = atoi(p + 1);
+
+                    blksize     = 64 >> (roimap_block_unit & 3);
+                    roiwidth    = (width + blksize - 1) / blksize;
+                    roiheight   = (height + blksize - 1) / blksize;
+                    roimap_size = roiwidth * roiheight;
+
+                    if (!side_data) {
+                        side_data = av_frame_new_side_data(dap->frame, AV_FRAME_DATA_ROIMAP, roimap_size);
+                        if (!side_data) {
+                            fprintf(stderr, "failed to create new roimap side data\n");
+                            return NULL;
+                        }
+                    }
+
+                    buffer = side_data->data;
+                    memset(buffer, 0, roiwidth * roiheight);
+                    for (y = 0; y < roiheight / 3; y++) {
+                        for (x = 0; x < roiwidth / 2; x++) {
+                            buffer[y * roiwidth + x] = -roimap_value[roimap_index];
+                        }
+                    }
+
+                    for (y = roiheight / 3; y < roiheight; y++) {
+                        for (x = 3 * roiwidth / 4; x < roiwidth; x++) {
+                            buffer[y * roiwidth + x] = roimap_value[roimap_index];
+                        }
+                    }
+                    // roimap_last_value = roimap_value[roimap_index];
+                }
+            }
+        }
+
+#ifdef RESET_TEST
+        if (input_params->enable_reset_resolution) {
+            if (frame_cnt[chan] == input_params->reset_frame_num + 1) {
+                printf("chan %d will reset resolution\n", chan);
+                if ((ret = process_reset(chan, input_params))) {
+                    fprintf(stderr, "process_reset error. %d %s\n", ret, av_err2str(ret));
+                    thread_end[chan] = 1;
+                }
+            }
+        }
+#endif
+
+        if (dap->frame) {
+            if ((ret = encode_write(dap->frame, chan, input_params)) < 0) {
+                if (ret != AVERROR_EOF) {
+                    fprintf(stderr, "Error during encoding and writing. %d %s\n", ret, av_err2str(ret));
+                    thread_end[chan] = 1;
+                }
+            }
+        }
+
+        av_frame_free(&dap->frame);
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+        if (dap->hw_frame_dec)
+            av_frame_free(&dap->hw_frame_dec);
+#endif
+
+        de_queue((void *)queue_g[chan]);
+
+        if (dap->endflg == 1 || thread_end[chan]) {
+            printf("chan %d here will end -------------------\n", chan);
+
+            // flush encoder
+            // while (1) {
+            //     if ((ret = encode_write(NULL, chan, input_params)) < 0) {
+            //         if (ret != AVERROR_EOF)
+            //             fprintf(stderr, "Error during flush encoding and writing. %d %s\n", ret, av_err2str(ret));
+            //         break;
+            //     }
+            // }
+            ret = flush_encoder(chan, input_params);
+            av_write_trailer(ofmt_ctx[chan]);
+
+            if (thread_end[chan]) {
+                do {
+                    de_queue((void *)queue_g[chan]);
+                } while (!is_empty((void *)queue_g[chan]));
+            }
+
+            printf("chan %d transcode success! total frame_cnt %d, cnt %d\n", chan, frame_cnt[chan], cnt[chan]);
+
+            break;
+        }
+    }
+
+    return NULL;
+}
+
+// 解码-transcoding 子线程
+static void *process_dec(void *arg)
+{
+    int                 chan         = 0;
+    int                 ret          = 0;
+    AVPacket            dec_pkt      = { 0 };
+    Usrdata             da1          = { 0 };
+    struct thread_info *ti           = (struct thread_info *)arg;
+    struct option_t    *input_params = (struct option_t *)ti->handle;
+    char               *fiename_in   = input_params->input;
+    int                 rawyuv       = 0;
+
+#ifdef RESET_TEST
+    int rawyuv_in2 = 0;
+#endif
+
+    rawyuv = (strstr(fiename_in, ".yuv") || strstr(fiename_in, ".rgb")) ? 1 : 0;
+    chan   = ti->thread_chn;
+
+    if (thread_end[chan])
+        return NULL;
+
+        /* read all packets and only transcoding video */
+#ifdef VASTAI_AVFRAME_TEST
+    dec_enc_test_avframe(input_params, chan);
+#elif defined DMABUFFER_FD_ENCODE_TEST
+    dec_enc_test_dmabuffer(input_params, chan);
+#else
+    while (ret >= 0 && !thread_end[chan] && !decode_end[chan]) {
+#ifdef RESET_TEST
+        if (input_params->enable_reset_resolution) {
+            if (input_cnt[chan] == input_params->reset_frame_num) {
+                AVDictionary *format_opts = NULL;
+                char         *fiename_in2 = input_params->reset_input;
+                AVStream     *video       = NULL;
+                AVCodec      *decoder     = NULL;
+
+                printf("chan=%d encode reset w x h\n", chan);
+
+                rawyuv_in2 = strstr(fiename_in2, ".yuv") || strstr(fiename_in2, ".rgb");
+                if (rawyuv_in2) {
+                    av_dict_set(&format_opts, "video_size", input_params->reset_video_size, 0);
+                    av_dict_set(&format_opts, "pixel_format", input_params->pixel_format, 0);
+
+                    if ((ret = avformat_open_input(&ifmt_ctx2[chan], fiename_in2, NULL, &format_opts)) < 0) {
+                        fprintf(stderr, "Cannot open input file '%s', Error code: %s\n", fiename_in2, av_err2str(ret));
+                        break;
+                    }
+                } else {
+                    if ((ret = avformat_open_input(&ifmt_ctx2[chan], fiename_in2, NULL, NULL)) < 0) {
+                        fprintf(stderr, "Cannot open input file %s, Error code: %s\n", fiename_in2, av_err2str(ret));
+                        break;
+                    }
+                }
+
+                if ((ret = avformat_find_stream_info(ifmt_ctx2[chan], NULL)) < 0) {
+                    fprintf(stderr, "Cannot find input stream information. Error code: %s\n", av_err2str(ret));
+                    break;
+                }
+
+                if ((ret = av_find_best_stream(ifmt_ctx2[chan], AVMEDIA_TYPE_VIDEO, -1, -1, &decoder, 0)) < 0) {
+                    fprintf(stderr, "Cannot find a video stream in the input file. Error code: %s\n", av_err2str(ret));
+                    break;
+                }
+
+                video                     = ifmt_ctx2[chan]->streams[video_stream[chan]];
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+                decoder_ctx[chan]->width  = video->codec->width;
+                decoder_ctx[chan]->height = video->codec->height;
+#else
+                decoder_ctx[chan]->width  = video->codecpar->width;
+                decoder_ctx[chan]->height = video->codecpar->height;
+#endif
+
+#ifdef EXTERNA_BUFFER_ENCODE_TEST
+                set_hwframe_ctx(decoder_ctx[chan], hw_device_ctx[chan], input_params, 1);
+#else
+                set_hwframe_ctx(decoder_ctx[chan], hw_device_ctx[chan], input_params, 0);
+#endif
+            }
+
+            if ((ret = av_read_frame(ifmt_ctx[chan], &dec_pkt)) < 0 ||
+                input_cnt[chan] >= input_params->reset_frame_num) {
+                if ((ret = av_read_frame(ifmt_ctx2[chan], &dec_pkt)) < 0) {
+                    if (loop[chan]) {
+                        avio_closep(&ofmt_ctx[chan]->pb);
+
+                        if ((ret = avio_open(&ofmt_ctx[chan]->pb, input_params->output_file, AVIO_FLAG_WRITE)) < 0) {
+                            fprintf(stderr, "Cannot open output file. Error code: %s\n", av_err2str(ret));
+                            break;
+                        }
+
+                        if (loop[chan] == -1)
+                            loop[chan] = 0;
+
+                        printf("thread %d looping %d................................ \n", chan, loop[chan]);
+                        loop[chan]--;
+
+                        av_seek_frame(ifmt_ctx[chan], video_stream[chan], 0, AVSEEK_FLAG_BYTE);
+
+                        if ((ret = av_read_frame(ifmt_ctx[chan], &dec_pkt)) < 0) {
+                            fprintf(stderr, "looping fail!!!\n");
+                            break;
+                        }
+                    } else {
+                        break;
+                    }
+                }
+            }
+        } else
+#endif
+        {
+            if ((ret = av_read_frame(ifmt_ctx[chan], &dec_pkt)) < 0) {
+                if (loop[chan]) {
+                    // avio_closep(&ofmt_ctx[chan]->pb);
+
+                    // if ((ret = avio_open(&ofmt_ctx[chan]->pb, input_params->output_file, AVIO_FLAG_WRITE)) < 0) {
+                    //     fprintf(stderr, "Cannot open output file. Error code: %s\n", av_err2str(ret));
+                    //     break;
+                    // }
+
+                    if (loop[chan] == -1)
+                        loop[chan] = 0;
+
+                    printf("thread %d looping %d................................ \n", chan, loop[chan]);
+                    loop[chan]--;
+
+                    av_seek_frame(ifmt_ctx[chan], video_stream[chan], 0, AVSEEK_FLAG_BYTE);
+
+                    if ((ret = av_read_frame(ifmt_ctx[chan], &dec_pkt)) < 0) {
+                        fprintf(stderr, "looping fail!!!\n");
+                        break;
+                    }
+                } else {
+                    break;
+                }
+            }
+        }
+
+        if (video_stream[chan] == dec_pkt.stream_index)
+            ret = dec_enc(&dec_pkt, chan, rawyuv, input_params);
+
+        av_packet_unref(&dec_pkt);
+    }
+
+    /* flush decoder */
+    dec_pkt.data = NULL;
+    dec_pkt.size = 0;
+    ret          = dec_enc(&dec_pkt, chan, rawyuv, input_params);
+
+    av_packet_unref(&dec_pkt);
+#endif
+
+    da1.chn    = chan;
+    da1.cnt    = cnt[chan];
+    da1.endflg = 1;
+    da1.frame  = NULL;
+
+    en_queue((void *)queue_g[chan], (void *)&da1, sizeof(Usrdata));
+
+    return NULL;
+}
+
+static int transcode(struct option_t *input_params)
+{
+    int                ret                        = 0;
+    int                chan                       = 0; // 线程号
+    int                thread_sum                 = input_params->thread_num;
+    struct thread_info usrarg_enc[MAX_THREAD_NUM] = { 0 };
+    struct thread_info usrarg_dec[MAX_THREAD_NUM] = { 0 };
+
+    // 初始化变量
+    for (chan = 0; chan < thread_sum; chan++) {
+        ifmt_ctx[chan]      = NULL;
+        ofmt_ctx[chan]      = NULL;
+        decoder_ctx[chan]   = NULL;
+        encoder_ctx[chan]   = NULL;
+        video_stream[chan]  = -1;
+        cnt[chan]           = 0;
+        queue_g[chan]       = init_queue();
+        thread_end[chan]    = 0;
+        loop[chan]          = input_params->loop;
+        frame_pts[chan]     = 0;
+        frame_cnt[chan]     = 0;
+        enc_frame_cnt[chan] = 0;
+        input_cnt[chan]     = 0;
+    }
+
+    for (chan = 0; chan < thread_sum; chan++) {
+        if ((ret = init_dec_enc(chan, input_params)) < 0) {
+            printf("init dec and enc error! %d\n", ret);
+            return ret;
+        }
+
+        usrarg_dec[chan].thread_chn = chan;
+        usrarg_dec[chan].thread_id  = chan;
+        usrarg_dec[chan].handle     = input_params;
+        if ((pthread_create(&usrarg_dec[chan].thread_id, NULL, process_dec, (void *)&usrarg_dec[chan])) == -1) {
+            printf("create process dec error!\n");
+            return -1;
+        }
+
+        usrarg_enc[chan].thread_chn = chan;
+        usrarg_enc[chan].thread_id  = chan;
+        usrarg_enc[chan].handle     = input_params;
+        if ((pthread_create(&usrarg_enc[chan].thread_id, NULL, process_enc, (void *)&usrarg_enc[chan])) == -1) {
+            printf("create process enc error!\n");
+            return -1;
+        }
+    }
+
+    for (chan = 0; chan < thread_sum; chan++) {
+        pthread_join(usrarg_dec[chan].thread_id, NULL);
+        pthread_join(usrarg_enc[chan].thread_id, NULL);
+    }
+
+    for (chan = 0; chan < thread_sum; chan++) {
+        destroy_queue((void *)queue_g[chan]);
+
+        if (ofmt_ctx[chan]->pb)
+            avio_closep(&ofmt_ctx[chan]->pb);
+
+#if defined FFMPEG_N26 || defined FFMPEG_N311
+        avcodec_close(decoder_ctx[chan]);
+        avcodec_close(encoder_ctx[chan]);
+        avformat_close_input(&ifmt_ctx[chan]);
+        avformat_close_input(&ofmt_ctx[chan]);
+        avcodec_free_context(&encoder_ctx[chan]);
+#else
+        avformat_close_input(&ifmt_ctx[chan]);
+        avformat_close_input(&ofmt_ctx[chan]);
+        avcodec_free_context(&decoder_ctx[chan]);
+        avcodec_free_context(&encoder_ctx[chan]);
+#endif
+
+        decoder_ctx[chan] = NULL;
+        encoder_ctx[chan] = NULL;
+        ifmt_ctx[chan]    = NULL;
+        ofmt_ctx[chan]    = NULL;
+        thread_end[chan]  = 1;
+        frame_pts[chan]   = 0;
+        frame_cnt[chan]   = 0;
+
+        av_buffer_unref(&hw_device_ctx[chan]); // 释放硬件资源
+    }
+
+    return 0;
+}
+
+static void usage(const char *program)
+{
+    fprintf(stderr, "\nUsage: %s [options]\n", program);
+    fprintf(stderr, "\n");
+    fprintf(stderr, "\t-i    input video file.  e.g. "
+                    "/video-case/video_xiaoling/test_encode/BQTerrace_yuv420p_1920x1080_60_50.yuv\n");
+    fprintf(stderr, "\t-o    output video file. e.g. /home/xiaoling/video/out.h264\n");
+    fprintf(stderr, "\t-r    render node.       e.g. /dev/vastai_video0\n");
+    fprintf(stderr, "\t-f    encode fps.        e.g. 30.0\n");
+    fprintf(stderr, "\t-b    encode bitrate.    e.g. 2000000\n");
+    fprintf(stderr, "\t-s    input video size.  e.g. 1920x1080\n");
+    fprintf(stderr, "\t-e    encoder.           e.g. h264_vastapi\n");
+    fprintf(stderr, "\t-p    encode profile.    e.g. main\n");
+    fprintf(stderr, "\t-l    encode levle.      e.g. 1.0\n");
+    fprintf(stderr, "\t-t    thread cnt.        default 1, max 32\n");
+    fprintf(stderr, "\t-n    number of actual transcoding frames.   default -1, means end of file\n");
+    fprintf(stderr, "\t-c    run count.         default 1\n");
+    fprintf(stderr, "\t-d    enable AV_LOG_DEBUG\n");
+
+    fprintf(stderr, "\t--vast_params        encode params\n");
+    fprintf(stderr, "\t--pix_fmt            input video pixel format.       e.g. nv12\n");
+    fprintf(stderr, "\t--loop               loop count.                     default 0, -1 means infinite loop\n");
+    fprintf(stderr, "\t--vfr                vfr interval.                   default 0(disenable)\n");
+    fprintf(stderr, "\t--crf                crf value.                      default 0(disenable)\n");
+    fprintf(stderr, "\t--reset              enable reset encode resolution. default 0(disenable)\n");
+    fprintf(stderr, "\t--reset_input        reset input file\n");
+    fprintf(stderr, "\t--reset_size         reset input file video size.    e.g. 1920x1080\n");
+    fprintf(stderr, "\t--reset_num          reset input file's total frame num\n");
+    fprintf(stderr, "\t--roi                enable roi.                     default 0(disenable)\n");
+    fprintf(stderr, "\t--sei                enable sei.                     default 0(disenable)\n");
+    fprintf(stderr, "\t--idr                enable idr.                     default 0(disenable)\n");
+    fprintf(stderr, "\t--dynamic_bitrate    enable dynamic bitrate.         default 0(disenable)\n");
+    fprintf(stderr, "\t--dynamic_fps        enable dynamic fps.             default 0(disenable)\n");
+    fprintf(stderr, "\t--dynamic_keyint     enable dynamic keyint.          default 0(disenable)\n");
+    fprintf(stderr, "\t--save               save file.                      default 1(enable)\n");
+    fprintf(stderr, "\t--help               help manuals\n");
+}
+
+static int parse_options(int argc, char **argv, struct option_t *input_params)
+{
+    static const char    optstr[]       = "i:o:r:f:b:s:e:p:n:l:c:t:d";
+    static struct option long_options[] = { { "vast_params", required_argument, 0, 0 },
+                                            { "pix_fmt", required_argument, 0, 0 },
+                                            { "loop", required_argument, 0, 0 },
+                                            { "vfr", required_argument, 0, 0 },
+                                            { "crf", required_argument, 0, 0 },
+                                            { "reset", required_argument, 0, 0 },
+                                            { "reset_input", required_argument, 0, 0 },
+                                            { "reset_size", required_argument, 0, 0 },
+                                            { "reset_num", required_argument, 0, 0 },
+                                            { "roi", required_argument, 0, 0 },
+                                            { "sei", required_argument, 0, 0 },
+                                            { "idr", required_argument, 0, 0 },
+                                            { "dynamic_bitrate", required_argument, 0, 0 },
+                                            { "dynamic_fps", required_argument, 0, 0 },
+                                            { "dynamic_keyint", required_argument, 0, 0 },
+                                            { "save", required_argument, 0, 0 },
+                                            { "help", no_argument, 0, 'h' },
+                                            { 0, 0, 0, 0 } };
+
+    int c = 0, option_index = 0;
+
+    /* Formerly, initialization of getopt depended on optind==0,
+    which causes problems with re-calling getopt as programs generally don't know that. */
+    optind = 0;
+
+    while ((c = getopt_long(argc, argv, optstr, long_options, &option_index)) != -1) {
+        switch (c) {
+        case 0:
+            if (optarg && strcmp(long_options[option_index].name, "vast_params") == 0) {
+                input_params->vast_params = optarg;
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "pix_fmt") == 0) {
+                input_params->pixel_format = optarg;
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "loop") == 0) {
+                input_params->loop = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "vfr") == 0) {
+                input_params->vfr_fps = atof(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "crf") == 0) {
+                input_params->crf = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "reset") == 0) {
+                input_params->enable_reset_resolution = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "reset_input") == 0) {
+                input_params->reset_input = optarg;
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "reset_size") == 0) {
+                input_params->reset_video_size = optarg;
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "reset_num") == 0) {
+                input_params->reset_frame_num = atof(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "roi") == 0) {
+                input_params->enable_roi = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "sei") == 0) {
+                input_params->enable_sei = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "idr") == 0) {
+                input_params->enable_idr = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "dynamic_bitrate") == 0) {
+                input_params->enable_dynamic_bitrate = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "dynamic_fps") == 0) {
+                input_params->enable_dynamic_fps = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "dynamic_keyint") == 0) {
+                input_params->enable_dynamic_keyint = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            } else if (optarg && strcmp(long_options[option_index].name, "save") == 0) {
+                input_params->save = atoi(optarg);
+                printf("========= %s with args %s\n", long_options[option_index].name, optarg);
+            }
+
+            break;
+        case 'i':
+            input_params->input = optarg;
+            printf("========= %c with args %s\n", c, input_params->input);
+            break;
+        case 'o':
+            input_params->output = optarg;
+            printf("========= %c with args %s\n", c, input_params->output);
+            break;
+        case 'r':
+            input_params->render = optarg;
+            printf("========= %c with args %s\n", c, input_params->render);
+            break;
+        case 'f':
+            input_params->fps        = atof(optarg);
+            input_params->frame_rate = av_d2q(input_params->fps, 4096);
+            printf("========= %c with args %f %d\n", c, input_params->fps, input_params->frame_rate.num);
+            break;
+        case 'b':
+            input_params->bitrate = atoi(optarg);
+            printf("========= %c with args %d\n", c, input_params->bitrate);
+            break;
+        case 's':
+            input_params->video_size = optarg;
+            printf("========= %c with args %s\n", c, input_params->video_size);
+            break;
+        case 'e':
+            input_params->encoder = optarg;
+            printf("========= %c with args %s\n", c, input_params->encoder);
+            break;
+        case 'p':
+            input_params->profile = optarg;
+            printf("========= %c with args %s\n", c, input_params->profile);
+            break;
+        case 'l':
+            input_params->level = atof(optarg);
+            printf("========= %c with args %f\n", c, input_params->level);
+            break;
+        case 't':
+            input_params->thread_num = atoi(optarg);
+            printf("========= %c with args %d\n", c, input_params->thread_num);
+            break;
+        case 'n':
+            input_params->frame_cnt = atoi(optarg);
+            printf("========= %c with args %d\n", c, input_params->frame_cnt);
+            break;
+        case 'c':
+            input_params->count = atoi(optarg);
+            printf("========= %c with args %s\n", c, optarg);
+            break;
+        case 'd':
+            av_log_set_level(AV_LOG_DEBUG);
+            printf("========= %c enable debug log\n", c);
+            break;
+        case 'h':
+            usage(argv[0]);
+            return -1;
+        case '?':
+        default:
+            printf("  unsupported option %c\n", c);
+            usage(argv[0]);
+            return -1;
+        }
+    }
+
+    if (optind < argc) {
+        usage(argv[0]);
+        return -1;
+    }
+
+    return 0;
+}
+
+static void set_default_params(struct option_t *input_params)
+{
+    input_params->input                   = "/video-case/video_xiaoling/test_filter/test_yuv420p_1280x720_25.yuv";
+    input_params->output                  = "/home/xiaoling/video/out.h264";
+    input_params->render                  = NULL;
+    input_params->fps                     = 30.0;
+    input_params->frame_rate              = av_d2q(input_params->fps, 4096);
+    input_params->bitrate                 = 5000000;
+    input_params->encoder                 = "h264_vastapi";
+    input_params->video_size              = "1280x720";
+    input_params->pixel_format            = "yuv420p";
+    input_params->vast_params             = NULL;
+    input_params->profile                 = NULL;
+    input_params->level                   = 0.0;
+    input_params->thread_num              = 1;
+    input_params->frame_cnt               = -1;
+    input_params->loop                    = 0;
+    input_params->count                   = 1;
+    input_params->save                    = 1;
+    input_params->vfr_fps                 = 0;
+    input_params->enable_roi              = 0;
+    input_params->enable_sei              = 0;
+    input_params->enable_idr              = 0;
+    input_params->enable_dynamic_bitrate  = 0;
+    input_params->enable_dynamic_fps      = 0;
+    input_params->enable_dynamic_keyint   = 0;
+    input_params->crf                     = 0;
+    input_params->enable_reset_resolution = 0;
+    input_params->reset_input             = "/video-case/video4.3/jctvc/ParkScene_1920x1080_24.yuv";
+    input_params->reset_video_size        = "1920x1080";
+    input_params->reset_frame_num         = 200;
+}
+
+int main(int argc, char **argv)
+{
+    int             ret          = 0;
+    struct option_t input_params = { 0 };
+
+    set_default_params(&input_params);
+
+    if ((ret = parse_options(argc, argv, &input_params)) < 0) {
+        printf("parse_options failed\n");
+        return ret;
+    }
+
+    int count = input_params.count;
+
+    while (!ret && count) {
+        ret = transcode(&input_params);
+        count--;
+        printf("-------- remain count = %d, ret %d --------\n\n", count, ret);
+    }
+
+    return ret;
+}
diff --git a/ffbuild/version.sh b/ffbuild/version.sh
index edc4dd3..e0b5904 100755
--- a/ffbuild/version.sh
+++ b/ffbuild/version.sh
@@ -7,7 +7,7 @@ if ! test "$revision"; then
     if (cd "$1" && grep git RELEASE 2> /dev/null >/dev/null) ; then
         revision=$(cd "$1" && git describe --tags --match N 2> /dev/null)
     else
-        revision=$(cd "$1" && git describe --tags --always 2> /dev/null)
+        revision=$(cd "$1" && git describe --tags --always --long 2> /dev/null)
     fi
 fi
 
diff --git a/fftools/ffmpeg.c b/fftools/ffmpeg.c
old mode 100644
new mode 100755
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index 9c820ab..2e42a2d 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -563,6 +563,21 @@ static int opt_qsv_device(void *optctx, const char *opt, const char *arg)
 }
 #endif
 
+#if CONFIG_VASTAPI
+static int opt_vastapi_device(void *optctx, const char *opt, const char *arg)
+{
+    const char *prefix = "vastapi:";
+    char *tmp;
+    int err;
+    tmp = av_asprintf("%s%s", prefix, arg);
+    if (!tmp)
+        return AVERROR(ENOMEM);
+    err = hw_device_init_from_string(tmp, NULL);
+    av_free(tmp);
+    return err;
+}
+#endif
+
 static int opt_init_hw_device(void *optctx, const char *opt, const char *arg)
 {
     if (!strcmp(arg, "list")) {
@@ -3886,6 +3901,11 @@ const OptionDef options[] = {
         "set VAAPI hardware device (DRM path or X11 display name)", "device" },
 #endif
 
+#if CONFIG_VASTAPI
+    { "vastapi_device", HAS_ARG | OPT_EXPERT, { .func_arg = opt_vastapi_device },
+        "set VASTAPI hardware device (DRM path or X11 display name)", "device" },
+#endif
+
 #if CONFIG_QSV
     { "qsv_device", HAS_ARG | OPT_EXPERT, { .func_arg = opt_qsv_device },
         "set QSV hardware device (DirectX adapter index, DRM path or X11 display name)", "device"},
diff --git a/libavcodec/Makefile b/libavcodec/Makefile
index 3adf153..b2ed6b4 100644
--- a/libavcodec/Makefile
+++ b/libavcodec/Makefile
@@ -149,6 +149,7 @@ OBJS-$(CONFIG_TEXTUREDSP)              += texturedsp.o
 OBJS-$(CONFIG_TEXTUREDSPENC)           += texturedspenc.o
 OBJS-$(CONFIG_TPELDSP)                 += tpeldsp.o
 OBJS-$(CONFIG_VAAPI_ENCODE)            += vaapi_encode.o
+OBJS-$(CONFIG_VASTAPI_ENCODE)          += vastapi_encode.o
 OBJS-$(CONFIG_VC1DSP)                  += vc1dsp.o
 OBJS-$(CONFIG_VIDEODSP)                += videodsp.o
 OBJS-$(CONFIG_VP3DSP)                  += vp3dsp.o
@@ -387,6 +388,7 @@ OBJS-$(CONFIG_H264_QSV_DECODER)        += qsvdec.o
 OBJS-$(CONFIG_H264_QSV_ENCODER)        += qsvenc_h264.o
 OBJS-$(CONFIG_H264_RKMPP_DECODER)      += rkmppdec.o
 OBJS-$(CONFIG_H264_VAAPI_ENCODER)      += vaapi_encode_h264.o h264_levels.o
+OBJS-$(CONFIG_H264_VASTAPI_ENCODER)    += vastapi_encode_h264.o h264_levels.o
 OBJS-$(CONFIG_H264_VIDEOTOOLBOX_ENCODER) += videotoolboxenc.o
 OBJS-$(CONFIG_H264_V4L2M2M_DECODER)    += v4l2_m2m_dec.o
 OBJS-$(CONFIG_H264_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
@@ -408,6 +410,8 @@ OBJS-$(CONFIG_HEVC_QSV_ENCODER)        += qsvenc_hevc.o hevc_ps_enc.o       \
                                           hevc_data.o
 OBJS-$(CONFIG_HEVC_RKMPP_DECODER)      += rkmppdec.o
 OBJS-$(CONFIG_HEVC_VAAPI_ENCODER)      += vaapi_encode_h265.o h265_profile_level.o
+OBJS-$(CONFIG_HEVC_VASTAPI_ENCODER)    += vastapi_encode_h265.o h265_profile_level.o
+OBJS-$(CONFIG_AV1_VASTAPI_ENCODER)     += vastapi_encode_av1.o
 OBJS-$(CONFIG_HEVC_V4L2M2M_DECODER)    += v4l2_m2m_dec.o
 OBJS-$(CONFIG_HEVC_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
 OBJS-$(CONFIG_HEVC_VIDEOTOOLBOX_ENCODER) += videotoolboxenc.o
@@ -465,6 +469,7 @@ OBJS-$(CONFIG_MJPEGB_DECODER)          += mjpegbdec.o
 OBJS-$(CONFIG_MJPEG_CUVID_DECODER)     += cuviddec.o
 OBJS-$(CONFIG_MJPEG_QSV_ENCODER)       += qsvenc_jpeg.o
 OBJS-$(CONFIG_MJPEG_VAAPI_ENCODER)     += vaapi_encode_mjpeg.o
+OBJS-$(CONFIG_MJPEG_VASTAPI_ENCODER)   += vastapi_encode_mjpeg.o
 OBJS-$(CONFIG_MLP_DECODER)             += mlpdec.o mlpdsp.o
 OBJS-$(CONFIG_MLP_ENCODER)             += mlpenc.o mlp.o
 OBJS-$(CONFIG_MMVIDEO_DECODER)         += mmvideo.o
@@ -935,6 +940,7 @@ OBJS-$(CONFIG_D3D11VA)                    += dxva2.o
 OBJS-$(CONFIG_DXVA2)                      += dxva2.o
 OBJS-$(CONFIG_NVDEC)                      += nvdec.o
 OBJS-$(CONFIG_VAAPI)                      += vaapi_decode.o
+OBJS-$(CONFIG_VASTAPI)                    += vastapi_decode.o
 OBJS-$(CONFIG_VIDEOTOOLBOX)               += videotoolbox.o
 OBJS-$(CONFIG_VDPAU)                      += vdpau.o
 
@@ -942,6 +948,7 @@ OBJS-$(CONFIG_AV1_D3D11VA_HWACCEL)        += dxva2_av1.o
 OBJS-$(CONFIG_AV1_DXVA2_HWACCEL)          += dxva2_av1.o
 OBJS-$(CONFIG_AV1_NVDEC_HWACCEL)          += nvdec_av1.o
 OBJS-$(CONFIG_AV1_VAAPI_HWACCEL)          += vaapi_av1.o
+OBJS-$(CONFIG_AV1_VASTAPI_HWACCEL)        += vastapi_av1.o
 OBJS-$(CONFIG_H263_VAAPI_HWACCEL)         += vaapi_mpeg4.o
 OBJS-$(CONFIG_H263_VIDEOTOOLBOX_HWACCEL)  += videotoolbox.o
 OBJS-$(CONFIG_H264_D3D11VA_HWACCEL)       += dxva2_h264.o
@@ -949,6 +956,7 @@ OBJS-$(CONFIG_H264_DXVA2_HWACCEL)         += dxva2_h264.o
 OBJS-$(CONFIG_H264_NVDEC_HWACCEL)         += nvdec_h264.o
 OBJS-$(CONFIG_H264_QSV_HWACCEL)           += qsvdec.o
 OBJS-$(CONFIG_H264_VAAPI_HWACCEL)         += vaapi_h264.o
+OBJS-$(CONFIG_H264_VASTAPI_HWACCEL)       += vastapi_h264.o
 OBJS-$(CONFIG_H264_VDPAU_HWACCEL)         += vdpau_h264.o
 OBJS-$(CONFIG_H264_VIDEOTOOLBOX_HWACCEL)  += videotoolbox.o
 OBJS-$(CONFIG_HEVC_D3D11VA_HWACCEL)       += dxva2_hevc.o
@@ -956,9 +964,11 @@ OBJS-$(CONFIG_HEVC_DXVA2_HWACCEL)         += dxva2_hevc.o
 OBJS-$(CONFIG_HEVC_NVDEC_HWACCEL)         += nvdec_hevc.o
 OBJS-$(CONFIG_HEVC_QSV_HWACCEL)           += qsvdec.o
 OBJS-$(CONFIG_HEVC_VAAPI_HWACCEL)         += vaapi_hevc.o h265_profile_level.o
+OBJS-$(CONFIG_HEVC_VASTAPI_HWACCEL)       += vastapi_hevc.o h265_profile_level.o
 OBJS-$(CONFIG_HEVC_VDPAU_HWACCEL)         += vdpau_hevc.o h265_profile_level.o
 OBJS-$(CONFIG_MJPEG_NVDEC_HWACCEL)        += nvdec_mjpeg.o
 OBJS-$(CONFIG_MJPEG_VAAPI_HWACCEL)        += vaapi_mjpeg.o
+OBJS-$(CONFIG_MJPEG_VASTAPI_HWACCEL)      += vastapi_mjpeg.o
 OBJS-$(CONFIG_MPEG1_NVDEC_HWACCEL)        += nvdec_mpeg12.o
 OBJS-$(CONFIG_MPEG1_VDPAU_HWACCEL)        += vdpau_mpeg12.o
 OBJS-$(CONFIG_MPEG1_VIDEOTOOLBOX_HWACCEL) += videotoolbox.o
@@ -1227,6 +1237,7 @@ SKIPHEADERS-$(CONFIG_QSV)              += qsv.h qsv_internal.h
 SKIPHEADERS-$(CONFIG_QSVENC)           += qsvenc.h
 SKIPHEADERS-$(CONFIG_XVMC)             += xvmc.h
 SKIPHEADERS-$(CONFIG_VAAPI)            += vaapi_decode.h vaapi_hevc.h vaapi_encode.h
+SKIPHEADERS-$(CONFIG_VASTAPI)          += vastapi_decode.h vastapi_encode.h
 SKIPHEADERS-$(CONFIG_VDPAU)            += vdpau.h vdpau_internal.h
 SKIPHEADERS-$(CONFIG_VIDEOTOOLBOX)     += videotoolbox.h vt_internal.h
 SKIPHEADERS-$(CONFIG_V4L2_M2M)         += v4l2_buffers.h v4l2_context.h v4l2_m2m.h
diff --git a/libavcodec/allcodecs.c b/libavcodec/allcodecs.c
index d1e1019..0019f93 100644
--- a/libavcodec/allcodecs.c
+++ b/libavcodec/allcodecs.c
@@ -813,6 +813,10 @@ extern const AVCodec ff_h264_omx_encoder;
 extern const AVCodec ff_h264_qsv_encoder;
 extern const AVCodec ff_h264_v4l2m2m_encoder;
 extern const AVCodec ff_h264_vaapi_encoder;
+extern const AVCodec ff_h264_vastapi_encoder;
+extern const AVCodec ff_hevc_vastapi_encoder;
+extern const AVCodec ff_av1_vastapi_encoder;
+extern const AVCodec ff_mjpeg_vastapi_encoder;
 extern const AVCodec ff_h264_videotoolbox_encoder;
 extern const AVCodec ff_hevc_amf_encoder;
 extern const AVCodec ff_hevc_cuvid_decoder;
diff --git a/libavcodec/av1dec.c b/libavcodec/av1dec.c
index 09df2bf..4876ae8 100644
--- a/libavcodec/av1dec.c
+++ b/libavcodec/av1dec.c
@@ -437,6 +437,7 @@ static int get_pixel_format(AVCodecContext *avctx)
 #define HWACCEL_MAX (CONFIG_AV1_DXVA2_HWACCEL + \
                      CONFIG_AV1_D3D11VA_HWACCEL * 2 + \
                      CONFIG_AV1_NVDEC_HWACCEL + \
+                     CONFIG_AV1_VASTAPI_HWACCEL + \
                      CONFIG_AV1_VAAPI_HWACCEL)
     enum AVPixelFormat pix_fmts[HWACCEL_MAX + 2], *fmtp = pix_fmts;
 
@@ -516,6 +517,9 @@ static int get_pixel_format(AVCodecContext *avctx)
 #if CONFIG_AV1_VAAPI_HWACCEL
         *fmtp++ = AV_PIX_FMT_VAAPI;
 #endif
+#if CONFIG_AV1_VASTAPI_HWACCEL
+        *fmtp++ = AV_PIX_FMT_VASTAPI;
+#endif
         break;
     case AV_PIX_FMT_YUV420P10:
 #if CONFIG_AV1_DXVA2_HWACCEL
@@ -531,6 +535,9 @@ static int get_pixel_format(AVCodecContext *avctx)
 #if CONFIG_AV1_VAAPI_HWACCEL
         *fmtp++ = AV_PIX_FMT_VAAPI;
 #endif
+#if CONFIG_AV1_VASTAPI_HWACCEL
+        *fmtp++ = AV_PIX_FMT_VASTAPI;
+#endif
         break;
     case AV_PIX_FMT_GRAY8:
 #if CONFIG_AV1_NVDEC_HWACCEL
@@ -556,11 +563,13 @@ static int get_pixel_format(AVCodecContext *avctx)
      * Since now the av1 decoder doesn't support native decode, if it will be
      * implemented in the future, need remove this check.
      */
+    /*
     if (!avctx->hwaccel) {
         av_log(avctx, AV_LOG_ERROR, "Your platform doesn't suppport"
                " hardware accelerated AV1 decoding.\n");
         return AVERROR(ENOSYS);
     }
+    */
 
     avctx->pix_fmt = ret;
 
@@ -1257,6 +1266,9 @@ const AVCodec ff_av1_decoder = {
 #if CONFIG_AV1_VAAPI_HWACCEL
         HWACCEL_VAAPI(av1),
 #endif
+#if CONFIG_AV1_VASTAPI_HWACCEL
+        HWACCEL_VASTAPI(av1),
+#endif
         NULL
     },
 };
diff --git a/libavcodec/avcodec.h b/libavcodec/avcodec.h
old mode 100644
new mode 100755
index 7ee8bc2..15da6b3
--- a/libavcodec/avcodec.h
+++ b/libavcodec/avcodec.h
@@ -3148,8 +3148,20 @@ void av_fast_padded_mallocz(void *ptr, unsigned int *size, size_t min_size);
  */
 int avcodec_is_open(AVCodecContext *s);
 
-/**
- * @}
- */
+#if CONFIG_VASTAPI
+int avcodec_vastapi_reset_flush(const AVCodecContext *codec);//vastai reset
+/**
+ * psnr[4] and ssim[4] save Y,U,V,avg value.
+ * display_order save display order value for having B frame situation,
+ * IPPP situation is same with encoder order.
+ * lookahead_size is for 2pass situation, 1pass lookahead_size=0.
+ */
+typedef struct PsnrSsimInfo {
+    double psnr[4];
+    double ssim[4];
+    int display_order;
+} PsnrSsimInfo;
+int avcodec_vastapi_get_psnr(const AVCodecContext *avctx, int lookahead_size, PsnrSsimInfo *info);//vastai get psnr/ssim api
+#endif
 
 #endif /* AVCODEC_AVCODEC_H */
diff --git a/libavcodec/encode.c b/libavcodec/encode.c
old mode 100644
new mode 100755
diff --git a/libavcodec/h264_slice.c b/libavcodec/h264_slice.c
index c21004d..d33edfe 100644
--- a/libavcodec/h264_slice.c
+++ b/libavcodec/h264_slice.c
@@ -792,6 +792,7 @@ static enum AVPixelFormat get_pixel_format(H264Context *h, int force_callback)
                      (CONFIG_H264_D3D11VA_HWACCEL * 2) + \
                      CONFIG_H264_NVDEC_HWACCEL + \
                      CONFIG_H264_VAAPI_HWACCEL + \
+                     CONFIG_H264_VASTAPI_HWACCEL + \
                      CONFIG_H264_VIDEOTOOLBOX_HWACCEL + \
                      CONFIG_H264_VDPAU_HWACCEL)
     enum AVPixelFormat pix_fmts[HWACCEL_MAX + 2], *fmt = pix_fmts;
@@ -811,6 +812,9 @@ static enum AVPixelFormat get_pixel_format(H264Context *h, int force_callback)
             *fmt++ = AV_PIX_FMT_YUV420P9;
         break;
     case 10:
+#if CONFIG_H264_VASTAPI_HWACCEL
+        *fmt++ = AV_PIX_FMT_VASTAPI;
+#endif
 #if CONFIG_H264_VIDEOTOOLBOX_HWACCEL
         if (h->avctx->colorspace != AVCOL_SPC_RGB)
             *fmt++ = AV_PIX_FMT_VIDEOTOOLBOX;
@@ -881,6 +885,9 @@ static enum AVPixelFormat get_pixel_format(H264Context *h, int force_callback)
 #if CONFIG_H264_VAAPI_HWACCEL
             *fmt++ = AV_PIX_FMT_VAAPI;
 #endif
+#if CONFIG_H264_VASTAPI_HWACCEL
+            *fmt++ = AV_PIX_FMT_VASTAPI;
+#endif
             if (h->avctx->codec->pix_fmts)
                 choices = h->avctx->codec->pix_fmts;
             else if (h->avctx->color_range == AVCOL_RANGE_JPEG)
diff --git a/libavcodec/h264dec.c b/libavcodec/h264dec.c
index 6a5bf51..27014e7 100644
--- a/libavcodec/h264dec.c
+++ b/libavcodec/h264dec.c
@@ -1101,6 +1101,9 @@ const AVCodec ff_h264_decoder = {
 #if CONFIG_H264_VAAPI_HWACCEL
                                HWACCEL_VAAPI(h264),
 #endif
+#if CONFIG_H264_VASTAPI_HWACCEL
+                               HWACCEL_VASTAPI(h264),
+#endif
 #if CONFIG_H264_VDPAU_HWACCEL
                                HWACCEL_VDPAU(h264),
 #endif
diff --git a/libavcodec/hevcdec.c b/libavcodec/hevcdec.c
index 8d7a4f7..cbba9a5 100644
--- a/libavcodec/hevcdec.c
+++ b/libavcodec/hevcdec.c
@@ -397,6 +397,7 @@ static enum AVPixelFormat get_format(HEVCContext *s, const HEVCSPS *sps)
                      CONFIG_HEVC_D3D11VA_HWACCEL * 2 + \
                      CONFIG_HEVC_NVDEC_HWACCEL + \
                      CONFIG_HEVC_VAAPI_HWACCEL + \
+                     CONFIG_HEVC_VASTAPI_HWACCEL + \
                      CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL + \
                      CONFIG_HEVC_VDPAU_HWACCEL)
     enum AVPixelFormat pix_fmts[HWACCEL_MAX + 2], *fmt = pix_fmts;
@@ -414,6 +415,9 @@ static enum AVPixelFormat get_format(HEVCContext *s, const HEVCSPS *sps)
 #if CONFIG_HEVC_VAAPI_HWACCEL
         *fmt++ = AV_PIX_FMT_VAAPI;
 #endif
+#if CONFIG_HEVC_VASTAPI_HWACCEL
+        *fmt++ = AV_PIX_FMT_VASTAPI;
+#endif
 #if CONFIG_HEVC_VDPAU_HWACCEL
         *fmt++ = AV_PIX_FMT_VDPAU;
 #endif
@@ -435,6 +439,9 @@ static enum AVPixelFormat get_format(HEVCContext *s, const HEVCSPS *sps)
 #if CONFIG_HEVC_VAAPI_HWACCEL
         *fmt++ = AV_PIX_FMT_VAAPI;
 #endif
+#if CONFIG_HEVC_VASTAPI_HWACCEL
+        *fmt++ = AV_PIX_FMT_VASTAPI;
+#endif
 #if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL
         *fmt++ = AV_PIX_FMT_VIDEOTOOLBOX;
 #endif
@@ -461,6 +468,9 @@ static enum AVPixelFormat get_format(HEVCContext *s, const HEVCSPS *sps)
 #if CONFIG_HEVC_VAAPI_HWACCEL
        *fmt++ = AV_PIX_FMT_VAAPI;
 #endif
+#if CONFIG_HEVC_VASTAPI_HWACCEL
+       *fmt++ = AV_PIX_FMT_VASTAPI;
+#endif
 #if CONFIG_HEVC_VIDEOTOOLBOX_HWACCEL
         *fmt++ = AV_PIX_FMT_VIDEOTOOLBOX;
 #endif
@@ -3888,6 +3898,9 @@ const AVCodec ff_hevc_decoder = {
 #if CONFIG_HEVC_VAAPI_HWACCEL
                                HWACCEL_VAAPI(hevc),
 #endif
+#if CONFIG_HEVC_VASTAPI_HWACCEL
+                               HWACCEL_VASTAPI(hevc),
+#endif
 #if CONFIG_HEVC_VDPAU_HWACCEL
                                HWACCEL_VDPAU(hevc),
 #endif
diff --git a/libavcodec/hwaccels.h b/libavcodec/hwaccels.h
index 1e7b464..96a9de6 100644
--- a/libavcodec/hwaccels.h
+++ b/libavcodec/hwaccels.h
@@ -33,6 +33,10 @@ extern const AVHWAccel ff_h264_d3d11va2_hwaccel;
 extern const AVHWAccel ff_h264_dxva2_hwaccel;
 extern const AVHWAccel ff_h264_nvdec_hwaccel;
 extern const AVHWAccel ff_h264_vaapi_hwaccel;
+extern const AVHWAccel ff_h264_vastapi_hwaccel;
+extern const AVHWAccel ff_hevc_vastapi_hwaccel;
+extern const AVHWAccel ff_av1_vastapi_hwaccel;
+extern const AVHWAccel ff_mjpeg_vastapi_hwaccel;
 extern const AVHWAccel ff_h264_vdpau_hwaccel;
 extern const AVHWAccel ff_h264_videotoolbox_hwaccel;
 extern const AVHWAccel ff_hevc_d3d11va_hwaccel;
diff --git a/libavcodec/hwconfig.h b/libavcodec/hwconfig.h
index f421dc9..22b6dd3 100644
--- a/libavcodec/hwconfig.h
+++ b/libavcodec/hwconfig.h
@@ -72,6 +72,8 @@ typedef struct AVCodecHWConfigInternal {
     HW_CONFIG_HWACCEL(1, 1, 0, CUDA,         CUDA,         ff_ ## codec ## _nvdec_hwaccel)
 #define HWACCEL_VAAPI(codec) \
     HW_CONFIG_HWACCEL(1, 1, 1, VAAPI,        VAAPI,        ff_ ## codec ## _vaapi_hwaccel)
+#define HWACCEL_VASTAPI(codec) \
+    HW_CONFIG_HWACCEL(1, 1, 1, VASTAPI,      VASTAPI,      ff_ ## codec ## _vastapi_hwaccel)
 #define HWACCEL_VDPAU(codec) \
     HW_CONFIG_HWACCEL(1, 1, 1, VDPAU,        VDPAU,        ff_ ## codec ## _vdpau_hwaccel)
 #define HWACCEL_VIDEOTOOLBOX(codec) \
diff --git a/libavcodec/mjpegdec.c b/libavcodec/mjpegdec.c
index a735d23..91044d0 100644
--- a/libavcodec/mjpegdec.c
+++ b/libavcodec/mjpegdec.c
@@ -706,6 +706,9 @@ int ff_mjpeg_decode_sof(MJpegDecodeContext *s)
 #if CONFIG_MJPEG_VAAPI_HWACCEL
                 AV_PIX_FMT_VAAPI,
 #endif
+#if CONFIG_MJPEG_VASTAPI_HWACCEL
+                AV_PIX_FMT_VASTAPI,
+#endif
                 s->avctx->pix_fmt,
                 AV_PIX_FMT_NONE,
             };
@@ -3031,6 +3034,9 @@ const AVCodec ff_mjpeg_decoder = {
 #if CONFIG_MJPEG_VAAPI_HWACCEL
                         HWACCEL_VAAPI(mjpeg),
 #endif
+#if CONFIG_MJPEG_VASTAPI_HWACCEL
+                        HWACCEL_VASTAPI(mjpeg),
+#endif
                         NULL
                     },
 };
diff --git a/libavcodec/pthread_frame.c b/libavcodec/pthread_frame.c
index 85a6bc9..6013a9e 100644
--- a/libavcodec/pthread_frame.c
+++ b/libavcodec/pthread_frame.c
@@ -848,6 +848,23 @@ int ff_frame_thread_init(AVCodecContext *avctx)
 
     if (!thread_count) {
         int nb_cpus = av_cpu_count();
+        #if CONFIG_VASTAPI
+        const AVCodecHWConfig *config;
+        enum AVHWDeviceType type = AV_HWDEVICE_TYPE_NONE;
+        int i;
+        if(codec){
+            for (i = 0;; i++) {
+                config = avcodec_get_hw_config(codec, i);
+                if (!config)
+                    break;
+                type = config->device_type;
+                break;
+            }
+        }
+        if(AV_HWDEVICE_TYPE_VASTAPI == type){
+            nb_cpus = 1;
+        }
+        #endif
         // use number of cores + 1 as thread count if there is more than one
         if (nb_cpus > 1)
             thread_count = avctx->thread_count = FFMIN(nb_cpus + 1, MAX_AUTO_THREADS);
@@ -859,7 +876,7 @@ int ff_frame_thread_init(AVCodecContext *avctx)
         avctx->active_thread_type = 0;
         return 0;
     }
-
+    
     avctx->internal->thread_ctx = fctx = av_mallocz(sizeof(FrameThreadContext));
     if (!fctx)
         return AVERROR(ENOMEM);
diff --git a/libavcodec/utils.c b/libavcodec/utils.c
old mode 100644
new mode 100755
diff --git a/libavcodec/vastapi_av1.c b/libavcodec/vastapi_av1.c
new file mode 100644
index 0000000..61c3c4e
--- /dev/null
+++ b/libavcodec/vastapi_av1.c
@@ -0,0 +1,434 @@
+/*
+ * AV1 HW decode acceleration through VA API
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/frame.h"
+#include "libavutil/pixdesc.h"
+#include "hwconfig.h"
+#include "vastapi_decode.h"
+#include "internal.h"
+#include "av1dec.h"
+#include "thread.h"
+
+typedef struct VASTAPIAV1FrameRef {
+    AVFrame *frame;
+    int      valid;
+} VASTAPIAV1FrameRef;
+
+typedef struct VASTAPIAV1DecContext {
+    VASTAPIDecodeContext base;
+
+    /**
+     * For film grain case, VAAPI generate 2 output for each frame,
+     * current_frame will not apply film grain, and will be used for
+     * references for next frames. Maintain the reference list without
+     * applying film grain here. And current_display_picture will be
+     * used to apply film grain and push to downstream.
+     */
+    VASTAPIAV1FrameRef ref_tab[AV1_NUM_REF_FRAMES];
+    AVFrame           *tmp_frame;
+} VASTAPIAV1DecContext;
+
+static VASTSurfaceID vastapi_av1_surface_id(AV1Frame *vf)
+{
+    if (vf)
+        return ff_vastapi_get_surface_id(
+#if LIBAVCODEC_VERSION_INT >= AV_VERSION_INT(59, 37, 100) // n5.1
+            vf->f
+#else
+            vf->tf.f
+#endif
+        );
+    else
+        return VAST_INVALID_SURFACE;
+}
+
+static int8_t vastapi_av1_get_bit_depth_idx(AVCodecContext *avctx)
+{
+    AV1DecContext              *s         = avctx->priv_data;
+    const AV1RawSequenceHeader *seq       = s->raw_seq;
+    int8_t                      bit_depth = 8;
+
+    if (seq->seq_profile == 2 && seq->color_config.high_bitdepth)
+        bit_depth = seq->color_config.twelve_bit ? 12 : 10;
+    else if (seq->seq_profile <= 2)
+        bit_depth = seq->color_config.high_bitdepth ? 10 : 8;
+    else {
+        av_log(avctx, AV_LOG_ERROR, "Couldn't get bit depth from profile:%d.\n", seq->seq_profile);
+        return -1;
+    }
+    return bit_depth == 8 ? 0 : bit_depth == 10 ? 1 : 2;
+}
+
+static int vastapi_av1_decode_init(AVCodecContext *avctx)
+{
+    VASTAPIAV1DecContext *ctx = avctx->internal->hwaccel_priv_data;
+
+    ctx->tmp_frame = av_frame_alloc();
+    if (!ctx->tmp_frame) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to allocate frame.\n");
+        return AVERROR(ENOMEM);
+    }
+
+    for (int i = 0; i < FF_ARRAY_ELEMS(ctx->ref_tab); i++) {
+        ctx->ref_tab[i].frame = av_frame_alloc();
+        if (!ctx->ref_tab[i].frame) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to allocate reference table frame %d.\n", i);
+            return AVERROR(ENOMEM);
+        }
+        ctx->ref_tab[i].valid = 0;
+    }
+
+    return ff_vastapi_decode_init(avctx);
+}
+
+static int vastapi_av1_decode_uninit(AVCodecContext *avctx)
+{
+    VASTAPIAV1DecContext *ctx = avctx->internal->hwaccel_priv_data;
+
+    if (ctx->tmp_frame->buf[0])
+        ff_thread_release_buffer(avctx, ctx->tmp_frame);
+    av_frame_free(&ctx->tmp_frame);
+
+    for (int i = 0; i < FF_ARRAY_ELEMS(ctx->ref_tab); i++) {
+        if (ctx->ref_tab[i].frame->buf[0])
+            ff_thread_release_buffer(avctx, ctx->ref_tab[i].frame);
+        av_frame_free(&ctx->ref_tab[i].frame);
+    }
+
+    return ff_vastapi_decode_uninit(avctx);
+}
+
+static int vastapi_av1_start_frame(AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)
+{
+    AV1DecContext                   *s            = avctx->priv_data;
+    const AV1RawSequenceHeader      *seq          = s->raw_seq;
+    const AV1RawFrameHeader         *frame_header = s->raw_frame_header;
+    const AV1RawFilmGrainParams     *film_grain   = &s->cur_frame.film_grain;
+    VASTAPIDecodePicture            *pic          = s->cur_frame.hwaccel_picture_private;
+    VASTAPIAV1DecContext            *ctx          = avctx->internal->hwaccel_priv_data;
+    VASTDecPictureParameterBufferAV1 pic_param;
+    int8_t                           bit_depth_idx;
+    int                              err = 0;
+    int     apply_grain      = !(avctx->export_side_data & AV_CODEC_EXPORT_DATA_FILM_GRAIN) && film_grain->apply_grain;
+    uint8_t remap_lr_type[4] = { AV1_RESTORE_NONE, AV1_RESTORE_SWITCHABLE, AV1_RESTORE_WIENER, AV1_RESTORE_SGRPROJ };
+    uint8_t segmentation_feature_signed[AV1_SEG_LVL_MAX] = { 1, 1, 1, 1, 1, 0, 0, 0 };
+    uint8_t segmentation_feature_max[AV1_SEG_LVL_MAX]    = {
+           255, AV1_MAX_LOOP_FILTER, AV1_MAX_LOOP_FILTER, AV1_MAX_LOOP_FILTER, AV1_MAX_LOOP_FILTER, 7, 0, 0
+    };
+
+    bit_depth_idx = vastapi_av1_get_bit_depth_idx(avctx);
+    if (bit_depth_idx < 0)
+        goto fail;
+
+    if (apply_grain) {
+        if (ctx->tmp_frame->buf[0])
+            ff_thread_release_buffer(avctx, ctx->tmp_frame);
+        err = ff_thread_get_buffer(avctx, ctx->tmp_frame, AV_GET_BUFFER_FLAG_REF);
+        if (err < 0)
+            goto fail;
+        pic->output_surface = ff_vastapi_get_surface_id(ctx->tmp_frame);
+    } else {
+        pic->output_surface = vastapi_av1_surface_id(&s->cur_frame);
+    }
+
+    memset(&pic_param, 0, sizeof(VASTDecPictureParameterBufferAV1));
+    pic_param = (VASTDecPictureParameterBufferAV1) {
+        .profile                    = seq->seq_profile,
+        .order_hint_bits_minus_1    = seq->order_hint_bits_minus_1,
+        .bit_depth_idx              = bit_depth_idx,
+        .matrix_coefficients        = seq->color_config.matrix_coefficients,
+        .current_frame              = pic->output_surface,
+        .current_display_picture    = vastapi_av1_surface_id(&s->cur_frame),
+        .frame_width_minus1         = frame_header->frame_width_minus_1,
+        .frame_height_minus1        = frame_header->frame_height_minus_1,
+        .primary_ref_frame          = frame_header->primary_ref_frame,
+        .order_hint                 = frame_header->order_hint,
+        .refresh_frame_flags     = frame_header->refresh_frame_flags,
+        .tile_cols                  = frame_header->tile_cols,
+        .tile_rows                  = frame_header->tile_rows,
+        .context_update_tile_id     = frame_header->context_update_tile_id,
+        .superres_scale_denominator = frame_header->use_superres ?
+                                        frame_header->coded_denom + AV1_SUPERRES_DENOM_MIN :
+                                        AV1_SUPERRES_NUM,
+        .interp_filter              = frame_header->interpolation_filter,
+        .filter_level[0]            = frame_header->loop_filter_level[0],
+        .filter_level[1]            = frame_header->loop_filter_level[1],
+        .filter_level_u             = frame_header->loop_filter_level[2],
+        .filter_level_v             = frame_header->loop_filter_level[3],
+        .base_qindex                = frame_header->base_q_idx,
+        .y_dc_delta_q               = frame_header->delta_q_y_dc,
+        .u_dc_delta_q               = frame_header->delta_q_u_dc,
+        .u_ac_delta_q               = frame_header->delta_q_u_ac,
+        .v_dc_delta_q               = frame_header->delta_q_v_dc,
+        .v_ac_delta_q               = frame_header->delta_q_v_ac,
+        .cdef_damping_minus_3       = frame_header->cdef_damping_minus_3,
+        .cdef_bits                  = frame_header->cdef_bits,
+        .seq_info_fields.fields = {
+            .still_picture              = seq->still_picture,
+            .use_128x128_superblock     = seq->use_128x128_superblock,
+            .enable_filter_intra        = seq->enable_filter_intra,
+            .enable_intra_edge_filter   = seq->enable_intra_edge_filter,
+            .enable_interintra_compound = seq->enable_interintra_compound,
+            .enable_masked_compound     = seq->enable_masked_compound,
+            .enable_dual_filter         = seq->enable_dual_filter,
+            .enable_order_hint          = seq->enable_order_hint,
+            .enable_jnt_comp            = seq->enable_jnt_comp,
+            .enable_cdef                = seq->enable_cdef,
+            .mono_chrome                = seq->color_config.mono_chrome,
+            .color_range                = seq->color_config.color_range,
+            .subsampling_x              = seq->color_config.subsampling_x,
+            .subsampling_y              = seq->color_config.subsampling_y,
+            .chroma_sample_position     = seq->color_config.chroma_sample_position,
+            .film_grain_params_present  = seq->film_grain_params_present &&
+                                          !(avctx->export_side_data & AV_CODEC_EXPORT_DATA_FILM_GRAIN),
+        },
+        .seg_info.segment_info_fields.bits = {
+            .enabled         = frame_header->segmentation_enabled,
+            .update_map      = frame_header->segmentation_update_map,
+            .temporal_update = frame_header->segmentation_temporal_update,
+            .update_data     = frame_header->segmentation_update_data,
+        },
+        .film_grain_info = {
+            .film_grain_info_fields.bits = {
+                .apply_grain              = apply_grain,
+                .chroma_scaling_from_luma = film_grain->chroma_scaling_from_luma,
+                .grain_scaling_minus_8    = film_grain->grain_scaling_minus_8,
+                .ar_coeff_lag             = film_grain->ar_coeff_lag,
+                .ar_coeff_shift_minus_6   = film_grain->ar_coeff_shift_minus_6,
+                .grain_scale_shift        = film_grain->grain_scale_shift,
+                .overlap_flag             = film_grain->overlap_flag,
+                .clip_to_restricted_range = film_grain->clip_to_restricted_range,
+            },
+            .grain_seed    = film_grain->grain_seed,
+            .num_y_points  = film_grain->num_y_points,
+            .num_cb_points = film_grain->num_cb_points,
+            .num_cr_points = film_grain->num_cr_points,
+            .cb_mult       = film_grain->cb_mult,
+            .cb_luma_mult  = film_grain->cb_luma_mult,
+            .cb_offset     = film_grain->cb_offset,
+            .cr_mult       = film_grain->cr_mult,
+            .cr_luma_mult  = film_grain->cr_luma_mult,
+            .cr_offset     = film_grain->cr_offset,
+        },
+        .pic_info_fields.bits = {
+            .frame_type                   = frame_header->frame_type,
+            .show_frame                   = frame_header->show_frame,
+            .showable_frame               = frame_header->showable_frame,
+            .error_resilient_mode         = frame_header->error_resilient_mode,
+            .disable_cdf_update           = frame_header->disable_cdf_update,
+            .allow_screen_content_tools   = frame_header->allow_screen_content_tools,
+            .force_integer_mv             = frame_header->force_integer_mv,
+            .allow_intrabc                = frame_header->allow_intrabc,
+            .use_superres                 = frame_header->use_superres,
+            .allow_high_precision_mv      = frame_header->allow_high_precision_mv,
+            .is_motion_mode_switchable    = frame_header->is_motion_mode_switchable,
+            .use_ref_frame_mvs            = frame_header->use_ref_frame_mvs,
+            .disable_frame_end_update_cdf = frame_header->disable_frame_end_update_cdf,
+            .uniform_tile_spacing_flag    = frame_header->uniform_tile_spacing_flag,
+            .allow_warped_motion          = frame_header->allow_warped_motion,
+        },
+        .loop_filter_info_fields.bits = {
+            .sharpness_level        = frame_header->loop_filter_sharpness,
+            .mode_ref_delta_enabled = frame_header->loop_filter_delta_enabled,
+            .mode_ref_delta_update  = frame_header->loop_filter_delta_update,
+        },
+        .mode_control_fields.bits = {
+            .delta_q_present_flag  = frame_header->delta_q_present,
+            .log2_delta_q_res      = frame_header->delta_q_res,
+            .delta_lf_present_flag = frame_header->delta_lf_present,
+            .log2_delta_lf_res     = frame_header->delta_lf_res,
+            .delta_lf_multi        = frame_header->delta_lf_multi,
+            .tx_mode               = frame_header->tx_mode,
+            .reference_select      = frame_header->reference_select,
+            .reduced_tx_set_used   = frame_header->reduced_tx_set,
+            .skip_mode_present     = frame_header->skip_mode_present,
+        },
+        .loop_restoration_fields.bits = {
+            .yframe_restoration_type  = remap_lr_type[frame_header->lr_type[0]],
+            .cbframe_restoration_type = remap_lr_type[frame_header->lr_type[1]],
+            .crframe_restoration_type = remap_lr_type[frame_header->lr_type[2]],
+            .lr_unit_shift            = frame_header->lr_unit_shift,
+            .lr_uv_shift              = frame_header->lr_uv_shift,
+        },
+        .qmatrix_fields.bits = {
+            .using_qmatrix = frame_header->using_qmatrix,
+            .qm_y          = frame_header->qm_y,
+            .qm_u          = frame_header->qm_u,
+            .qm_v          = frame_header->qm_v,
+        }
+    };
+
+    for (int i = 0; i < AV1_NUM_REF_FRAMES; i++) {
+        if (pic_param.pic_info_fields.bits.frame_type == AV1_FRAME_KEY)
+            pic_param.ref_frame_map[i] = VAST_INVALID_ID;
+        else
+            pic_param.ref_frame_map[i] = ctx->ref_tab[i].valid ? ff_vastapi_get_surface_id(ctx->ref_tab[i].frame)
+                                                               : vastapi_av1_surface_id(&s->ref[i]);
+    }
+    for (int i = 0; i < AV1_REFS_PER_FRAME; i++) {
+        pic_param.ref_frame_idx[i] = frame_header->ref_frame_idx[i];
+    }
+    for (int i = 0; i < AV1_TOTAL_REFS_PER_FRAME; i++) {
+        pic_param.ref_deltas[i] = frame_header->loop_filter_ref_deltas[i];
+    }
+    for (int i = 0; i < 2; i++) {
+        pic_param.mode_deltas[i] = frame_header->loop_filter_mode_deltas[i];
+    }
+    for (int i = 0; i < (1 << frame_header->cdef_bits); i++) {
+        pic_param.cdef_y_strengths[i] =
+            (frame_header->cdef_y_pri_strength[i] << 2) + frame_header->cdef_y_sec_strength[i];
+        pic_param.cdef_uv_strengths[i] =
+            (frame_header->cdef_uv_pri_strength[i] << 2) + frame_header->cdef_uv_sec_strength[i];
+    }
+    for (int i = 0; i < frame_header->tile_cols; i++) {
+        pic_param.width_in_sbs_minus_1[i] = frame_header->width_in_sbs_minus_1[i];
+    }
+    for (int i = 0; i < frame_header->tile_rows; i++) {
+        pic_param.height_in_sbs_minus_1[i] = frame_header->height_in_sbs_minus_1[i];
+    }
+    for (int i = AV1_REF_FRAME_LAST; i <= AV1_REF_FRAME_ALTREF; i++) {
+        pic_param.wm[i - 1].invalid = s->cur_frame.gm_invalid[i];
+        pic_param.wm[i - 1].wmtype  = s->cur_frame.gm_type[i];
+        for (int j = 0; j < 6; j++)
+            pic_param.wm[i - 1].wmmat[j] = s->cur_frame.gm_params[i][j];
+    }
+    for (int i = 0; i < AV1_MAX_SEGMENTS; i++) {
+        for (int j = 0; j < AV1_SEG_LVL_MAX; j++) {
+            pic_param.seg_info.feature_mask[i] |= (frame_header->feature_enabled[i][j] << j);
+            if (segmentation_feature_signed[j])
+                pic_param.seg_info.feature_data[i][j] = av_clip(
+                    frame_header->feature_value[i][j], -segmentation_feature_max[j], segmentation_feature_max[j]);
+            else
+                pic_param.seg_info.feature_data[i][j] =
+                    av_clip(frame_header->feature_value[i][j], 0, segmentation_feature_max[j]);
+        }
+    }
+    if (apply_grain) {
+        for (int i = 0; i < film_grain->num_y_points; i++) {
+            pic_param.film_grain_info.point_y_value[i]   = film_grain->point_y_value[i];
+            pic_param.film_grain_info.point_y_scaling[i] = film_grain->point_y_scaling[i];
+        }
+        for (int i = 0; i < film_grain->num_cb_points; i++) {
+            pic_param.film_grain_info.point_cb_value[i]   = film_grain->point_cb_value[i];
+            pic_param.film_grain_info.point_cb_scaling[i] = film_grain->point_cb_scaling[i];
+        }
+        for (int i = 0; i < film_grain->num_cr_points; i++) {
+            pic_param.film_grain_info.point_cr_value[i]   = film_grain->point_cr_value[i];
+            pic_param.film_grain_info.point_cr_scaling[i] = film_grain->point_cr_scaling[i];
+        }
+        for (int i = 0; i < 24; i++) {
+            pic_param.film_grain_info.ar_coeffs_y[i] = film_grain->ar_coeffs_y_plus_128[i] - 128;
+        }
+        for (int i = 0; i < 25; i++) {
+            pic_param.film_grain_info.ar_coeffs_cb[i] = film_grain->ar_coeffs_cb_plus_128[i] - 128;
+            pic_param.film_grain_info.ar_coeffs_cr[i] = film_grain->ar_coeffs_cr_plus_128[i] - 128;
+        }
+    }
+    err =
+        ff_vastapi_decode_make_param_buffer(avctx, pic, VASTPictureParameterBufferType, &pic_param, sizeof(pic_param));
+    if (err < 0)
+        goto fail;
+
+    return 0;
+
+fail:
+    ff_vastapi_decode_cancel(avctx, pic);
+    return err;
+}
+
+static int vastapi_av1_end_frame(AVCodecContext *avctx)
+{
+    const AV1DecContext         *s          = avctx->priv_data;
+    const AV1RawFrameHeader     *header     = s->raw_frame_header;
+    const AV1RawFilmGrainParams *film_grain = &s->cur_frame.film_grain;
+    VASTAPIDecodePicture        *pic        = s->cur_frame.hwaccel_picture_private;
+    VASTAPIAV1DecContext        *ctx        = avctx->internal->hwaccel_priv_data;
+
+    int apply_grain = !(avctx->export_side_data & AV_CODEC_EXPORT_DATA_FILM_GRAIN) && film_grain->apply_grain;
+    int ret;
+    ret = ff_vastapi_decode_issue(avctx, pic);
+    if (ret < 0)
+        return ret;
+
+    for (int i = 0; i < AV1_NUM_REF_FRAMES; i++) {
+        if (header->refresh_frame_flags & (1 << i)) {
+            if (ctx->ref_tab[i].frame->buf[0])
+                ff_thread_release_buffer(avctx, ctx->ref_tab[i].frame);
+
+            if (apply_grain) {
+                ret = av_frame_ref(ctx->ref_tab[i].frame, ctx->tmp_frame);
+                if (ret < 0)
+                    return ret;
+                ctx->ref_tab[i].valid = 1;
+            } else {
+                ctx->ref_tab[i].valid = 0;
+            }
+        }
+    }
+
+    return 0;
+}
+
+static int vastapi_av1_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
+{
+    const AV1DecContext        *s   = avctx->priv_data;
+    VASTAPIDecodePicture       *pic = s->cur_frame.hwaccel_picture_private;
+    VASTSliceParameterBufferAV1 slice_param;
+    int                         err = 0;
+
+    for (int i = s->tg_start; i <= s->tg_end; i++) {
+        memset(&slice_param, 0, sizeof(VASTSliceParameterBufferAV1));
+
+        slice_param = (VASTSliceParameterBufferAV1){
+            .slice_data_size   = s->tile_group_info[i].tile_size,
+            .slice_data_offset = s->tile_group_info[i].tile_offset,
+            .slice_data_flag   = VAST_SLICE_DATA_FLAG_ALL,
+            .tile_row          = s->tile_group_info[i].tile_row,
+            .tile_column       = s->tile_group_info[i].tile_column,
+            .tg_start          = s->tg_start,
+            .tg_end            = s->tg_end,
+        };
+
+        err = ff_vastapi_decode_make_slice_buffer(avctx, pic, &slice_param, sizeof(VASTSliceParameterBufferAV1), buffer,
+                                                  size);
+        if (err) {
+            ff_vastapi_decode_cancel(avctx, pic);
+            return err;
+        }
+    }
+
+    return 0;
+}
+
+const AVHWAccel ff_av1_vastapi_hwaccel = {
+    .name                 = "av1_vastapi",
+    .type                 = AVMEDIA_TYPE_VIDEO,
+    .id                   = AV_CODEC_ID_AV1,
+    .pix_fmt              = AV_PIX_FMT_VASTAPI,
+    .start_frame          = vastapi_av1_start_frame,
+    .end_frame            = vastapi_av1_end_frame,
+    .decode_slice         = vastapi_av1_decode_slice,
+    .frame_priv_data_size = sizeof(VASTAPIDecodePicture),
+    .init                 = vastapi_av1_decode_init,
+    .uninit               = vastapi_av1_decode_uninit,
+    .frame_params         = ff_vastapi_common_frame_params,
+    .priv_data_size       = sizeof(VASTAPIAV1DecContext),
+    .caps_internal        = HWACCEL_CAP_ASYNC_SAFE,
+};
diff --git a/libavcodec/vastapi_decode.c b/libavcodec/vastapi_decode.c
new file mode 100644
index 0000000..0936908
--- /dev/null
+++ b/libavcodec/vastapi_decode.c
@@ -0,0 +1,499 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/avassert.h"
+#include "libavutil/common.h"
+#include "libavutil/pixdesc.h"
+
+#include "avcodec.h"
+#include "decode.h"
+#include "internal.h"
+#include "vastapi_decode.h"
+
+int ff_vastapi_decode_make_param_buffer(AVCodecContext *avctx, VASTAPIDecodePicture *pic, int type, const void *data,
+                                        size_t size)
+{
+    VASTAPIDecodeContext *ctx  = avctx->internal->hwaccel_priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->decCtx.vst_func;
+
+    return func->vastapiDecMakeParamBuffer(&ctx->decCtx, pic, type, data, size);
+}
+
+int ff_vastapi_decode_make_slice_buffer(AVCodecContext *avctx, VASTAPIDecodePicture *pic, const void *params_data,
+                                        size_t params_size, const void *slice_data, size_t slice_size)
+{
+    VASTAPIDecodeContext *ctx  = avctx->internal->hwaccel_priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->decCtx.vst_func;
+
+    return func->vastapiDecMakeSliceBuff(&ctx->decCtx, pic, params_data, params_size, slice_data, slice_size);
+}
+
+int ff_vastapi_decode_issue(AVCodecContext *avctx, VASTAPIDecodePicture *pic)
+{
+    VASTAPIDecodeContext *ctx  = avctx->internal->hwaccel_priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->decCtx.vst_func;
+
+    return func->vastapiDecPicutre(&ctx->decCtx, pic);
+}
+
+int ff_vastapi_decode_cancel(AVCodecContext *avctx, VASTAPIDecodePicture *pic)
+{
+    VASTAPIDecodeContext *ctx  = avctx->internal->hwaccel_priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->decCtx.vst_func;
+
+    func->vastapiDecDestroyBuff(&ctx->decCtx, pic);
+
+    return 0;
+}
+
+static int vastapi_decode_find_best_format(AVCodecContext *avctx, AVHWDeviceContext *device, VASTConfigID config_id,
+                                           AVHWFramesContext *frames)
+{
+    AVVASTAPIDeviceContext *hwctx = device->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    VASTStatus              vas;
+    VASTSurfaceAttrib      *attr = NULL;
+    enum AVPixelFormat      source_format, best_format, format;
+    uint32_t                best_fourcc, fourcc;
+    int                     i, j, nb_attr;
+    VAST_PIX_FTM            vst_fmt;
+    VASTVADecCtx            vaCtx = { config_id, VAST_INVALID_ID, hwctx->display };
+
+    source_format = avctx->sw_pix_fmt;
+    av_assert0(source_format != AV_PIX_FMT_NONE);
+
+    nb_attr = func->vastapiDecQuerySurfaceAttr(&vaCtx, &attr);
+    if (nb_attr <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to query surface attributes");
+        return AVERROR(ENOSYS);
+    }
+
+    best_format = AV_PIX_FMT_NONE;
+
+    for (i = 0; i < nb_attr; i++) {
+
+        vst_fmt = func->vastapiDecGetFmt(attr[i]);
+        if (vst_fmt == VAST_FTM_NONE)
+            continue;
+
+        format = vastaiFmtToAvFmt(vst_fmt);
+        av_log(avctx, AV_LOG_DEBUG, "Considering format %#x -> %s.\n", fourcc, av_get_pix_fmt_name(format));
+
+        best_format = av_find_best_pix_fmt_of_2(format, best_format, source_format, 0, NULL);
+        if (format == best_format)
+            best_fourcc = fourcc;
+    }
+
+    func->vastapiFreeMemory(attr);
+
+    if (best_format == AV_PIX_FMT_NONE) {
+        av_log(avctx, AV_LOG_ERROR, "No usable formats for decoding!\n");
+        return AVERROR(EINVAL);
+    }
+
+    av_log(avctx, AV_LOG_DEBUG, "Picked %s (%#x) as best match for %s.\n", av_get_pix_fmt_name(best_format),
+           best_fourcc, av_get_pix_fmt_name(source_format));
+
+    frames->sw_format = best_format;
+    if (avctx->internal->hwaccel_priv_data) {
+        VASTAPIDecodeContext   *ctx  = avctx->internal->hwaccel_priv_data;
+        AVVASTAPIFramesContext *avfc = frames->hwctx;
+
+        ctx->decCtx.pixel_format_attribute = (VASTSurfaceAttrib){
+            .type          = VASTSurfaceAttribPixelFormat,
+            .value.value.i = best_fourcc,
+        };
+
+        avfc->attributes    = &ctx->decCtx.pixel_format_attribute;
+        avfc->nb_attributes = 1;
+    }
+
+    return 0;
+}
+
+static const struct {
+    enum AVCodecID codec_id;
+    int            codec_profile;
+    VASTProfile    va_profile;
+} vastapi_profile_map[] = {
+    { AV_CODEC_ID_H264, FF_PROFILE_H264_HIGH_10, HANTROProfileH264High10 },
+
+#define MAP(c, p, v, ...)                                                                                              \
+    {                                                                                                                  \
+        AV_CODEC_ID_##c, FF_PROFILE_##p, VASTProfile##v, __VA_ARGS__                                                   \
+    }
+    MAP(MPEG2VIDEO, MPEG2_SIMPLE, MPEG2Simple),
+    MAP(MPEG2VIDEO, MPEG2_MAIN, MPEG2Main),
+    MAP(H263, UNKNOWN, H263Baseline),
+    MAP(MPEG4, MPEG4_SIMPLE, MPEG4Simple),
+    MAP(MPEG4, MPEG4_ADVANCED_SIMPLE, MPEG4AdvancedSimple),
+    MAP(MPEG4, MPEG4_MAIN, MPEG4Main),
+    MAP(H264, H264_CONSTRAINED_BASELINE, H264ConstrainedBaseline),
+    MAP(H264, H264_MAIN, H264Main),
+    MAP(H264, H264_EXTENDED, H264Main),
+    MAP(H264, H264_HIGH, H264High),
+    MAP(H264, H264_BASELINE, H264Baseline),
+#if VA_CHECK_VERSION(0, 37, 0)
+    MAP(HEVC, HEVC_MAIN, HEVCMain),
+    MAP(HEVC, HEVC_MAIN_10, HEVCMain10),
+    MAP(HEVC, HEVC_MAIN_STILL_PICTURE, HEVCMain),
+    MAP(HEVC, HEVC_REXT, HEVCMainIntra),
+#endif
+    MAP(MJPEG, MJPEG_HUFFMAN_BASELINE_DCT, JPEGBaseline),
+    MAP(WMV3, VC1_SIMPLE, VC1Simple),
+    MAP(WMV3, VC1_MAIN, VC1Main),
+    MAP(WMV3, VC1_COMPLEX, VC1Advanced),
+    MAP(WMV3, VC1_ADVANCED, VC1Advanced),
+    MAP(VC1, VC1_SIMPLE, VC1Simple),
+    MAP(VC1, VC1_MAIN, VC1Main),
+    MAP(VC1, VC1_COMPLEX, VC1Advanced),
+    MAP(VC1, VC1_ADVANCED, VC1Advanced),
+    MAP(VP8, UNKNOWN, VP8Version0_3),
+#if VA_CHECK_VERSION(0, 38, 0)
+    MAP(VP9, VP9_0, VP9Profile0),
+#endif
+#if VA_CHECK_VERSION(0, 39, 0)
+    MAP(VP9, VP9_2, VP9Profile2),
+#endif
+    MAP(AV1, AV1_MAIN, AV1Main),
+    MAP(AV1, AV1_HIGH, AV1Hign),
+#undef MAP
+};
+
+/*
+ * Set *va_config and the frames_ref fields from the current codec parameters
+ * in avctx.
+ */
+static int vastapi_decode_make_config(AVCodecContext *avctx, AVBufferRef *device_ref, VASTConfigID *va_config,
+                                      AVBufferRef *frames_ref)
+{
+    AVVASTAPIHWConfig       *hwconfig    = NULL;
+    AVHWFramesConstraints   *constraints = NULL;
+    VASTStatus               vas;
+    int                      err, i, j;
+    const AVCodecDescriptor *codec_desc;
+    VASTProfile             *profile_list = NULL, matched_va_profile, va_profile;
+    int                      profile_count, exact_match, matched_ff_profile, codec_profile;
+
+    AVHWDeviceContext      *device = (AVHWDeviceContext *)device_ref->data;
+    AVVASTAPIDeviceContext *hwctx  = device->hwctx;
+    VastapiFunctions       *func   = (VastapiFunctions *)hwctx->vst_func;
+    VASTVADecCtx            vaCtx  = { VAST_INVALID_ID, VAST_INVALID_ID, hwctx->display };
+
+    codec_desc = avcodec_descriptor_get(avctx->codec_id);
+    if (!codec_desc) {
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+
+    profile_count = func->vastapiDecQueryProfileList(&vaCtx, &profile_list);
+    if (profile_count <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to query profiles: %d.\n", vas);
+        return AVERROR(ENOSYS);
+    }
+
+    matched_va_profile = VASTProfileNone;
+    exact_match        = 0;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(vastapi_profile_map); i++) {
+        int profile_match = 0;
+        if (avctx->codec_id != vastapi_profile_map[i].codec_id)
+            continue;
+        if (avctx->profile == vastapi_profile_map[i].codec_profile ||
+            vastapi_profile_map[i].codec_profile == FF_PROFILE_UNKNOWN)
+            profile_match = 1;
+
+        va_profile    = vastapi_profile_map[i].va_profile;
+        codec_profile = vastapi_profile_map[i].codec_profile;
+
+        for (j = 0; j < profile_count; j++) {
+            if (va_profile == profile_list[j]) {
+                exact_match = profile_match;
+                break;
+            }
+        }
+        if (j < profile_count) {
+            matched_va_profile = va_profile;
+            matched_ff_profile = codec_profile;
+            if (exact_match)
+                break;
+        }
+    }
+    func->vastapiFreeMemory(profile_list);
+
+    if (matched_va_profile == VASTProfileNone) {
+        av_log(avctx, AV_LOG_ERROR,
+               "No support for codec %s "
+               "profile %d.\n",
+               codec_desc->name, avctx->profile);
+        err = AVERROR(ENOSYS);
+        goto fail;
+    }
+    if (!exact_match) {
+        if (avctx->hwaccel_flags & AV_HWACCEL_FLAG_ALLOW_PROFILE_MISMATCH) {
+            av_log(avctx, AV_LOG_VERBOSE,
+                   "Codec %s profile %d not "
+                   "supported for hardware decode.\n",
+                   codec_desc->name, avctx->profile);
+            av_log(avctx, AV_LOG_WARNING,
+                   "Using possibly-"
+                   "incompatible profile %d instead.\n",
+                   matched_ff_profile);
+        } else {
+            av_log(avctx, AV_LOG_VERBOSE,
+                   "Codec %s profile %d not "
+                   "supported for hardware decode.\n",
+                   codec_desc->name, avctx->profile);
+            err = AVERROR(EINVAL);
+            goto fail;
+        }
+    }
+
+    if (func->vastapiDecCreateConfig(&vaCtx, matched_va_profile) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create decode config\n");
+        err = AVERROR(EIO);
+        goto fail;
+    }
+
+    hwconfig = av_hwdevice_hwconfig_alloc(device_ref);
+    if (!hwconfig) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    *va_config          = vaCtx.va_config;
+    hwconfig->config_id = *va_config;
+
+    constraints = av_hwdevice_get_hwframe_constraints(device_ref, hwconfig);
+    if (!constraints) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    if (avctx->coded_width < constraints->min_width || avctx->coded_height < constraints->min_height ||
+        avctx->coded_width > constraints->max_width || avctx->coded_height > constraints->max_height) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Hardware does not support image "
+               "size %dx%d (constraints: width %d-%d height %d-%d).\n",
+               avctx->coded_width, avctx->coded_height, constraints->min_width, constraints->max_width,
+               constraints->min_height, constraints->max_height);
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (!constraints->valid_sw_formats || constraints->valid_sw_formats[0] == AV_PIX_FMT_NONE) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Hardware does not offer any "
+               "usable surface formats.\n");
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+
+    if (frames_ref) {
+        AVHWFramesContext *frames = (AVHWFramesContext *)frames_ref->data;
+
+        frames->format = AV_PIX_FMT_VASTAPI;
+        frames->width  = avctx->coded_width;
+        frames->height = avctx->coded_height;
+
+        err = vastapi_decode_find_best_format(avctx, device, *va_config, frames);
+        if (err < 0)
+            goto fail;
+
+        frames->initial_pool_size = 1;
+        // Add per-codec number of surfaces used for storing reference frames.
+        switch (avctx->codec_id) {
+        case AV_CODEC_ID_H264:
+        case AV_CODEC_ID_HEVC:
+            frames->initial_pool_size += 16;
+            break;
+        case AV_CODEC_ID_VP9:
+            frames->initial_pool_size += 8;
+            break;
+        case AV_CODEC_ID_VP8:
+            frames->initial_pool_size += 3;
+            break;
+        default:
+            frames->initial_pool_size += 2;
+        }
+    }
+
+    av_hwframe_constraints_free(&constraints);
+    av_freep(&hwconfig);
+
+    return 0;
+
+fail:
+    av_hwframe_constraints_free(&constraints);
+    av_freep(&hwconfig);
+    if (*va_config != VAST_INVALID_ID) {
+        func->vastapiDecDestoryConfig(&vaCtx);
+        *va_config = VAST_INVALID_ID;
+    }
+    return err;
+}
+
+int ff_vastapi_common_frame_params(AVCodecContext *avctx, AVBufferRef *hw_frames_ctx)
+{
+    AVHWFramesContext      *hw_frames  = (AVHWFramesContext *)hw_frames_ctx->data;
+    AVHWDeviceContext      *device_ctx = hw_frames->device_ctx;
+    AVVASTAPIDeviceContext *hwctx;
+    VastapiFunctions       *func = NULL;
+    int                     err;
+    VASTVADecCtx            vaCtx = { VAST_INVALID_ID, VAST_INVALID_ID, 0 };
+
+    if (device_ctx->type != AV_HWDEVICE_TYPE_VASTAPI)
+        return AVERROR(EINVAL);
+    hwctx = device_ctx->hwctx;
+    func  = (VastapiFunctions *)hwctx->vst_func;
+
+    err = vastapi_decode_make_config(avctx, hw_frames->device_ref, &vaCtx.va_config, hw_frames_ctx);
+    if (err)
+        return err;
+
+    if (vaCtx.va_config != VAST_INVALID_ID) {
+        vaCtx.display = hwctx->display;
+        func->vastapiDecDestoryConfig(&vaCtx);
+    }
+
+    return 0;
+}
+
+static int vastapi_retrieve_data(void *avctx, AVFrame *frame)
+{
+    FrameDecodeData        *fdd           = NULL;
+    AVHWDeviceContext      *hw_device_ctx = NULL;
+    AVVASTAPIDeviceContext *hwctx         = NULL;
+    VastapiFunctions       *func          = NULL;
+    VASTSurfaceID           surface_id;
+    VASTVADecCtx            vaCtx;
+    int                     err = 0;
+
+    if (NULL == frame || NULL == frame->private_ref) {
+        av_log(avctx, AV_LOG_ERROR, "%s:%d, Invalid input frame->private_ref!!!\n", __func__, __LINE__);
+        err = AVERROR(EIO);
+        goto fail;
+    }
+
+    fdd           = (FrameDecodeData *)frame->private_ref->data;
+    hw_device_ctx = (AVHWDeviceContext *)(((AVCodecContext *)avctx)->hw_device_ctx->data);
+
+    if (NULL == hw_device_ctx || NULL == hw_device_ctx->hwctx) {
+
+        hw_device_ctx = (AVHWDeviceContext *)fdd->hwaccel_priv;
+        if (NULL == hw_device_ctx || NULL == hw_device_ctx->hwctx) {
+            av_log(avctx, AV_LOG_ERROR, "%s:%d, Invalid input hw_device_ctx->hwctx!!!\n", __func__, __LINE__);
+            err = AVERROR(EIO);
+            goto fail;
+        }
+    }
+
+    hwctx = hw_device_ctx->hwctx;
+    func  = (VastapiFunctions *)hwctx->vst_func;
+
+    surface_id = ff_vastapi_get_surface_id(frame);
+
+    vaCtx.display = hwctx->display;
+    if (func->vastapiDecSyncSurface(&vaCtx, surface_id) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "%s:%d, Failed to sync surface %#x\n", __func__, __LINE__, surface_id);
+        err = AVERROR(EIO);
+    }
+
+fail:
+    return err;
+}
+
+int ff_vastapi_decode_start_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    FrameDecodeData *fdd = NULL;
+
+    if (!frame->private_ref) {
+        av_log(avctx, AV_LOG_ERROR, "%s:%d, frame private_ref is null!\n", __func__, __LINE__);
+        return -1;
+    }
+
+    fdd = (FrameDecodeData *)frame->private_ref->data;
+
+    fdd->hwaccel_priv = avctx->hw_device_ctx->data;
+    fdd->post_process = vastapi_retrieve_data;
+
+    return 0;
+}
+
+int ff_vastapi_decode_init(AVCodecContext *avctx)
+{
+    VASTAPIDecodeContext *ctx = avctx->internal->hwaccel_priv_data;
+    VASTStatus            vas;
+    int                   err;
+    VastapiFunctions     *func = NULL;
+
+    ctx->decCtx.display    = NULL;
+    ctx->decCtx.va_config  = VAST_INVALID_ID;
+    ctx->decCtx.va_context = VAST_INVALID_ID;
+    if (avctx->profile == FF_PROFILE_H264_EXTENDED) {
+        av_log(avctx, AV_LOG_ERROR,
+               "H.264 extended profile "
+               "is not supported.\n");
+        return AVERROR_PATCHWELCOME;
+    }
+
+    err = ff_decode_get_hw_frames_ctx(avctx, AV_HWDEVICE_TYPE_VASTAPI);
+    if (err < 0)
+        goto fail;
+
+    ctx->frames         = (AVHWFramesContext *)avctx->hw_frames_ctx->data;
+    ctx->hwfc           = ctx->frames->hwctx;
+    ctx->device         = ctx->frames->device_ctx;
+    ctx->hwctx          = ctx->device->hwctx;
+    ctx->decCtx.display = ctx->hwctx->display;
+
+    func                 = (VastapiFunctions *)ctx->hwctx->vst_func;
+    ctx->decCtx.vst_func = func;
+
+    err = vastapi_decode_make_config(avctx, ctx->frames->device_ref, &ctx->decCtx.va_config, NULL);
+    if (err)
+        goto fail;
+
+    if (func->vastapiDecCreateContext(&ctx->decCtx, avctx->coded_width, avctx->coded_height, VA_PROGRESSIVE,
+                                      ctx->hwfc->surface_ids, ctx->hwfc->nb_surfaces) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create decode context.\n");
+        err = AVERROR(EIO);
+        goto fail;
+    }
+
+    av_log(avctx, AV_LOG_DEBUG,
+           "Decode context initialised: "
+           "%#x/%#x.\n",
+           ctx->decCtx.va_config, ctx->decCtx.va_context);
+
+    return 0;
+
+fail:
+    ff_vastapi_decode_uninit(avctx);
+    return err;
+}
+
+int ff_vastapi_decode_uninit(AVCodecContext *avctx)
+{
+    VASTAPIDecodeContext *ctx  = avctx->internal->hwaccel_priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->decCtx.vst_func;
+
+    if(func != NULL)
+        func->vastapiDecUnint(&ctx->decCtx);
+
+    return 0;
+}
diff --git a/libavcodec/vastapi_decode.h b/libavcodec/vastapi_decode.h
new file mode 100644
index 0000000..a813187
--- /dev/null
+++ b/libavcodec/vastapi_decode.h
@@ -0,0 +1,63 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVCODEC_VASTAPI_DECODE_H
+#define AVCODEC_VASTAPI_DECODE_H
+
+#include "libavutil/frame.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_vastapi.h"
+
+#include "avcodec.h"
+#include "version.h"
+#include "vastva/vastapi.h"
+#include "vastva/vastapi_dynlink_loader.h"
+
+static inline VASTSurfaceID ff_vastapi_get_surface_id(AVFrame *pic)
+{
+    return (uintptr_t)pic->data[3];
+}
+
+typedef struct VASTAPIDecodeContext {
+    VASTVADecCtx decCtx;
+
+    AVHWDeviceContext      *device;
+    AVVASTAPIDeviceContext *hwctx;
+
+    AVHWFramesContext      *frames;
+    AVVASTAPIFramesContext *hwfc;
+
+} VASTAPIDecodeContext;
+
+int ff_vastapi_decode_make_param_buffer(AVCodecContext *avctx, VASTAPIDecodePicture *pic, int type, const void *data,
+                                        size_t size);
+
+int ff_vastapi_decode_make_slice_buffer(AVCodecContext *avctx, VASTAPIDecodePicture *pic, const void *params_data,
+                                        size_t params_size, const void *slice_data, size_t slice_size);
+
+int ff_vastapi_decode_issue(AVCodecContext *avctx, VASTAPIDecodePicture *pic);
+int ff_vastapi_decode_cancel(AVCodecContext *avctx, VASTAPIDecodePicture *pic);
+
+int ff_vastapi_decode_init(AVCodecContext *avctx);
+int ff_vastapi_decode_uninit(AVCodecContext *avctx);
+
+int ff_vastapi_common_frame_params(AVCodecContext *avctx, AVBufferRef *hw_frames_ctx);
+
+int ff_vastapi_decode_start_frame(AVCodecContext *avctx, AVFrame *frame);
+
+#endif /* AVCODEC_VASTAPI_DECODE_H */
diff --git a/libavcodec/vastapi_encode.c b/libavcodec/vastapi_encode.c
new file mode 100755
index 0000000..31d7478
--- /dev/null
+++ b/libavcodec/vastapi_encode.c
@@ -0,0 +1,5036 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <inttypes.h>
+#include <string.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/common.h"
+#include "libavutil/log.h"
+#include "libavutil/pixdesc.h"
+
+#include "vastapi_encode.h"
+#include "vastva/va.h"
+#include <vastva/va_enc_hevc.h>
+#include <vastva/va_enc_h264.h>
+#include <vastva/va_enc_jpeg.h>
+#include <vastva/va_enc_av1.h>
+
+#if FF_GE(N441)
+#include "encode.h"
+#endif
+
+#if FF_GE(N512)
+#include "codec_internal.h"
+#endif
+
+#if FF_LT(N441)
+#define PRIV_CBC priv->cbc,
+#else
+#define PRIV_CBC // Nothing
+#endif
+
+#include "avcodec.h"
+#if HAVE_UNISTD_H
+#include <unistd.h>
+#endif
+#include "internal.h" //vastai flush
+
+#ifndef MAX
+#define MAX(a, b) ((a) > (b) ? (a) : (b))
+#endif
+#ifndef MIN
+#define MIN(a, b) ((a) < (b) ? (a) : (b))
+#endif
+
+#define AVCodecContextPtr(x) ((AVCodecContext *)(x))
+#define AVFramePtr(x) ((AVFrame *)(x))
+#define AVBufferRefPtr(x) ((AVBufferRef *)(x))
+#define AVHWDeviceContextPtr(x) ((AVHWDeviceContext *)(x))
+#define AVVASTAPIDeviceContextPtr(x) ((AVVASTAPIDeviceContext *)(x))
+#define AVHWFramesContextPtr(x) ((AVHWFramesContext *)(x))
+
+struct av1_pkt {
+    struct node *next;
+    AVPacket    *pkt;
+};
+
+void         v_queue_init(struct queue *queue);
+void         v_queue_put(struct queue *queue, struct node *node);
+struct node *v_queue_get(struct queue *queue);
+void         v_queue_free(struct queue *queue);
+void         v_queue_remove(struct queue *queue, struct node *node);
+
+void v_queue_init(struct queue *queue)
+{
+    queue->head   = NULL;
+    queue->tail   = NULL;
+    queue->length = 0;
+}
+
+void v_queue_put(struct queue *queue, struct node *node)
+{
+    node->next = NULL;
+    if (queue->head) {
+        queue->head->next = node;
+        queue->head       = node;
+    } else {
+        queue->tail = node;
+        queue->head = node;
+    }
+
+    queue->length++;
+}
+
+struct node *v_queue_get(struct queue *queue)
+{
+    struct node *node = queue->tail;
+
+    if (!node)
+        return NULL; /* Empty queue */
+
+    if (queue->head == queue->tail) {
+        queue->head = NULL;
+    }
+    queue->tail = node->next;
+    queue->length--;
+
+    return node;
+}
+
+void v_queue_free(struct queue *queue)
+{
+    while (queue->length > 0) {
+        v_queue_remove(queue, queue->tail);
+    }
+    return;
+}
+
+void v_queue_remove(struct queue *queue, struct node *node)
+{
+    struct node *prev, *p;
+
+    if (queue->tail == queue->head) {
+        if (queue->head == node) {
+            v_queue_init(queue);
+        }
+        return;
+    }
+
+    for (prev = p = queue->tail; p; p = p->next) {
+        if (p == node) {
+            prev->next = p->next;
+            if (queue->head == node)
+                queue->head = prev;
+            if (queue->tail == node)
+                queue->tail = p->next;
+            queue->length--;
+            break;
+        }
+        prev = p;
+    }
+}
+
+
+static int vastapi_encode_av1_split_and_combine(AVCodecContext *avctx, AVPacket *pkt);
+static int vastapi_encode_issue(AVCodecContext *avctx, VASTAPIEncodePicture *pic);
+static int vastapi_encode_head_issue(AVCodecContext *avctx, VASTAPIEncodePicture *pic);
+
+static int vastapi_get_psnr(VASTAPIEncodeContext *ctx, VASTDisplay display,
+                     int64_t display_order, int64_t encode_order, int flush_lookahead, PsnrSsimInfo *info)
+{
+    VastapiFunctions          *func    = (VastapiFunctions *)ctx->vst_func;
+    int                   max_value;
+    double                mse_y, mse_u, mse_v, mse_avg;
+    double               *psnr_buffer = NULL;
+    VASTStatus            vas         = 0;
+    int                   err;
+    double                psnr[4];
+    double                ssim[4];
+    double                qp;
+    vas = func->vastapiMapBuffer(display, ctx->vast_param->brc.psnr_info_buf_id, (void **)&psnr_buffer);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(ctx, AV_LOG_ERROR,
+               "1pass Failed to map psnr buffers: "
+               "%d.\n",
+               vas);
+        err = -1/*AVERROR(EIO)*/;
+        return err;
+    }
+    mse_y   = psnr_buffer[flush_lookahead * 6 + 0]; // mse_y
+    mse_u   = psnr_buffer[flush_lookahead * 6 + 1]; // mse_u
+    mse_v   = psnr_buffer[flush_lookahead * 6 + 2]; // mse_v
+    ssim[0] = psnr_buffer[flush_lookahead * 6 + 3]; // ssim_y
+    ssim[1] = psnr_buffer[flush_lookahead * 6 + 4]; // ssim_u
+    ssim[2] = psnr_buffer[flush_lookahead * 6 + 5]; // ssim_v
+    qp = psnr_buffer[246];
+    if (ctx->vast_param->bitDepthLuma == DEFAULT_VAST) {
+        max_value = (1 << 8) - 1;
+    } else {
+        max_value = (1 << (ctx->vast_param->bitDepthLuma - 8) << 8) - 1;
+    }
+
+    if (ctx->vast_param->psnrType == 411) {
+        mse_avg = (mse_y * 4 + mse_u + mse_v) / 6;
+        ssim[3] = (ssim[0] * 4 + ssim[1] + ssim[2]) / 6;
+    } else {
+        mse_avg = (mse_y * 6 + mse_u + mse_v) / 8;
+        ssim[3] = (ssim[0] * 6 + ssim[1] + ssim[2]) / 8;
+    }
+
+    if (mse_y == 0.0)
+        psnr[0] = 999999.0;
+    else
+        psnr[0] = 10.0 * log10f(max_value * max_value / mse_y);
+
+    if (mse_u == 0.0)
+        psnr[1] = 999999.0;
+    else
+        psnr[1] = 10.0 * log10f(max_value * max_value / mse_u);
+
+    if (mse_v == 0.0)
+        psnr[2] = 999999.0;
+    else
+        psnr[2] = 10.0 * log10f(max_value * max_value / mse_v);
+    psnr[3] = 10.0 * log10f(max_value * max_value / mse_avg);
+
+    av_log(ctx, AV_LOG_DEBUG,
+           "display_order/encode_order %ld/%ld vastapi_encode_output psnr=%lf %lf %lf %lf ssim=%lf %lf %lf %lf,qp=%lf\n",
+           display_order, encode_order, psnr[0], psnr[1], psnr[2], psnr[3], ssim[0], ssim[1], ssim[2], ssim[3],qp);
+    vas = func->vastapiUnmapBuffer(display, ctx->vast_param->brc.psnr_info_buf_id);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(ctx, AV_LOG_ERROR,
+               "1pass Failed to unmap psnr buffers: "
+               "%d.\n",
+               vas);
+        err = -1/*AVERROR(EIO)*/;
+        return err;
+    }
+
+    if (info) {
+        memcpy(&info->psnr, psnr, sizeof(psnr));
+        memcpy(&info->ssim, ssim, sizeof(ssim));
+        info->display_order = psnr_buffer[flush_lookahead * 6 + 6];
+    }
+
+    return 0;
+}
+
+static unsigned char *vaenc_get_encode_buffer(void *pkt, int size)
+{
+    AVPacket *avpkt = (AVPacket *)pkt;
+    int       ret   = av_new_packet(avpkt, size);
+    if (ret) {
+        return NULL;
+    }
+    return avpkt->data;
+}
+
+static void vaenc_buffer_unref(void **buf)
+{
+    return av_buffer_unref(buf);
+}
+
+static void vaenc_frame_free(void **frame)
+{
+    return av_frame_free(frame);
+}
+
+static void *vaenc_av_buffer_pool_get(void *pool)
+{
+    return av_buffer_pool_get(pool);
+}
+
+static void vaenc_av_buffer_pool_uninit(void **ppool)
+{
+    return av_buffer_pool_uninit(ppool);
+}
+
+static int vaenc_vastapi_encode_receive_packet(void *avctx, void *pkt)
+{
+    return ff_vastapi_encode_receive_packet(avctx, pkt);
+}
+
+static int vaenc_vastapi_encode_av1_split_and_combine(void *avctx, void *pkt)
+{
+    return vastapi_encode_av1_split_and_combine(avctx, pkt);
+}
+
+static int vaenc_vastapi_encode_reset_flush(void *avctx)
+{
+    return ff_vastapi_encode_reset_flush((AVCodecContext *)avctx);
+}
+
+static void vaenc_ffmpeg_av_freep(void *arg)
+{
+    av_freep(arg);
+}
+
+static void vaenc_ff_cmd_api(int cmd, void *arg)
+{
+    switch(cmd){
+        case VAENC_CMDTYPE_PSNR:
+        {
+            VASTAPIPsnrCmd *cmd = (VASTAPIPsnrCmd *)arg;
+            vastapi_get_psnr(cmd->ctx, cmd->display,cmd->display_order, cmd->encode_order,cmd->flush_lookahead, NULL);
+            break;
+        }
+        default :break;
+    };
+}
+
+
+static void vaenc_set_flags_and_pts(VASTAPIEncodePicture *pic, void *pkt, int64_t pkt_pts)
+{
+    AVPacket *avpkt = (AVPacket *)pkt;
+    if (pic->type == PICTURE_TYPE_IDR || pic->force_idr == 1)
+        avpkt->flags |= AV_PKT_FLAG_KEY;
+    avpkt->pts = pkt_pts;
+}
+
+static void vaenc_update_pkt_dts(void *avctx, void *pkt, int64_t dts, int delay)
+{
+    AVPacket *avpkt = (AVPacket *)pkt;
+    if (delay == 0) {
+        avpkt->dts = avpkt->pts;
+    } else {
+        avpkt->dts = dts;
+    }
+    av_log(avctx, AV_LOG_DEBUG, "Output packet: pts %" PRId64 " dts %" PRId64 ". size %d\n", avpkt->pts, avpkt->dts,
+           avpkt->size);
+}
+
+static int vaenc_vastapi_encode_issue(void *avctx, void *pic)
+{
+    return vastapi_encode_issue(avctx, pic);
+}
+
+static void vaenc_av_packet_unref(void *pkt)
+{
+    return av_packet_unref(pkt);
+}
+
+static int vaenc_update_av1_pkt(void *vactx, void *avpkt)
+{
+    VASTAPIEncodeContext *ctx         = (VASTAPIEncodeContext *)vactx;
+    AVPacket             *pkt         = (AVPacket *)avpkt;
+    struct av1_pkt       *new_av1_pkt = (struct av1_pkt *)v_queue_get(&ctx->encodePktQ); // lost free
+    AVPacket             *tmppkt      = new_av1_pkt->pkt;
+    av_packet_unref(pkt);
+    av_packet_move_ref(pkt, tmppkt);
+    av_packet_free(&tmppkt);
+    free(new_av1_pkt);
+    ctx->av1_again--;
+    return 0;
+}
+
+static int vastapi_encode_issue(AVCodecContext *avctx, VASTAPIEncodePicture *pic)
+{
+    VASTAPIEncodeContext      *ctx     = avctx->priv_data;
+    VastapiFunctions          *func    = (VastapiFunctions *)ctx->vst_func;
+    VASTDisplay                display = AVVASTAPIDeviceContextPtr(ctx->hwctx)->display;
+    //void                      *opaque  = AVFramePtr(pic->input_image)->opaque;
+    VASTAPIEncodeSlice        *slice;
+    VASTStatus                 vas;
+    int                        err, i;
+    char                       data[MAX_PARAM_BUFFER_SIZE];
+    size_t                     bit_len;
+    av_unused AVFrameSideData *sd;
+
+    static const char * const picture_type_name[] = { "IDR", "I", "P", "B", "2passflush", "flush" };
+    av_log(avctx, AV_LOG_DEBUG,
+           "Issuing encode for pic %" PRId64 "/%" PRId64 " "
+           "as type %s.[endofstream = %d]\n",
+           pic->display_order, pic->encode_order, picture_type_name[pic->type], ctx->end_of_stream);
+
+    if (pic->nb_refs == 0) {
+        av_log(avctx, AV_LOG_DEBUG, "No reference pictures.\n");
+    } else {
+        av_log(avctx, AV_LOG_DEBUG, "Refers to:");
+        for (i = 0; i < pic->nb_refs && pic->refs[i]; i++) {
+            av_log(avctx, AV_LOG_DEBUG, " %" PRId64 "/%" PRId64, pic->refs[i]->display_order,
+                   pic->refs[i]->encode_order);
+        }
+        av_log(avctx, AV_LOG_DEBUG, ".\n");
+    }
+
+    // printf("issue  pic %ld type %d\n",pic->pts, pic->type);
+    av_log(avctx, AV_LOG_DEBUG, "Input surface is %#x.\n", pic->input_surface);
+
+    // pic->passmodel = passmodel;
+
+    // for multicore enc when type is flush ,do not alloc new output surface
+    if ((ctx->vast_param->multimode == VA_MULTI_CORE_MODE &&
+         !((avctx->width * avctx->height < 256 * 256 * 2 * 2 && ctx->vast_param->lookaheadDepth > 0) ||
+           (avctx->width * avctx->height < 256 * 256 && ctx->vast_param->lookaheadDepth == 0))) &&
+        pic->type == CODETYPE_FLUSH) {
+        if (pic->output_buffer == VAST_INVALID_SURFACE) {
+            pic->output_buffer_ref = av_buffer_pool_get(ctx->output_buffer_pool);
+            if (!pic->output_buffer_ref) {
+                err = AVERROR(ENOMEM);
+                goto fail;
+            }
+            pic->output_buffer = (VASTBufferID)(uintptr_t)AVBufferRefPtr(pic->output_buffer_ref)->data;
+            av_log(avctx, AV_LOG_DEBUG, "Output buffer is %#x.\n", pic->output_buffer);
+        }
+    } else {
+
+        pic->output_buffer_ref = av_buffer_pool_get(ctx->output_buffer_pool);
+        if (!pic->output_buffer_ref) {
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+        pic->output_buffer = (VASTBufferID)(uintptr_t)AVBufferRefPtr(pic->output_buffer_ref)->data;
+        av_log(avctx, AV_LOG_DEBUG, "Output buffer is %#x.\n", pic->output_buffer);
+    }
+
+    ///
+    int                nb_side_data = AVFramePtr(pic->input_image)->nb_side_data;
+    VaEncFrameSideData sd_list[MAX_SEI_COUNT];
+    if (nb_side_data > 0) {
+        enum VaEncFrameSideDataType type;
+        enum VaEncCodecID           codec_id;
+
+        for (int i = 0; i < nb_side_data; ++i) {
+            AVFrameSideData *sdsei = AVFramePtr(pic->input_image)->side_data[i];
+            switch (sdsei->type) {
+            case AV_FRAME_DATE_VASTAI_BITRATE_EXT1:
+                type = VAENC_FRAME_DATE_VASTAI_BITRATE_EXT1;
+                break;
+            case AV_FRAME_DATA_UDU_SEI:
+                type = VAENC_FRAME_DATA_UDU_SEI;
+                break;
+            case AV_FRAME_DATA_RESERVED_SEI:
+                type = VAENC_FRAME_DATA_RESERVED_SEI;
+                break;
+            case AV_FRAME_DATA_ROIMAP:
+                type = VAENC_FRAME_DATA_ROIMAP;
+                break;
+            case AV_FRAME_DATA_VASTAI_FRAMERATE:
+                type = VAENC_FRAME_DATA_VASTAI_FRAMERATE;
+                break;
+            case AV_FRAME_DATA_VASTAI_CRF:
+                type = VAENC_FRAME_DATA_VASTAI_CRF;
+                break;
+            case AV_FRAME_DATA_VASTAI_KEYINT:
+                type = VAENC_FRAME_DATA_VASTAI_KEYINT;
+                break;
+#if FF_GE(N441)
+            case AV_FRAME_DATA_SEI_UNREGISTERED: // Since n4.4
+                type = VAENC_FRAME_DATA_SEI_UNREGISTERED;
+                break;
+#endif
+            default:
+                type = VAENC_FRAME_DATA_UNKOWN;
+                break;
+            }
+
+            sd_list[i].data = sdsei->data;
+            sd_list[i].size = sdsei->size;
+            sd_list[i].type = type;
+        }
+    }
+    enum VaEncCodecID codec_id;
+    switch (avctx->codec_descriptor->id) {
+    case AV_CODEC_ID_H264:
+        codec_id = VAENC_CODEC_ID_H264;
+        break;
+    case AV_CODEC_ID_H265:
+        codec_id = VAENC_CODEC_ID_H265;
+        break;
+    default:
+        codec_id = VAENC_CODEC_ID_UNKOWN;
+        break;
+    }
+
+    err = func->vastapiEncIssuePrep(ctx, display, pic, sd_list, nb_side_data, AVFramePtr(pic->input_image)->opaque, FF_LT(N500), avctx->frame_number,
+                                    avctx->width, avctx->height);
+    if (err != 0)
+        goto fail;
+
+    ///
+    VASTAPIEncodeParam *params = malloc((5 + ctx->nb_slices * 2) * sizeof(VASTAPIEncodeParam));
+    int                 index  = 0;
+
+    av_log(avctx, AV_LOG_DEBUG, "vast last frame=%d\n", ctx->vast_last_frame);
+
+    if (ctx->codec->init_picture_params) {
+        err = ctx->codec->init_picture_params(avctx, pic);
+        if (err < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to initialise picture "
+                   "parameters: %d.\n",
+                   err);
+            goto fail;
+        }
+
+        params[index++] = (VASTAPIEncodeParam){ VASTEncPictureParameterBufferType, pic->codec_picture_params,
+                                                ctx->codec->picture_params_size, 0 };
+    }
+
+    if (pic->type == PICTURE_TYPE_IDR) {
+        if (ctx->va_packed_headers & VAST_ENC_PACKED_HEADER_SEQUENCE && ctx->codec->write_sequence_header) {
+            bit_len = 8 * sizeof(data);
+            err     = ctx->codec->write_sequence_header(avctx, data, &bit_len);
+            if (err < 0) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to write per-sequence "
+                       "header: %d.\n",
+                       err);
+                goto fail;
+            }
+            params[index++] = (VASTAPIEncodeParam){ ctx->codec->sequence_header_type, data, bit_len, 1 };
+        }
+    }
+
+    if (ctx->va_packed_headers & VAST_ENC_PACKED_HEADER_PICTURE && ctx->codec->write_picture_header) {
+        bit_len = 8 * sizeof(data);
+        err     = ctx->codec->write_picture_header(avctx, pic, data, &bit_len);
+        if (err < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to write per-picture "
+                   "header: %d.\n",
+                   err);
+            goto fail;
+        }
+        params[index++] = (VASTAPIEncodeParam){ ctx->codec->picture_header_type, data, bit_len, 1 };
+    }
+
+    if (ctx->codec->write_extra_buffer) {
+        for (i = 0;; i++) {
+            size_t len = sizeof(data);
+            int    type;
+            err = ctx->codec->write_extra_buffer(avctx, pic, i, &type, data, &len);
+            if (err == AVERROR_EOF)
+                break;
+            if (err < 0) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to write extra "
+                       "buffer %d: %d.\n",
+                       i, err);
+                goto fail;
+            }
+
+            params[index++] = (VASTAPIEncodeParam){ type, data, len, 0 };
+        }
+    }
+
+    if (ctx->va_packed_headers & VAST_ENC_PACKED_HEADER_MISC && ctx->codec->write_extra_header) {
+        for (i = 0;; i++) {
+            int type;
+            bit_len = 8 * sizeof(data);
+            err     = ctx->codec->write_extra_header(avctx, pic, i, &type, data, &bit_len);
+            if (err == AVERROR_EOF)
+                break;
+            if (err < 0) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to write extra "
+                       "header %d: %d.\n",
+                       i, err);
+                goto fail;
+            }
+
+            params[index++] = (VASTAPIEncodeParam){ type, data, bit_len, 1 };
+        }
+    }
+
+    if (pic->nb_slices == 0)
+        pic->nb_slices = ctx->nb_slices;
+    if ((pic->nb_slices > 0) && (pic->type != CODETYPE_FLUSH)) {
+        int rounding;
+        if (!pic->encode_issued) {
+            pic->slices = av_calloc(pic->nb_slices, sizeof(*pic->slices));
+            if (!pic->slices) {
+                err = AVERROR(ENOMEM);
+                goto fail;
+            }
+        }
+
+        for (i = 0; i < pic->nb_slices; i++)
+            pic->slices[i].row_size = ctx->slice_size;
+
+        rounding = ctx->slice_block_rows - ctx->nb_slices * ctx->slice_size;
+        if (rounding > 0) {
+            // Place rounding error at top and bottom of frame.
+            av_assert0(rounding < pic->nb_slices);
+            // Some Intel drivers contain a bug where the encoder will fail
+            // if the last slice is smaller than the one before it.  Since
+            // that's straightforward to avoid here, just do so.
+            if (rounding <= 2) {
+                for (i = 0; i < rounding; i++)
+                    ++pic->slices[i].row_size;
+            } else {
+                for (i = 0; i < (rounding + 1) / 2; i++)
+                    ++pic->slices[pic->nb_slices - i - 1].row_size;
+                for (i = 0; i < rounding / 2; i++)
+                    ++pic->slices[i].row_size;
+            }
+        } else if (rounding < 0) {
+            // Remove rounding error from last slice only.
+            av_assert0(rounding < ctx->slice_size);
+            pic->slices[pic->nb_slices - 1].row_size += rounding;
+        }
+    }
+    for (i = 0; i < pic->nb_slices; i++) {
+        slice        = &pic->slices[i];
+        slice->index = i;
+        if (i == 0) {
+            slice->row_start   = 0;
+            slice->block_start = 0;
+        } else {
+            const VASTAPIEncodeSlice *prev = &pic->slices[i - 1];
+            slice->row_start               = prev->row_start + prev->row_size;
+            slice->block_start             = prev->block_start + prev->block_size;
+        }
+        slice->block_size = slice->row_size * ctx->slice_block_cols;
+
+        av_log(avctx, AV_LOG_DEBUG,
+               "Slice %d: %d-%d (%d rows), "
+               "%d-%d (%d blocks).\n",
+               i, slice->row_start, slice->row_start + slice->row_size - 1, slice->row_size, slice->block_start,
+               slice->block_start + slice->block_size - 1, slice->block_size);
+
+        if ((ctx->codec->slice_params_size > 0) && (pic->type != CODETYPE_FLUSH)) {
+            if (!pic->encode_issued) {
+                slice->codec_slice_params = av_mallocz(ctx->codec->slice_params_size);
+                if (!slice->codec_slice_params) {
+                    err = AVERROR(ENOMEM);
+                    goto fail;
+                }
+            }
+        }
+
+        if (ctx->codec->init_slice_params && !pic->encode_issued) {
+            err = ctx->codec->init_slice_params(avctx, pic, slice);
+            if (err < 0) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to initialise slice "
+                       "parameters: %d.\n",
+                       err);
+                goto fail;
+            }
+        }
+
+        if (ctx->va_packed_headers & VAST_ENC_PACKED_HEADER_SLICE && ctx->codec->write_slice_header) {
+            bit_len = 8 * sizeof(data);
+            err     = ctx->codec->write_slice_header(avctx, pic, slice, data, &bit_len);
+            if (err < 0) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to write per-slice "
+                       "header: %d.\n",
+                       err);
+                goto fail;
+            }
+            params[index++] = (VASTAPIEncodeParam){ ctx->codec->slice_header_type, data, bit_len, 1 };
+        }
+
+        if (ctx->codec->init_slice_params) {
+            params[index++] = (VASTAPIEncodeParam){ VASTEncSliceParameterBufferType, slice->codec_slice_params,
+                                                    ctx->codec->slice_params_size, 0 };
+        }
+    }
+
+skipinit:
+    err = func->vastapiEncIssue(ctx, display, pic, sd_list, nb_side_data, avctx->width, avctx->height, codec_id,
+                                FF_GE(N441), params, index);
+    free(params);
+    if (err == 0)
+        return 0;
+
+fail:
+    for (i = 0; i < pic->nb_param_buffers; i++)
+        func->vastapiDestroyBuffer(display, pic->param_buffers[i]);
+    for (i = 0; i < pic->nb_slices; i++) {
+        if (pic->slices) {
+            av_freep(&pic->slices[i].priv_data);
+            av_freep(&pic->slices[i].codec_slice_params);
+        }
+    }
+
+    av_freep(&pic->codec_picture_params);
+    av_freep(&pic->param_buffers);
+    av_freep(&pic->slices);
+    av_freep(&pic->roi);
+    av_buffer_unref(&pic->output_buffer_ref);
+    pic->output_buffer = VAST_INVALID_ID;
+    return err;
+}
+
+static int vastapi_encode_head_issue(AVCodecContext *avctx, VASTAPIEncodePicture *pic)
+{
+    VASTAPIEncodeContext      *ctx     = avctx->priv_data;
+    VastapiFunctions          *func    = (VastapiFunctions *)ctx->vst_func;
+    VASTDisplay                display = AVVASTAPIDeviceContextPtr(ctx->hwctx)->display;
+    VASTAPIEncodeSlice        *slice;
+    VASTStatus                 vas;
+    int                        err, i;
+    char                       data[MAX_PARAM_BUFFER_SIZE];
+    size_t                     bit_len;
+    av_unused AVFrameSideData *sd;
+
+    pic->input_image = av_frame_alloc();
+    if (!pic->input_image) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    err = av_hwframe_get_buffer(ctx->input_frames_ref, pic->input_image, 0);
+    if (err < 0) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    pic->input_surface = (VASTSurfaceID)(uintptr_t)((AVFrame*)pic->input_image)->data[3];
+
+    av_log(avctx, AV_LOG_DEBUG, "Input surface is %#x.\n", pic->input_surface);
+
+    pic->output_buffer_ref = av_buffer_pool_get(ctx->output_buffer_pool);
+    if (!pic->output_buffer_ref) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    pic->output_buffer = (VASTBufferID)(uintptr_t)AVBufferRefPtr(pic->output_buffer_ref)->data;
+    av_log(avctx, AV_LOG_DEBUG, "Output buffer is %#x.\n", pic->output_buffer);
+    
+    int                nb_side_data = AVFramePtr(pic->input_image)->nb_side_data;
+    VaEncFrameSideData sd_list[MAX_SEI_COUNT];
+    
+    enum VaEncCodecID codec_id;
+    switch (avctx->codec_descriptor->id) {
+    case AV_CODEC_ID_H264:
+        codec_id = VAENC_CODEC_ID_H264;
+        break;
+    case AV_CODEC_ID_H265:
+        codec_id = VAENC_CODEC_ID_H265;
+        break;
+    default:
+        codec_id = VAENC_CODEC_ID_UNKOWN;
+        break;
+    }
+
+    err = func->vastapiEncIssuePrep(ctx, display, pic, sd_list, nb_side_data, 0, FF_LT(N500), avctx->frame_number,
+                                    avctx->width, avctx->height);
+    if (err != 0)
+        goto fail;
+
+    ///
+    VASTAPIEncodeParam *params = malloc((5 + ctx->nb_slices * 2) * sizeof(VASTAPIEncodeParam));
+    int                 index  = 0;
+
+    av_log(avctx, AV_LOG_DEBUG, "vast last frame=%d\n", ctx->vast_last_frame);
+
+    if (ctx->codec->init_picture_params) {
+        err = ctx->codec->init_picture_params(avctx, pic);
+        if (err < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to initialise picture "
+                   "parameters: %d.\n",
+                   err);
+            goto fail;
+        }
+
+        params[index++] = (VASTAPIEncodeParam){ VASTEncPictureParameterBufferType, pic->codec_picture_params,
+                                                ctx->codec->picture_params_size, 0 };
+    }
+
+    if (pic->nb_slices == 0)
+        pic->nb_slices = ctx->nb_slices;
+    if (pic->nb_slices > 0) {
+        int rounding;
+        if (!pic->encode_issued) {
+            pic->slices = av_calloc(pic->nb_slices, sizeof(*pic->slices));
+            if (!pic->slices) {
+                err = AVERROR(ENOMEM);
+                goto fail;
+            }
+        }
+
+        for (i = 0; i < pic->nb_slices; i++)
+            pic->slices[i].row_size = ctx->slice_size;
+
+        rounding = ctx->slice_block_rows - ctx->nb_slices * ctx->slice_size;
+        if (rounding > 0) {
+            // Place rounding error at top and bottom of frame.
+            av_assert0(rounding < pic->nb_slices);
+            // Some Intel drivers contain a bug where the encoder will fail
+            // if the last slice is smaller than the one before it.  Since
+            // that's straightforward to avoid here, just do so.
+            if (rounding <= 2) {
+                for (i = 0; i < rounding; i++)
+                    ++pic->slices[i].row_size;
+            } else {
+                for (i = 0; i < (rounding + 1) / 2; i++)
+                    ++pic->slices[pic->nb_slices - i - 1].row_size;
+                for (i = 0; i < rounding / 2; i++)
+                    ++pic->slices[i].row_size;
+            }
+        } else if (rounding < 0) {
+            // Remove rounding error from last slice only.
+            av_assert0(rounding < ctx->slice_size);
+            pic->slices[pic->nb_slices - 1].row_size += rounding;
+        }
+    }
+    for (i = 0; i < pic->nb_slices; i++) {
+        slice        = &pic->slices[i];
+        slice->index = i;
+        if (i == 0) {
+            slice->row_start   = 0;
+            slice->block_start = 0;
+        } else {
+            const VASTAPIEncodeSlice *prev = &pic->slices[i - 1];
+            slice->row_start               = prev->row_start + prev->row_size;
+            slice->block_start             = prev->block_start + prev->block_size;
+        }
+        slice->block_size = slice->row_size * ctx->slice_block_cols;
+
+        av_log(avctx, AV_LOG_DEBUG,
+               "Slice %d: %d-%d (%d rows), "
+               "%d-%d (%d blocks).\n",
+               i, slice->row_start, slice->row_start + slice->row_size - 1, slice->row_size, slice->block_start,
+               slice->block_start + slice->block_size - 1, slice->block_size);
+
+        if ((ctx->codec->slice_params_size > 0) && (pic->type != CODETYPE_FLUSH)) {
+            if (!pic->encode_issued) {
+                slice->codec_slice_params = av_mallocz(ctx->codec->slice_params_size);
+                if (!slice->codec_slice_params) {
+                    err = AVERROR(ENOMEM);
+                    goto fail;
+                }
+            }
+        }
+
+        if (ctx->codec->init_slice_params && !pic->encode_issued) {
+            err = ctx->codec->init_slice_params(avctx, pic, slice);
+            if (err < 0) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to initialise slice "
+                       "parameters: %d.\n",
+                       err);
+                goto fail;
+            }
+        }
+
+        if (ctx->va_packed_headers & VAST_ENC_PACKED_HEADER_SLICE && ctx->codec->write_slice_header) {
+            bit_len = 8 * sizeof(data);
+            err     = ctx->codec->write_slice_header(avctx, pic, slice, data, &bit_len);
+            if (err < 0) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to write per-slice "
+                       "header: %d.\n",
+                       err);
+                goto fail;
+            }
+            params[index++] = (VASTAPIEncodeParam){ ctx->codec->slice_header_type, data, bit_len, 1 };
+        }
+
+        if (ctx->codec->init_slice_params) {
+            params[index++] = (VASTAPIEncodeParam){ VASTEncSliceParameterBufferType, slice->codec_slice_params,
+                                                    ctx->codec->slice_params_size, 0 };
+        }
+    }
+
+skipinit:
+    err = func->vastapiEncHeadIssue(ctx, display, pic, sd_list, nb_side_data, avctx->width, avctx->height, codec_id,
+                                FF_GE(N441), params, index);
+    free(params);
+    if (err == 0)
+        return 0;
+
+fail:
+    for (i = 0; i < pic->nb_param_buffers; i++)
+        func->vastapiDestroyBuffer(display, pic->param_buffers[i]);
+    for (i = 0; i < pic->nb_slices; i++) {
+        if (pic->slices) {
+            av_freep(&pic->slices[i].priv_data);
+            av_freep(&pic->slices[i].codec_slice_params);
+        }
+    }
+
+    av_freep(&pic->codec_picture_params);
+    av_freep(&pic->param_buffers);
+    av_freep(&pic->slices);
+    av_freep(&pic->roi);
+    av_buffer_unref(&pic->output_buffer_ref);
+    pic->output_buffer = VAST_INVALID_ID;
+    return err;
+}
+
+static int vastapi_encode_av1_split_and_combine(AVCodecContext *avctx, AVPacket *pkt)
+{
+    VASTAPIEncodeContext *ctx = avctx->priv_data;
+    int                   frameNotShow, err;
+    int                   eos_flag                  = ctx->av1_frame_not_show & 0x80000000;
+    int                   show_existing_packet_last = 0;
+    struct av1_pkt       *new_av1_pkt               = NULL;
+
+    if (ctx->av1pkg == NULL) {
+        ctx->av1pkg = av_malloc(12 * 1024 * 1024);
+        if (ctx->av1pkg == NULL) {
+            av_log(avctx, AV_LOG_DEBUG, "1pass ctx->av1pkg malloc failed\n");
+            return -1;
+        }
+    }
+
+    av_log(avctx, AV_LOG_DEBUG,
+           "eos_flag=%d,pkt->av1_num_nalus=%d av1_frame_not_show %d av1_nalu_size[0] %d av1_nalu_size[1] %d\n",
+           eos_flag, ctx->av1_num_nalus, ctx->av1_frame_not_show, ctx->av1_nalu_size[0], ctx->av1_nalu_size[1]);
+    if (ctx->av1_num_nalus > 1) {
+        if (eos_flag && (ctx->av1size == 0) &&
+            ((pkt->data[0] == 0x12) && (pkt->data[1] == 0x0) && (pkt->data[2] == 0x1E) && (pkt->data[3] == 0x0))) {
+            if (pkt->data[4] == 0x1)
+                show_existing_packet_last = 6;
+            else if (pkt->data[4] == 0x3)
+                show_existing_packet_last = 8;
+            else
+                show_existing_packet_last = 0;
+        }
+
+        if (show_existing_packet_last > 0) {
+            AVPacket *tmppkt1;
+            tmppkt1 = (AVPacket *)malloc(sizeof(AVPacket)); // when to free
+            err     = av_new_packet(tmppkt1, ctx->av1_nalu_size[0] - show_existing_packet_last);
+            memcpy(tmppkt1->data, pkt->data + show_existing_packet_last,
+                   ctx->av1_nalu_size[0] - show_existing_packet_last);
+            tmppkt1->size = ctx->av1_nalu_size[0] - show_existing_packet_last;
+
+            av_shrink_packet(pkt, show_existing_packet_last);
+            pkt->pts = pkt->dts = ctx->output_order;
+            ctx->output_order++;
+
+            new_av1_pkt      = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+            new_av1_pkt->pkt = av_packet_clone(pkt);
+            v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+
+            tmppkt1->dts     = ctx->output_order;
+            tmppkt1->pts     = tmppkt1->dts;
+            new_av1_pkt      = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+            new_av1_pkt->pkt = tmppkt1;
+            v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+            ctx->output_order++;
+
+            int eos_pos = ctx->av1_nalu_size[0];
+            if ((pkt->data[eos_pos] == 0x12) && (pkt->data[eos_pos + 1] == 0x0) && (pkt->data[eos_pos + 2] == 0x1E) &&
+                (pkt->data[eos_pos + 3] == 0x0)) {
+                if (pkt->data[eos_pos + 4] == 0x1)
+                    show_existing_packet_last = 6;
+                else if (pkt->data[eos_pos + 4] == 0x3)
+                    show_existing_packet_last = 8;
+                else
+                    show_existing_packet_last = 0;
+            }
+
+            if (show_existing_packet_last > 0) {
+                AVPacket *tmppkt2;
+                tmppkt2 = (AVPacket *)malloc(sizeof(AVPacket)); // when to free
+                err     = av_new_packet(tmppkt2, show_existing_packet_last);
+                memcpy(tmppkt2->data, pkt->data + ctx->av1_nalu_size[0], show_existing_packet_last);
+                tmppkt2->size = show_existing_packet_last;
+
+                tmppkt2->dts     = ctx->output_order;
+                tmppkt2->pts     = tmppkt2->dts;
+                new_av1_pkt      = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+                new_av1_pkt->pkt = tmppkt2;
+                v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+                ctx->output_order++;
+            }
+        } else {
+            if (eos_flag) {
+                int eos_pos = ctx->av1_nalu_size[0];
+                if ((pkt->data[eos_pos] == 0x12) && (pkt->data[eos_pos + 1] == 0x0) &&
+                    (pkt->data[eos_pos + 2] == 0x1E) && (pkt->data[eos_pos + 3] == 0x0)) {
+                    if (pkt->data[eos_pos + 4] == 0x1)
+                        show_existing_packet_last = 6;
+                    else if (pkt->data[eos_pos + 4] == 0x3)
+                        show_existing_packet_last = 8;
+                }
+            }
+            av_log(avctx, AV_LOG_DEBUG, "show_existing_packet_last=%d\n", show_existing_packet_last);
+            if (show_existing_packet_last > 0) {
+                AVPacket *tmppkt1;
+                tmppkt1 = (AVPacket *)malloc(sizeof(AVPacket)); // when to free
+                err     = av_new_packet(tmppkt1, show_existing_packet_last);
+                memcpy(tmppkt1->data, pkt->data + ctx->av1_nalu_size[0], show_existing_packet_last);
+                tmppkt1->size = show_existing_packet_last;
+
+                if (ctx->av1size > 0) {
+                    memcpy(ctx->av1pkg + ctx->av1size, pkt->data, ctx->av1_nalu_size[0]);
+                    av_grow_packet(pkt, ctx->av1size - show_existing_packet_last);
+                    memcpy(pkt->data, ctx->av1pkg, ctx->av1size + ctx->av1_nalu_size[0]);
+                    pkt->size = ctx->av1size + ctx->av1_nalu_size[0];
+                    pkt->pts = pkt->dts = ctx->output_order;
+                    ctx->output_order++;
+                    ctx->av1size = 0;
+                } else {
+                    pkt->size = ctx->av1_nalu_size[0];
+                    pkt->pts = pkt->dts = ctx->output_order;
+                    ctx->output_order++;
+                }
+
+                new_av1_pkt      = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+                new_av1_pkt->pkt = av_packet_clone(pkt);
+                v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+
+                tmppkt1->dts     = ctx->output_order;
+                tmppkt1->pts     = tmppkt1->dts;
+                new_av1_pkt      = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+                new_av1_pkt->pkt = tmppkt1;
+                v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+                ctx->output_order++;
+            } else {
+                memcpy(ctx->av1pkg, pkt->data + ctx->av1_nalu_size[0], ctx->av1_nalu_size[1]);
+                ctx->av1size = ctx->av1_nalu_size[1];
+                pkt->size    = ctx->av1_nalu_size[0];
+                frameNotShow = (ctx->av1_frame_not_show >> 1) & 1;
+                pkt->pts = pkt->dts = ctx->output_order;
+
+                new_av1_pkt      = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+                new_av1_pkt->pkt = av_packet_clone(pkt);
+                v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+                ctx->output_order++;
+                if (frameNotShow) {
+
+                } else {
+                    AVPacket *tmppkt;
+                    tmppkt = (AVPacket *)malloc(sizeof(AVPacket)); // when to free
+                    err    = av_new_packet(tmppkt, ctx->av1_nalu_size[1]);
+                    memcpy(tmppkt->data, ctx->av1pkg, ctx->av1size);
+                    tmppkt->size = ctx->av1_nalu_size[1];
+                    tmppkt->dts  = ctx->output_order;
+                    tmppkt->pts  = tmppkt->dts;
+
+                    new_av1_pkt      = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+                    new_av1_pkt->pkt = tmppkt;
+                    v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+                    ctx->output_order++;
+                    ctx->av1size = 0;
+                    av_log(avctx, AV_LOG_DEBUG, "av1 Output tmppkt: pts %" PRId64 " dts %" PRId64 ".\n", tmppkt->pts,
+                           tmppkt->dts);
+                }
+            }
+        }
+    } else {
+        frameNotShow = ctx->av1_frame_not_show & 1;
+        if (frameNotShow) {
+            memcpy(ctx->av1pkg + ctx->av1size, pkt->data, ctx->av1_nalu_size[0]); // can pkt->data free
+            ctx->av1size = ctx->av1size + ctx->av1_nalu_size[0];
+
+            if (ctx->encodePktQ.length == 0) {
+                // printf("--- EAGAIN\n");
+                ctx->av1_again++;
+                return AVERROR(EAGAIN);
+            }
+        } else {
+            if (ctx->av1size > 0) {
+                memcpy(ctx->av1pkg + ctx->av1size, pkt->data, ctx->av1_nalu_size[0]);
+                av_grow_packet(pkt, ctx->av1size);
+                memcpy(pkt->data, ctx->av1pkg, pkt->size);
+            }
+            pkt->pts = pkt->dts = ctx->output_order;
+            new_av1_pkt         = (struct av1_pkt *)malloc(sizeof(struct av1_pkt));
+            new_av1_pkt->pkt    = av_packet_clone(pkt);
+            v_queue_put(&ctx->encodePktQ, (struct node *)new_av1_pkt);
+            ctx->output_order++;
+            ctx->av1size = 0;
+        }
+    }
+
+    new_av1_pkt      = (struct av1_pkt *)v_queue_get(&ctx->encodePktQ);
+    AVPacket *tmppkt = new_av1_pkt->pkt;
+    av_packet_unref(pkt);
+    av_packet_move_ref(pkt, tmppkt);
+    av_packet_free(&tmppkt);
+    free(new_av1_pkt);
+
+    if ((ctx->vast_param->lookaheadDepth == 0) && (ctx->vast_param->multimode != VA_MULTI_CORE_MODE ||
+        (ctx->vast_param->multimode == VA_MULTI_CORE_MODE && 
+        (ctx->ff_param.width * ctx->ff_param.height < 256 * 256 && ctx->vast_param->lookaheadDepth == 0))))
+        ctx->flush_pkt_flag = (eos_flag == 0) ? 0 : 1;
+
+    av_log(avctx, AV_LOG_DEBUG, "av1s Output packet: pts %" PRId64 " dts %" PRId64 ".\n", pkt->pts, pkt->dts);
+    return 0;
+}
+
+static VASTAPIEncodePicture *vastapi_encode_alloc(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext *ctx = avctx->priv_data;
+    VASTAPIEncodePicture *pic;
+
+    pic = av_mallocz(sizeof(*pic));
+    if (!pic)
+        return NULL;
+
+    if (ctx->codec->picture_priv_data_size > 0) {
+        pic->priv_data = av_mallocz(ctx->codec->picture_priv_data_size);
+        if (!pic->priv_data) {
+            av_freep(&pic);
+            return NULL;
+        }
+        pic->should_do_2pass = -1;
+    }
+
+    pic->input_surface = VAST_INVALID_ID;
+    pic->recon_surface = VAST_INVALID_ID;
+    pic->output_buffer = VAST_INVALID_ID;
+
+    return pic;
+}
+
+static int vastapi_encode_check_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    VASTAPIEncodeContext *ctx = avctx->priv_data;
+
+    // if ((frame->crop_top  || frame->crop_bottom ||
+    //      frame->crop_left || frame->crop_right) && !ctx->crop_warned) {
+    //     av_log(avctx, AV_LOG_WARNING, "Cropping information on input "
+    //            "frames ignored due to lack of API support.\n");
+    //     ctx->crop_warned = 1;
+    // }
+    if (frame->crop_top || frame->crop_bottom || frame->crop_left || frame->crop_right) {
+        ctx->vast_param->preprocess.cropped_height    = frame->height - frame->crop_top;
+        ctx->vast_param->preprocess.cropped_width     = frame->width - frame->crop_bottom;
+        ctx->vast_param->preprocess.inputFrameCropFlag = 1;
+        ctx->vast_param->preprocess.inputFrameCropTop = frame->crop_top;
+        ctx->vast_param->preprocess.inputFrameCropBottom = frame->crop_bottom;
+        ctx->vast_param->preprocess.inputFrameCropLeft = frame->crop_left;
+        ctx->vast_param->preprocess.inputFrameCropRight = frame->crop_right;
+    }
+    if (!ctx->roi_allowed) {
+        AVFrameSideData *sd = av_frame_get_side_data(frame, AV_FRAME_DATA_REGIONS_OF_INTEREST);
+
+        if (sd && !ctx->roi_warned) {
+            av_log(avctx, AV_LOG_WARNING,
+                   "ROI side data on input "
+                   "frames ignored due to lack of driver support.\n");
+            ctx->roi_warned = 1;
+        }
+    }
+
+    return 0;
+}
+
+#if FF_LT(N441)
+int ff_vastapi_encode_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+#else
+static int vastapi_encode_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+#endif
+{
+    VASTAPIEncodeContext *ctx  = avctx->priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->vst_func;
+    VASTAPIEncodePicture *pic;
+    AVFrameSideData      *sd;
+    int64_t               current_order = ctx->input_order;
+
+    int err;
+
+    if (frame) {
+        int64_t pkt_duration = 0;
+        av_log(avctx, AV_LOG_DEBUG, "Input frame: %ux%u (%" PRId64 ").%d type %d\n", frame->width, frame->height, frame->pts,
+               frame->pkt_duration,frame->pict_type);
+        
+        pkt_duration = func->vastapiEncCalDurPar(ctx, frame->time_base, frame->pts);
+
+        err = vastapi_encode_check_frame(avctx, frame);
+        if (err < 0)
+            return err;
+        pic = vastapi_encode_alloc(avctx);
+        if (!pic)
+            return AVERROR(ENOMEM);
+
+        pic->input_image = av_frame_alloc();
+        if (!pic->input_image) {
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+#if 0 // test idr
+        if(ctx->input_order%60==0)
+        {
+            ctx->vast_param->insertIDR = ctx->input_order;//keep until this gop end
+            pic->force_idr = 1;
+        }
+        else{
+            pic->force_idr = 0;
+        }
+#endif
+
+        if (frame->pict_type == AV_PICTURE_TYPE_I) {
+            ctx->vast_param->insertIDR = ctx->input_order;
+            pic->force_idr             = 1;
+            pic->insertIDR             = ctx->input_order;
+        } else {
+            pic->force_idr = 0;
+            pic->insertIDR = 0;
+        }
+
+        sd = av_frame_get_side_data(frame, AV_FRAME_DATA_VASTAI_KEYINT);
+        if (sd && sd->size == sizeof(uint32_t) && sd->data != NULL) {
+            av_log(avctx, AV_LOG_DEBUG, "set new keyint = %d\n", *((uint32_t *)sd->data));
+            ctx->vast_param->intraPicRate = *((uint32_t *)sd->data);
+            ;
+            ctx->input_order_change_point = ctx->input_order;
+        }
+
+        current_order = ctx->input_order - ctx->input_order_change_point;
+
+        if (ctx->input_order == 0 || frame->pict_type == AV_PICTURE_TYPE_I ||
+            (ctx->vast_param->intraPicRate > 0 && current_order % ctx->vast_param->intraPicRate == 0 &&
+             !ctx->vast_param->openGop) ||
+            (ctx->input_order_change_point == ctx->input_order)) {
+            pic->force_idr = 1;
+        }
+        pic->input_surface = (VASTSurfaceID)(uintptr_t)frame->data[3];
+        pic->pts           = frame->pts;
+        pic->pts_internal  = ctx->pts_internal++;
+#if FF_LT(N441)
+        err = av_frame_ref(pic->input_image, frame);
+        if (err < 0)
+            goto fail;
+#else
+        av_frame_move_ref(pic->input_image, frame);
+#endif
+        
+        func->vastapiEncCalTimeStampPar(ctx, pic, pkt_duration);
+
+        pic->display_order = ctx->input_order;
+        ++ctx->input_order;
+        pic->reserved = av_mallocz(sizeof(VASTAPIEncodeOutInfo));
+        if (!pic->reserved) {
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+
+        if (ctx->pic_start) {
+            ctx->pic_end->next = pic;
+            ctx->pic_end       = pic;
+        } else {
+            ctx->pic_start = pic;
+            ctx->pic_end   = pic;
+        }
+
+    } else {
+        ctx->end_of_stream = 1;
+
+        // Fix timestamps if we hit end-of-stream before the initial decode
+        // delay has elapsed.
+        if (ctx->pic_end && ctx->input_order < ctx->decode_delay)
+            ctx->dts_pts_diff = ctx->pic_end->pts - ctx->first_pts;
+    }
+
+    return 0;
+
+fail:
+    func->vastapiEncFree(ctx, pic);
+    return err;
+}
+
+
+int ff_vastapi_encode_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    VASTAPIEncodeContext *ctx  = avctx->priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->vst_func;
+    VASTDisplay        display = AVVASTAPIDeviceContextPtr(ctx->hwctx)->display;
+    VASTAPIEncodePicture *pic;
+    int                   err;
+
+#if FF_GE(N441)
+    AVFrame *frame = ctx->frame;
+    err            = ff_encode_get_frame(avctx, frame);
+    if (err < 0 && err != AVERROR_EOF)
+        return err;
+
+    if (err == AVERROR_EOF)
+        frame = NULL;
+
+    err = vastapi_encode_send_frame(avctx, frame);
+    if (err < 0) {
+        return err;
+    }
+#endif
+
+    func->vastapiEncCheckAV11Pass(ctx, pkt);
+    if (!ctx->pic_start) {
+        if (ctx->end_of_stream) {
+            return AVERROR_EOF;
+        } else
+            return AVERROR(EAGAIN);
+    }
+    if (ctx->flush_pkt_flag &&
+        (ctx->vast_param->lookaheadDepth > 0 || 
+        (ctx->vast_param->multimode == VA_MULTI_CORE_MODE 
+        && ((ctx->ff_param.width * ctx->ff_param.height > 256 * 256 && ctx->vast_param->lookaheadDepth == 0) ||
+        (ctx->ff_param.width * ctx->ff_param.height > 512 * 512 && ctx->vast_param->lookaheadDepth > 0))))) {
+            err = func->vastapiEncFlushEncoder(ctx, pkt);         
+        return err;
+    }
+
+    // printf("111 ctx->encodePktQ.length=%d\n",ctx->encodePktQ.length);
+    if ((avctx->codec_id == AV_CODEC_ID_AV1) && (ctx->flush_pkt_flag == 1) && (ctx->encodePktQ.length > 0) &&
+        (ctx->vast_param->lookaheadDepth == 0 && (ctx->vast_param->multimode != VA_MULTI_CORE_MODE || 
+        (ctx->vast_param->multimode == VA_MULTI_CORE_MODE && 
+            (ctx->ff_param.width * ctx->ff_param.height < 256 * 256 && ctx->vast_param->lookaheadDepth == 0))))) {
+        struct av1_pkt *new_av1_pkt = (struct av1_pkt *)v_queue_get(&ctx->encodePktQ);
+        AVPacket       *tmppkt      = new_av1_pkt->pkt;
+        av_packet_unref(pkt);
+        av_packet_move_ref(pkt, tmppkt);
+        av_packet_free(&tmppkt);
+        free(new_av1_pkt);
+        ctx->av1_again--;
+        return 0;
+    }
+
+    // update lastpic
+    if (ctx->end_of_stream) {
+        VASTAPIEncodePicture *tmp         = NULL;
+        uint32_t              lastDisplay = 0;
+        for (tmp = ctx->pic_start; tmp; tmp = tmp->next)
+            lastDisplay = tmp->display_order;
+        ctx->vast_param->lastPic = lastDisplay;
+        ctx->vast_last_frame++;
+    }
+
+    // printf("send avctx frame %d\n",avctx->frame_number);
+    pic = NULL;
+    err = func->vastapiEncPickNext(ctx, avctx->width, avctx->height, avctx->codec_id == AV_CODEC_ID_AV1, &pic);
+    if (err == 6) {
+        pic->input_image = av_frame_alloc();
+        if (!pic->input_image) {
+            err = AVERROR(ENOMEM);
+        } else {
+            err = 5;
+        }
+    }
+    if (pic) {
+        av_log(avctx, AV_LOG_DEBUG, "ffmpeg pic frame %ld type %d \n", pic->pts, pic->type);
+        ctx->vast_param->lastCodingType = pic->type - 1; // temp for lastpic type 0:idr 1:I 2:P 3:B
+    }
+
+    av_log(avctx, AV_LOG_DEBUG, "ff_vastapi_encode_receive_packet err=%d,vast_last_frame=%d,ctx->gop_size=%d\n", err,
+           ctx->vast_last_frame, ctx->gop_size);
+
+    if (!pic) {
+        if (func->vastapiEncAllowOptimizeDelay(ctx)) {
+            int32_t delay2pass = (ctx->vast_param->lookaheadDepth + ctx->vast_param->brc.gop_size - 2) / ctx->vast_param->brc.gop_size * ctx->vast_param->brc.gop_size + 1;
+            if ((ctx->input_order >= delay2pass) && !ctx->end_of_stream) {
+                return func->vastapiEnc2PassOnlyIssue(ctx, pic, pkt);
+            } else {
+                return err;
+            }
+        } else {
+            return err;
+        }
+    }
+
+    av_assert0(pic);
+
+    if (pic->type != CODETYPE_FLUSH) // temp last 5 for flush only
+        pic->encode_order = ctx->encode_order++;
+    av_log(avctx, AV_LOG_DEBUG, "pic->encode_order=%d\n", pic->encode_order);
+    pic->passmodel = NORMALPASS;
+    err            = vastapi_encode_issue(avctx, pic);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Encode failed: %d.\n", err);
+        return err;
+    }
+
+    err = func->vastapiEnc1PassIssue(ctx, pic, pkt);
+    if (!err || err == AVERROR(EAGAIN)) {
+        return err;
+    }      
+
+    err = func->vastapiEncGetEncoderOutput(ctx, pic, pkt);
+    return err;
+}
+
+static void vastapi_encode_free_output_buffer(void *opaque, uint8_t *data)
+{
+    AVCodecContext       *avctx = opaque;
+    VASTAPIEncodeContext *ctx   = avctx->priv_data;
+    VastapiFunctions     *func  = (VastapiFunctions *)ctx->vst_func;
+    VASTBufferID          buffer_id;
+
+    buffer_id = (VASTBufferID)(uintptr_t)data;
+    av_log(avctx, AV_LOG_DEBUG, "will Freed output buffer %#x\n", buffer_id);
+    func->vastapiDestroyBuffer(AVVASTAPIDeviceContextPtr(ctx->hwctx)->display, buffer_id);
+}
+
+static AVBufferRef *vastapi_encode_alloc_output_buffer(void *opaque, int size)
+{
+    AVCodecContext       *avctx   = opaque;
+    VASTAPIEncodeContext *ctx     = avctx->priv_data;
+    VastapiFunctions     *func    = (VastapiFunctions *)ctx->vst_func;
+    VASTDisplay           display = AVVASTAPIDeviceContextPtr(ctx->hwctx)->display;
+    VASTBufferID          buffer_id;
+    VASTStatus            vas;
+    AVBufferRef          *ref;
+
+    vas = func->vastapiEncAllocOutputBuff(ctx, display, avctx->codec_id == AV_CODEC_ID_AV1, avctx->width, avctx->height,
+                                          &buffer_id);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create bitstream output buffer: %d .\n", vas);
+        return NULL;
+    }
+
+    av_log(avctx, AV_LOG_DEBUG, "Allocated output buffer %#x\n", buffer_id);
+
+    ref = av_buffer_create((uint8_t *)(uintptr_t)buffer_id, sizeof(buffer_id), &vastapi_encode_free_output_buffer,
+                           avctx, AV_BUFFER_FLAG_READONLY);
+    if (!ref) {
+        func->vastapiDestroyBuffer(AVVASTAPIDeviceContextPtr(ctx->hwctx)->display, buffer_id);
+        return NULL;
+    }
+
+    return ref;
+}
+
+static av_cold int vastapi_encode_create_recon_frames(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext  *ctx         = avctx->priv_data;
+    AVVASTAPIHWConfig     *hwconfig    = NULL;
+    AVHWFramesConstraints *constraints = NULL;
+    enum AVPixelFormat     recon_format;
+    int                    err, i;
+
+    hwconfig = av_hwdevice_hwconfig_alloc(AVBufferRefPtr(ctx->device_ref));
+    if (!hwconfig) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    hwconfig->config_id = ctx->va_config;
+
+    constraints = av_hwdevice_get_hwframe_constraints(AVBufferRefPtr(ctx->device_ref), hwconfig);
+    if (!constraints) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    // Probably we can use the input surface format as the surface format
+    // of the reconstructed frames.  If not, we just pick the first (only?)
+    // format in the valid list and hope that it all works.
+    recon_format = AV_PIX_FMT_NONE;
+    if (constraints->valid_sw_formats) {
+        for (i = 0; constraints->valid_sw_formats[i] != AV_PIX_FMT_NONE; i++) {
+            if (AVHWFramesContextPtr(ctx->input_frames)->sw_format == constraints->valid_sw_formats[i]) {
+                recon_format = AVHWFramesContextPtr(ctx->input_frames)->sw_format;
+                break;
+            }
+        }
+        if (recon_format == AV_PIX_FMT_NONE) {
+            // No match.  Just use the first in the supported list and
+            // hope for the best.
+            recon_format = constraints->valid_sw_formats[0];
+        }
+    } else {
+        // No idea what to use; copy input format.
+        recon_format = AVHWFramesContextPtr(ctx->input_frames)->sw_format;
+    }
+    av_log(avctx, AV_LOG_DEBUG,
+           "Using %s as format of "
+           "reconstructed frames.\n",
+           av_get_pix_fmt_name(recon_format));
+
+    if (ctx->surface_width < constraints->min_width || ctx->surface_height < constraints->min_height ||
+        ctx->surface_width > constraints->max_width || ctx->surface_height > constraints->max_height) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Hardware does not support encoding at "
+               "size %dx%d (constraints: width %d-%d height %d-%d).\n",
+               ctx->surface_width, ctx->surface_height, constraints->min_width, constraints->max_width,
+               constraints->min_height, constraints->max_height);
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+
+    av_freep(&hwconfig);
+    av_hwframe_constraints_free(&constraints);
+
+    ctx->recon_frames_ref = av_hwframe_ctx_alloc(AVBufferRefPtr(ctx->device_ref));
+    if (!ctx->recon_frames_ref) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    ctx->recon_frames = (AVHWFramesContext *)AVBufferRefPtr(ctx->recon_frames_ref)->data;
+
+    AVHWFramesContextPtr(ctx->recon_frames)->format            = AV_PIX_FMT_VASTAPI;
+    AVHWFramesContextPtr(ctx->recon_frames)->sw_format         = recon_format;
+    AVHWFramesContextPtr(ctx->recon_frames)->width             = ctx->surface_width;
+    AVHWFramesContextPtr(ctx->recon_frames)->height            = ctx->surface_height;
+    AVHWFramesContextPtr(ctx->recon_frames)->frame_buffer_flag = 1; // not to alloc useless recon pic buffer.
+
+    err = av_hwframe_ctx_init(ctx->recon_frames_ref);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to initialise reconstructed "
+               "frame context: %d.\n",
+               err);
+        goto fail;
+    }
+
+    err = 0;
+fail:
+    av_freep(&hwconfig);
+    av_hwframe_constraints_free(&constraints);
+    return err;
+}
+
+static int ff_vastapi_encode_get_psnr(const AVCodecContext *avctx, int lookahead_size, PsnrSsimInfo *info)
+{
+    VASTAPIEncodeContext *ctx = NULL;
+
+    if (!avctx || !avctx->priv_data || !info) {
+        av_log(avctx, AV_LOG_ERROR,"error, get psnr invalid input, info=%p avctx=%p\n", info, avctx);
+        return -1;
+    }
+
+    ctx = avctx->priv_data;
+
+    return vastapi_get_psnr(ctx, ((AVVASTAPIDeviceContext *)ctx->hwctx)->display, 0, 0, lookahead_size, info);
+}
+
+// vastai reset
+int avcodec_vastapi_reset_flush(const AVCodecContext *avctx)
+{
+    // not reset hw, only cleanup data
+    AVCodecInternal *avci = avctx->internal;
+    int              ret;
+    avci->draining      = 0;
+    avci->draining_done = 0;
+    ret                 = ff_vastapi_encode_reset_flush(avctx);
+    return ret;
+}
+
+int avcodec_vastapi_get_psnr(const AVCodecContext *avctx, int lookahead_size, PsnrSsimInfo *info)
+{
+    int ret;
+    ret = ff_vastapi_encode_get_psnr(avctx, lookahead_size, info);
+    return ret;
+}
+
+static av_cold int _vastapi_encode_init(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext *ctx = avctx->priv_data;
+    int                   err;
+
+#if FF_GE(N441)
+    ctx->frame = av_frame_alloc();
+    if (!ctx->frame) {
+        return AVERROR(ENOMEM);
+    }
+#endif
+
+    if (!avctx->hw_frames_ctx) {
+        av_log(avctx, AV_LOG_ERROR,
+               "A hardware frames reference is "
+               "required to associate the encoding device.\n");
+        return AVERROR(EINVAL);
+    }
+    ctx->va_config                            = VAST_INVALID_ID;
+    ctx->va_context                           = VAST_INVALID_ID;
+    ctx->pts_internal                         = 0;
+    ctx->is_av1                               = avctx->codec_id == AV_CODEC_ID_AV1;
+    ctx->get_encode_buffer                    = vaenc_get_encode_buffer;
+    ctx->av_buffer_unref                      = vaenc_buffer_unref;
+    ctx->av_frame_free                        = vaenc_frame_free;
+    ctx->av_buffer_pool_uninit                = vaenc_av_buffer_pool_uninit;
+    ctx->av_buffer_pool_get                   = vaenc_av_buffer_pool_get;
+    ctx->vastapi_encode_receive_packet        = vaenc_vastapi_encode_receive_packet;
+    ctx->vastapi_encode_av1_split_and_combine = vaenc_vastapi_encode_av1_split_and_combine;
+    ctx->vastapi_encode_reset_flush           = vaenc_vastapi_encode_reset_flush;
+    ctx->set_flags_and_pts                    = vaenc_set_flags_and_pts;
+    ctx->update_pkt_dts                       = vaenc_update_pkt_dts;
+    ctx->vastapi_encode_issue                 = vaenc_vastapi_encode_issue;
+    ctx->av_packet_unref                      = vaenc_av_packet_unref;
+    ctx->update_av1_pkt                       = vaenc_update_av1_pkt;
+    ctx->ffmpeg_av_freep                      = vaenc_ffmpeg_av_freep;
+    ctx->ff_av_log                            = av_log;
+    ctx->ff_cmd_api                           = vaenc_ff_cmd_api;
+    ctx->pframe_number                        = &avctx->frame_number;
+    ctx->avctx                                = avctx;
+#if FF_GE(N441)
+    ctx->ff_version = 2;
+#else
+    ctx->ff_version = 1;
+#endif
+
+    ctx->input_frames_ref = av_buffer_ref(avctx->hw_frames_ctx);
+    if (!ctx->input_frames_ref) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    ctx->input_frames = (AVHWFramesContext *)AVBufferRefPtr(ctx->input_frames_ref)->data;
+
+    ctx->device_ref = av_buffer_ref(AVHWFramesContextPtr(ctx->input_frames)->device_ref);
+    if (!ctx->device_ref) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    ctx->device   = (AVHWDeviceContext *)AVBufferRefPtr(ctx->device_ref)->data;
+    ctx->hwctx    = AVHWDeviceContextPtr(ctx->device)->hwctx;
+    ctx->vst_func = ((AVVASTAPIDeviceContext *)ctx->hwctx)->vst_func;
+
+    v_queue_init(&ctx->encodePktQ);
+    ctx->av1_again = 0;
+
+    ctx->reserved = av_mallocz(sizeof(VASTAPIEncodeOutInfo));
+    if (!ctx->reserved) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    
+    err = ff_vastapi_encode_reset_init(avctx);
+    if (err != 0)
+        goto fail;
+
+    return 0;
+
+fail:
+    return err;
+}
+
+static av_cold int _vastapi_encode_close(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext *ctx     = avctx->priv_data;
+    VastapiFunctions     *func    = (VastapiFunctions *)ctx->vst_func;
+    VASTDisplay           display = NULL;
+    VASTAPIEncodePicture *pic, *next;
+
+    if(!ctx->hwctx){
+        return AVERROR(EINVAL);
+    }
+    display = AVVASTAPIDeviceContextPtr(ctx->hwctx)->display;
+    if (avctx->codec_id == AV_CODEC_ID_AV1) // av1mp4
+        av_free(ctx->av1pkg);
+
+    func->vastapiEncFreeVastBuff2(ctx, display);
+    for (pic = ctx->pic_start; pic; pic = next) {
+        next = pic->next;
+        func->vastapiEncFree(ctx, pic);
+    }
+
+    if (ctx->va_context != VAST_INVALID_ID) {
+        if (AVVASTAPIDeviceContextPtr(ctx->hwctx)) {
+            func->vastapiDestroyContext(AVVASTAPIDeviceContextPtr(ctx->hwctx)->display, ctx->va_context);
+        }
+        ctx->va_context = VAST_INVALID_ID;
+    }
+
+    av_buffer_pool_uninit(&ctx->output_buffer_pool);
+
+    if (ctx->va_config != VAST_INVALID_ID) {
+        if (AVVASTAPIDeviceContextPtr(ctx->hwctx)) {
+            func->vastapiDestroyConfig(AVVASTAPIDeviceContextPtr(ctx->hwctx)->display, ctx->va_config);
+        }
+        ctx->va_config = VAST_INVALID_ID;
+    }
+
+#if FF_GE(N441)
+    av_frame_free(&ctx->frame);
+#endif
+
+    av_freep(&ctx->codec_sequence_params);
+    av_freep(&ctx->codec_picture_params);
+
+    func->vastapiFreeMemory(ctx->vast_param); // vastai add cfg
+
+    av_buffer_unref(&ctx->recon_frames_ref);
+    av_buffer_unref(&ctx->input_frames_ref);
+    av_buffer_unref(&ctx->device_ref);
+
+    v_queue_free(&ctx->encodePktQ);
+    av_freep(&ctx->reserved);
+
+    return 0;
+}
+
+av_cold int ff_vastapi_encode_reset_init(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext   *ctx         = avctx->priv_data;
+    VastapiFunctions       *func        = (VastapiFunctions *)ctx->vst_func;
+    VASTDisplay             display     = AVVASTAPIDeviceContextPtr(ctx->hwctx)->display;
+    AVVASTAPIFramesContext *recon_hwctx = NULL;
+    VASTStatus              vas;
+    int                     err;
+
+    // add cfg begin
+    int is_fmt_yuvj  = (AVHWFramesContextPtr(ctx->input_frames)->sw_format == AV_PIX_FMT_YUVJ420P);
+    int is_color_set = (avctx->color_primaries != AVCOL_PRI_UNSPECIFIED || avctx->color_trc != AVCOL_TRC_UNSPECIFIED ||
+                        avctx->colorspace != AVCOL_SPC_UNSPECIFIED);
+    int is_vui       = is_color_set || is_fmt_yuvj;
+
+    if (is_fmt_yuvj) {
+        avctx->color_range = AVCOL_RANGE_JPEG;
+        if (!is_color_set) {
+            avctx->color_primaries = 1;
+            avctx->color_trc       = 1;
+            avctx->colorspace      = 1;
+        }
+    }
+
+    // add vui aspect ration info
+    int num = 0, den = 0;
+    if (avctx->sample_aspect_ratio.num != 0 && avctx->sample_aspect_ratio.den != 0) {
+        av_reduce(&num, &den, avctx->sample_aspect_ratio.num, avctx->sample_aspect_ratio.den, 65535);
+    }
+    ctx->display                  = display;
+    ctx->ff_param.width           = avctx->width;
+    ctx->ff_param.height          = avctx->height;
+    ctx->ff_param.bit_rate        = avctx->bit_rate;
+    ctx->ff_param.profile         = avctx->profile;
+    ctx->ff_param.color_primaries = avctx->color_primaries;
+    ctx->ff_param.color_trc       = avctx->color_trc;
+    ctx->ff_param.colorspace      = avctx->colorspace;
+
+    ctx->ff_param.framerate = &avctx->framerate;
+    ctx->ff_param.time_base = &avctx->time_base;
+
+    err = func->vastapiEncInitVastParam(
+        ctx, avctx->color_range == AVCOL_RANGE_JPEG, avctx->codec_id == AV_CODEC_ID_AV1,
+        (avctx->sw_pix_fmt == AV_PIX_FMT_YUV420P10LE || avctx->sw_pix_fmt == AV_PIX_FMT_P010LE), &avctx->gop_size,
+        &avctx->max_b_frames, is_vui, num, den);
+    if (err < 0)
+        goto fail;
+
+    // add cfg end
+
+    const AVPixFmtDescriptor *desc;
+    desc = av_pix_fmt_desc_get(AVHWFramesContextPtr(ctx->input_frames)->sw_format);
+    if (!desc) {
+        av_log(avctx, AV_LOG_ERROR, "Invalid input pixfmt (%d).\n", AVHWFramesContextPtr(ctx->input_frames)->sw_format);
+        return AVERROR(EINVAL);
+    }
+    ctx->ff_param.desc.name          = desc->name;
+    ctx->ff_param.desc.nb_components = desc->nb_components;
+    ctx->ff_param.desc.log2_chroma_w = desc->log2_chroma_w;
+    ctx->ff_param.desc.log2_chroma_h = desc->log2_chroma_h;
+    ctx->ff_param.desc.depth         = desc->comp[0].depth;
+
+    int fr_num, fr_den;
+    if (avctx->framerate.num > 0 && avctx->framerate.den > 0)
+        av_reduce(&fr_num, &fr_den, avctx->framerate.num, avctx->framerate.den, 65535);
+    else
+        av_reduce(&fr_num, &fr_den, avctx->time_base.den, avctx->time_base.num, 65535);
+
+    int is_qsacle = avctx->flags & AV_CODEC_FLAG_QSCALE;
+
+    ctx->ff_param.bit_rate                    = avctx->bit_rate;
+    ctx->ff_param.global_quality              = avctx->global_quality;
+    ctx->ff_param.gop_size                    = avctx->gop_size;
+    ctx->ff_param.rc_buffer_size              = avctx->rc_buffer_size;
+    ctx->ff_param.rc_initial_buffer_occupancy = avctx->rc_initial_buffer_occupancy;
+    ctx->ff_param.rc_max_rate                 = avctx->rc_max_rate;
+
+    ctx->ff_param.compression_level = avctx->compression_level;
+    ctx->ff_param.max_b_frames      = avctx->max_b_frames;
+    ctx->ff_param.width             = avctx->width;
+    ctx->ff_param.height            = avctx->height;
+    ctx->ff_param.slices            = avctx->slices;
+
+    err = func->vastapiEncConfigCreate(ctx, display, fr_num, fr_den, is_qsacle, &avctx->profile);
+    if (err < 0)
+        goto fail;
+
+    ctx->rate_emu = ctx->vast_param->lkLatency;
+
+#if FF_LT(N441)
+    ctx->rate_emu = 0;
+#else
+    if (avctx->codec_id == AV_CODEC_ID_AV1 || ctx->vast_param->brc.gop_size == 0 ||
+        ctx->vast_param->multimode != VA_SINGLE_CORE_MODE || ctx->vast_param->lookaheadDepth == 0 ||
+        ctx->vast_param->openGop)
+        ctx->rate_emu = 0;
+#endif
+    ctx->av1_eos = 0;
+
+    err = vastapi_encode_create_recon_frames(avctx);
+    if (err < 0)
+        goto fail;
+
+    recon_hwctx = AVHWFramesContextPtr(ctx->recon_frames)->hwctx;
+    vas = func->vastapiCreateContext(display, ctx->va_config, ctx->surface_width, ctx->surface_height, VA_PROGRESSIVE,
+                                     recon_hwctx->surface_ids, recon_hwctx->nb_surfaces, &ctx->va_context);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create encode pipeline context: %d.\n", vas);
+        err = AVERROR(EIO);
+        goto fail;
+    }
+
+    if (ctx->vast_param->brc.ipcmmap_is_enabled || ctx->vast_param->brc.roimap_is_enabled) {
+        unsigned int   unit_size;
+        unsigned int   pitch;
+        unsigned char *buffer         = NULL;
+        VASTBufferID   roi_map_buf_id = 0; // raoli over
+        unsigned int   block_size;
+
+        // create roimap buffer when 2 pass
+        if (ctx->vast_param->lookaheadDepth) {
+            err = func->vastapiCreateBuffer2(display, ctx->va_context, VASTHANTROEncROIMapBufferType, avctx->width,
+                                             avctx->height, &unit_size, &pitch, &roi_map_buf_id);
+
+            ctx->vast_param->brc.roimap_ipcmmap_buf_id = roi_map_buf_id;
+        } else if ((ctx->vast_param->lookaheadDepth == 0) && ctx->vast_param->brc.roimap_is_enabled) {
+            uint32_t deltaqpwidth  = (avctx->width + 63) / 64 * 8;
+            uint32_t deltaqpheight = (avctx->height + 63) / 64 * 8;
+            uint32_t deltaqpsize   = deltaqpwidth * deltaqpheight;
+
+            if (ctx->vast_param->brc.roimap_ipcmmap_buf_id == 0) {
+                err = func->vastapiCreateBuffer(display, ctx->va_context, HANTROEncROIMapBufferType, deltaqpsize, 1,
+                                                NULL, &roi_map_buf_id);
+            }
+            ctx->vast_param->brc.roimap_ipcmmap_buf_id = roi_map_buf_id;
+        }
+    }
+
+    ctx->output_buffer_pool =
+        av_buffer_pool_init2(sizeof(VASTBufferID), avctx, &vastapi_encode_alloc_output_buffer, NULL);
+    if (!ctx->output_buffer_pool) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    if (ctx->codec->configure) {
+        err = ctx->codec->configure(avctx);
+        if (err < 0)
+            goto fail;
+    }
+
+    if (ctx->vast_param->lookaheadDepth > 0 && ctx->vast_param->brc.gop_size == 1) {
+        ctx->output_delay = 1;
+        ctx->decode_delay = 1;
+    } else {
+        ctx->output_delay = ctx->b_per_p;
+        ctx->decode_delay = ctx->max_b_depth;
+    }
+
+    if (ctx->codec->sequence_params_size > 0) {
+        ctx->codec_sequence_params = av_mallocz(ctx->codec->sequence_params_size);
+        if (!ctx->codec_sequence_params) {
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+    }
+    if (ctx->codec->picture_params_size > 0) {
+        ctx->codec_picture_params = av_mallocz(ctx->codec->picture_params_size);
+        if (!ctx->codec_picture_params) {
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+    }
+
+    if (ctx->codec->init_sequence_params) {
+        err = ctx->codec->init_sequence_params(avctx);
+        if (err < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Codec sequence initialisation "
+                   "failed: %d.\n",
+                   err);
+            goto fail;
+        }
+    }
+
+    if(avctx->codec_id != AV_CODEC_ID_MJPEG) // vastai head
+    {
+        char data[MAX_PARAM_BUFFER_SIZE];
+        size_t len = sizeof(data);
+        VASTAPIEncodePicture *pic;
+
+        pic = vastapi_encode_alloc(avctx);//head temp pic
+        if (!pic)
+            return AVERROR(ENOMEM);
+
+        err = vastapi_encode_head_issue(avctx, pic);
+        if (err < 0) {
+            printf("Encode head issue failed: %d.\n", err);
+        }
+
+        // err = vastapi_encode_output_head(avctx, pic, data, &len);
+        err = func->vastapiEncHeadOutput(ctx, pic, data, &len);
+        if (err < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Encode head out failed: %d.\n", err);
+            func->vastapiEncFreeHead(ctx, pic);
+            goto fail;
+        } else{
+            avctx->extradata_size = len;
+            avctx->extradata = av_mallocz(avctx->extradata_size +
+                                        AV_INPUT_BUFFER_PADDING_SIZE);
+            if (!avctx->extradata) {
+                err = AVERROR(ENOMEM);
+                func->vastapiEncFreeHead(ctx, pic);
+                goto fail;
+            }
+            av_log(avctx, AV_LOG_DEBUG, "will cp head size %ld\n",len);
+            memcpy(avctx->extradata, data, avctx->extradata_size);
+        }
+
+        func->vastapiEncFreeHead(ctx, pic);
+    }
+    return 0;
+fail:
+    return err;
+}
+
+av_cold int ff_vastapi_encode_reset_close(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext *ctx     = avctx->priv_data;
+    VastapiFunctions     *func    = (VastapiFunctions *)ctx->vst_func;
+    VASTDisplay           display = AVVASTAPIDeviceContextPtr(ctx->hwctx)->display;
+    VASTAPIEncodePicture *pic, *next;
+
+    func->vastapiEncFreeVastBuff2(ctx, display);
+    for (pic = ctx->pic_start; pic; pic = next) {
+        next = pic->next;
+        func->vastapiEncFree(ctx, pic);
+    }
+
+    if (ctx->va_context != VAST_INVALID_ID) {
+        if (AVVASTAPIDeviceContextPtr(ctx->hwctx)) {
+            func->vastapiDestroyContext(AVVASTAPIDeviceContextPtr(ctx->hwctx)->display, ctx->va_context);
+        }
+        ctx->va_context = VAST_INVALID_ID;
+    }
+    av_buffer_pool_uninit(&ctx->output_buffer_pool);
+    if (ctx->va_config != VAST_INVALID_ID) {
+        if (AVVASTAPIDeviceContextPtr(ctx->hwctx)) {
+            func->vastapiDestroyConfig(AVVASTAPIDeviceContextPtr(ctx->hwctx)->display, ctx->va_config);
+        }
+        ctx->va_config = VAST_INVALID_ID;
+    }
+
+    av_freep(&ctx->codec_sequence_params);
+    av_freep(&ctx->codec_picture_params);
+
+    av_freep(&ctx->vast_param); // vastai add cfg
+
+    av_buffer_unref(&ctx->recon_frames_ref);
+    return 0;
+}
+
+// vastai reset
+av_cold int ff_vastapi_encode_reset_flush(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext *ctx = avctx->priv_data;
+    int                   err, vas;
+
+    av_log(avctx, AV_LOG_DEBUG, "in ff_vastapi_encode_reset_flush\n");
+    err                       = ff_vastapi_encode_reset_close(avctx);
+    ctx->input_order          = 0;
+    ctx->pts_internal         = 0;
+    ctx->dts_index            = 0;
+    ctx->encode_order         = 0;
+    ctx->output_order         = 0;
+    ctx->pic_start            = NULL;
+    ctx->pic_end              = NULL;
+    ctx->outpic_start         = NULL;
+    ctx->outpic_end           = NULL;
+    ctx->next_prev            = NULL;
+    ctx->nb_global_params     = 0;
+    ctx->end_of_stream        = 0;
+    ctx->nb_config_attributes = 0;
+    ctx->flush_pkt_flag       = 0;
+    ctx->lookaheadPacket_size = 0;
+    ctx->vast_last_frame      = 0;
+    // if change w and h
+    ctx->surface_width  = FFALIGN(avctx->width, 64);  // changed by vastai (vsi align 16 -> 64)
+    ctx->surface_height = FFALIGN(avctx->height, 64); // changed by vastai (height not align)
+    err                 = ff_vastapi_encode_reset_init(avctx);
+
+    return 0;
+
+fail:
+    return err;
+}
+
+///
+#define FOR_QUICKTIME
+
+static int vastapi_encode_h264_write_access_unit(AVCodecContext *avctx, char *data, size_t *data_len,
+                                                 CodedBitstreamFragment *au)
+{
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+    int                       err;
+
+    err = ff_cbs_write_fragment_data(priv->cbc, au);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to write packed header.\n");
+        return err;
+    }
+
+    if (*data_len < 8 * au->data_size - au->data_bit_padding) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Access unit too large: "
+               "%zu < %zu.\n",
+               *data_len, 8 * au->data_size - au->data_bit_padding);
+        return AVERROR(ENOSPC);
+    }
+
+    memcpy(data, au->data, au->data_size);
+    *data_len = 8 * au->data_size - au->data_bit_padding;
+
+    return 0;
+}
+
+static int vastapi_encode_h264_add_nal(AVCodecContext *avctx, CodedBitstreamFragment *au, void *nal_unit)
+{
+    VASTAPIEncodeH264Context *priv   = avctx->priv_data;
+    H264RawNALUnitHeader     *header = nal_unit;
+    int                       err;
+
+    err = ff_cbs_insert_unit_content(PRIV_CBC au, -1, header->nal_unit_type, nal_unit, NULL);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to add NAL unit: "
+               "type = %d.\n",
+               header->nal_unit_type);
+        return err;
+    }
+
+    return 0;
+}
+
+static int vastapi_encode_h264_write_sequence_header(AVCodecContext *avctx, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err;
+
+    if (priv->aud_needed) {
+        err = vastapi_encode_h264_add_nal(avctx, au, &priv->raw_aud);
+        if (err < 0)
+            goto fail;
+        priv->aud_needed = 0;
+    }
+
+    err = vastapi_encode_h264_add_nal(avctx, au, &priv->raw_sps);
+    if (err < 0)
+        goto fail;
+
+    err = vastapi_encode_h264_add_nal(avctx, au, &priv->raw_pps);
+    if (err < 0)
+        goto fail;
+
+    err = vastapi_encode_h264_write_access_unit(avctx, data, data_len, au);
+fail:
+    ff_cbs_fragment_reset(PRIV_CBC au);
+    return err;
+}
+
+static int vastapi_encode_h264_write_slice_header(AVCodecContext *avctx, VASTAPIEncodePicture *pic,
+                                                  VASTAPIEncodeSlice *slice, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err;
+
+    if (priv->aud_needed) {
+        err = vastapi_encode_h264_add_nal(avctx, au, &priv->raw_aud);
+        if (err < 0)
+            goto fail;
+        priv->aud_needed = 0;
+    }
+
+    err = vastapi_encode_h264_add_nal(avctx, au, &priv->raw_slice);
+    if (err < 0)
+        goto fail;
+
+    err = vastapi_encode_h264_write_access_unit(avctx, data, data_len, au);
+fail:
+    ff_cbs_fragment_reset(PRIV_CBC au);
+    return err;
+}
+
+#if FF_LT(N441)
+static int vastapi_encode_h264_write_extra_header(AVCodecContext *avctx, VASTAPIEncodePicture *pic, int index,
+                                                  int *type, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err, i;
+
+    if (priv->sei_needed) {
+        H264RawSEI *sei = &priv->raw_sei;
+
+        if (priv->aud_needed) {
+            err = vastapi_encode_h264_add_nal(avctx, au, &priv->raw_aud);
+            if (err < 0)
+                goto fail;
+            priv->aud_needed = 0;
+        }
+
+        *sei = (H264RawSEI) {
+            .nal_unit_header = {
+                .nal_unit_type = H264_NAL_SEI,
+            },
+        };
+
+        i = 0;
+
+        if (priv->sei_needed & SEI_IDENTIFIER) {
+            sei->payload[i].payload_type                   = H264_SEI_TYPE_USER_DATA_UNREGISTERED;
+            sei->payload[i].payload.user_data_unregistered = priv->sei_identifier;
+            ++i;
+        }
+        if (priv->sei_needed & SEI_TIMING) {
+            if (pic->type == PICTURE_TYPE_IDR) {
+                sei->payload[i].payload_type             = H264_SEI_TYPE_BUFFERING_PERIOD;
+                sei->payload[i].payload.buffering_period = priv->sei_buffering_period;
+                ++i;
+            }
+            sei->payload[i].payload_type       = H264_SEI_TYPE_PIC_TIMING;
+            sei->payload[i].payload.pic_timing = priv->sei_pic_timing;
+            ++i;
+        }
+        if (priv->sei_needed & SEI_RECOVERY_POINT) {
+            sei->payload[i].payload_type           = H264_SEI_TYPE_RECOVERY_POINT;
+            sei->payload[i].payload.recovery_point = priv->sei_recovery_point;
+            ++i;
+        }
+
+        sei->payload_count = i;
+        av_assert0(sei->payload_count > 0);
+
+        err = vastapi_encode_h264_add_nal(avctx, au, sei);
+        if (err < 0)
+            goto fail;
+        priv->sei_needed = 0;
+
+        err = vastapi_encode_h264_write_access_unit(avctx, data, data_len, au);
+        if (err < 0)
+            goto fail;
+
+        ff_cbs_fragment_reset(priv->cbc, au);
+
+        *type = VASTEncPackedHeaderRawData;
+        return 0;
+    } else {
+        return AVERROR_EOF;
+    }
+
+fail:
+    ff_cbs_fragment_reset(priv->cbc, au);
+    return err;
+}
+#else
+static int vastapi_encode_h264_write_extra_header(AVCodecContext *avctx, VASTAPIEncodePicture *pic, int index,
+                                                  int *type, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err;
+
+    if (priv->sei_needed) {
+        if (priv->aud_needed) {
+            err = vastapi_encode_h264_add_nal(avctx, au, &priv->raw_aud);
+            if (err < 0)
+                goto fail;
+            priv->aud_needed = 0;
+        }
+        if (priv->sei_needed & SEI_IDENTIFIER) {
+            err =
+                ff_cbs_sei_add_message(priv->cbc, au, 1, SEI_TYPE_USER_DATA_UNREGISTERED, &priv->sei_identifier, NULL);
+            if (err < 0)
+                goto fail;
+        }
+        if (priv->sei_needed & SEI_TIMING) {
+            if (pic->type == PICTURE_TYPE_IDR) {
+                err = ff_cbs_sei_add_message(priv->cbc, au, 1, SEI_TYPE_BUFFERING_PERIOD, &priv->sei_buffering_period,
+                                             NULL);
+                if (err < 0)
+                    goto fail;
+            }
+            err = ff_cbs_sei_add_message(priv->cbc, au, 1, SEI_TYPE_PIC_TIMING, &priv->sei_pic_timing, NULL);
+            if (err < 0)
+                goto fail;
+        }
+        if (priv->sei_needed & SEI_RECOVERY_POINT) {
+            err = ff_cbs_sei_add_message(priv->cbc, au, 1, SEI_TYPE_RECOVERY_POINT, &priv->sei_recovery_point, NULL);
+            if (err < 0)
+                goto fail;
+        }
+
+        priv->sei_needed = 0;
+
+        err = vastapi_encode_h264_write_access_unit(avctx, data, data_len, au);
+        if (err < 0)
+            goto fail;
+
+        ff_cbs_fragment_reset(au);
+
+        *type = VASTEncPackedHeaderRawData;
+        return 0;
+    } else {
+        return AVERROR_EOF;
+    }
+
+fail:
+    ff_cbs_fragment_reset(au);
+    return err;
+}
+#endif
+
+static int vastapi_encode_h264_init_sequence_params(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext               *ctx  = avctx->priv_data;
+    VASTAPIEncodeH264Context           *priv = avctx->priv_data;
+    H264RawSPS                         *sps  = &priv->raw_sps;
+    H264RawPPS                         *pps  = &priv->raw_pps;
+    VASTEncSequenceParameterBufferH264 *vseq = ctx->codec_sequence_params;
+    VASTEncPictureParameterBufferH264  *vpic = ctx->codec_picture_params;
+
+    memset(sps, 0, sizeof(*sps));
+    memset(pps, 0, sizeof(*pps));
+#ifdef FOR_QUICKTIME
+    sps->nal_unit_header.nal_ref_idc = 1;
+#else
+    sps->nal_unit_header.nal_ref_idc = 3;
+#endif
+    sps->nal_unit_header.nal_unit_type = H264_NAL_SPS;
+
+    sps->profile_idc = avctx->profile & 0xff;
+
+    if (avctx->profile == FF_PROFILE_H264_CONSTRAINED_BASELINE || avctx->profile == FF_PROFILE_H264_MAIN)
+        sps->constraint_set1_flag = 1;
+
+    if (avctx->profile == FF_PROFILE_H264_HIGH)
+        sps->constraint_set3_flag = ctx->gop_size == 1;
+
+#ifdef FOR_QUICKTIME
+    sps->constraint_set4_flag = 0;
+    sps->constraint_set5_flag = 0;
+#else
+    if (avctx->profile == FF_PROFILE_H264_MAIN || avctx->profile == FF_PROFILE_H264_HIGH) {
+        sps->constraint_set4_flag = 1;
+        sps->constraint_set5_flag = ctx->b_per_p == 0;
+    }
+#endif
+#ifdef FOR_QUICKTIME
+    if (ctx->vast_param->brc.gop_size == 1) {
+        priv->dpb_frames = 0;
+    } else {
+        if (ctx->vast_param->adaptiveGOPEn) {
+            priv->dpb_frames = 4;
+        } else {
+            priv->dpb_frames = 1 + ctx->max_b_depth;
+        }
+    }
+#else
+    if (ctx->gop_size == 1) {
+        priv->dpb_frames = 0;
+    } else {
+        priv->dpb_frames = ctx->max_b_depth;
+    }
+#endif
+
+
+    if (avctx->level != FF_LEVEL_UNKNOWN) {
+        sps->level_idc = avctx->level;
+    } else {
+        sps->level_idc = 51; // vastai
+    }
+
+    sps->seq_parameter_set_id = 0;
+    sps->chroma_format_idc    = 1;
+#ifdef FOR_QUICKTIME
+    sps->log2_max_frame_num_minus4 = 8;
+#else
+    sps->log2_max_frame_num_minus4 = 4;
+#endif
+    sps->pic_order_cnt_type = 0;
+    // vastai
+    sps->log2_max_pic_order_cnt_lsb_minus4 = ctx->vast_param->log2MaxPicOrderCntLsb - 4;
+
+    sps->max_num_ref_frames = priv->dpb_frames;
+
+#ifdef FOR_QUICKTIME
+    sps->gaps_in_frame_num_allowed_flag = 1;
+#endif
+
+    sps->pic_width_in_mbs_minus1        = priv->mb_width - 1;
+    sps->pic_height_in_map_units_minus1 = priv->mb_height - 1;
+
+    sps->frame_mbs_only_flag       = 1;
+    sps->direct_8x8_inference_flag = 1;
+
+    if (avctx->width != 16 * priv->mb_width || avctx->height != 16 * priv->mb_height) {
+        sps->frame_cropping_flag = 1;
+
+        sps->frame_crop_left_offset   = 0;
+        sps->frame_crop_right_offset  = (16 * priv->mb_width - avctx->width) / 2;
+        sps->frame_crop_top_offset    = 0;
+        sps->frame_crop_bottom_offset = (16 * priv->mb_height - avctx->height) / 2;
+    } else {
+        sps->frame_cropping_flag = 0;
+    }
+
+    sps->vui_parameters_present_flag = 1;
+
+    if (avctx->sample_aspect_ratio.num != 0 && avctx->sample_aspect_ratio.den != 0) {
+        static const AVRational sar_idc[] = {
+            { 0, 0 },   { 1, 1 },   { 12, 11 }, { 10, 11 }, { 16, 11 },  { 40, 33 }, { 24, 11 }, { 20, 11 }, { 32, 11 },
+            { 80, 33 }, { 18, 11 }, { 15, 11 }, { 64, 33 }, { 160, 99 }, { 4, 3 },   { 3, 2 },   { 2, 1 },
+        };
+        int num, den, i;
+        av_reduce(&num, &den, avctx->sample_aspect_ratio.num, avctx->sample_aspect_ratio.den, 65535);
+        for (i = 0; i < FF_ARRAY_ELEMS(sar_idc); i++) {
+            if (num == sar_idc[i].num && den == sar_idc[i].den) {
+                sps->vui.aspect_ratio_idc = i;
+                break;
+            }
+        }
+        if (i >= FF_ARRAY_ELEMS(sar_idc)) {
+            sps->vui.aspect_ratio_idc = 255;
+            sps->vui.sar_width        = num;
+            sps->vui.sar_height       = den;
+        }
+        sps->vui.aspect_ratio_info_present_flag = 1;
+    }
+
+    if (avctx->color_range != AVCOL_RANGE_UNSPECIFIED || avctx->color_primaries != AVCOL_PRI_UNSPECIFIED ||
+        avctx->color_trc != AVCOL_TRC_UNSPECIFIED || avctx->colorspace != AVCOL_SPC_UNSPECIFIED) {
+        sps->vui.video_signal_type_present_flag = 1;
+        sps->vui.video_format                   = 5; // Unspecified.
+        sps->vui.video_full_range_flag          = avctx->color_range == AVCOL_RANGE_JPEG;
+
+        if (avctx->color_primaries != AVCOL_PRI_UNSPECIFIED || avctx->color_trc != AVCOL_TRC_UNSPECIFIED ||
+            avctx->colorspace != AVCOL_SPC_UNSPECIFIED) {
+            sps->vui.colour_description_present_flag = 1;
+            sps->vui.colour_primaries                = avctx->color_primaries;
+            sps->vui.transfer_characteristics        = avctx->color_trc;
+            sps->vui.matrix_coefficients             = avctx->colorspace;
+        } else {
+            sps->vui.colour_description_present_flag = 0;
+            sps->vui.colour_primaries                = avctx->color_primaries;
+            sps->vui.transfer_characteristics        = avctx->color_trc;
+            sps->vui.matrix_coefficients             = avctx->colorspace;
+        }
+    } else {
+        sps->vui.video_format             = 5;
+        sps->vui.video_full_range_flag    = 0;
+        sps->vui.colour_primaries         = avctx->color_primaries;
+        sps->vui.transfer_characteristics = avctx->color_trc;
+        sps->vui.matrix_coefficients      = avctx->colorspace;
+    }
+
+    if (avctx->chroma_sample_location != AVCHROMA_LOC_UNSPECIFIED) {
+        sps->vui.chroma_loc_info_present_flag     = 1;
+        sps->vui.chroma_sample_loc_type_top_field = sps->vui.chroma_sample_loc_type_bottom_field =
+            avctx->chroma_sample_location - 1;
+    }
+
+    sps->vui.timing_info_present_flag = 1;
+    if (avctx->framerate.num > 0 && avctx->framerate.den > 0) {
+        sps->vui.num_units_in_tick = avctx->framerate.den;
+        sps->vui.time_scale        = 2 * avctx->framerate.num;
+#ifdef FOR_QUICKTIME
+        sps->vui.fixed_frame_rate_flag = 0;
+#else
+        sps->vui.fixed_frame_rate_flag = 1;
+#endif
+    } else {
+        sps->vui.num_units_in_tick     = avctx->time_base.num;
+        sps->vui.time_scale            = 2 * avctx->time_base.den;
+        sps->vui.fixed_frame_rate_flag = 0;
+    }
+
+    if (priv->sei & SEI_TIMING) {
+        H264RawHRD                *hrd = &sps->vui.nal_hrd_parameters;
+        H264RawSEIBufferingPeriod *bp  = &priv->sei_buffering_period;
+
+        sps->vui.nal_hrd_parameters_present_flag = 1;
+
+        hrd->cpb_cnt_minus1 = 0;
+
+        // Try to scale these to a sensible range so that the
+        // golomb encode of the value is not overlong.
+        hrd->bit_rate_scale           = av_clip_uintp2(av_log2(ctx->va_bit_rate) - 15 - 6, 4);
+        hrd->bit_rate_value_minus1[0] = (ctx->va_bit_rate >> hrd->bit_rate_scale + 6) - 1;
+
+        hrd->cpb_size_scale           = av_clip_uintp2(av_log2(ctx->hrd_params.buffer_size) - 15 - 4, 4);
+        hrd->cpb_size_value_minus1[0] = (ctx->hrd_params.buffer_size >> hrd->cpb_size_scale + 4) - 1;
+
+        // CBR mode as defined for the HRD cannot be achieved without filler
+        // data, so this flag cannot be set even with VASTAPI CBR modes.
+        hrd->cbr_flag[0] = 0;
+
+        hrd->initial_cpb_removal_delay_length_minus1 = 23;
+        hrd->cpb_removal_delay_length_minus1         = 23;
+        hrd->dpb_output_delay_length_minus1          = 7;
+        hrd->time_offset_length                      = 0;
+
+        bp->seq_parameter_set_id = sps->seq_parameter_set_id;
+
+        // This calculation can easily overflow 32 bits.
+        bp->nal.initial_cpb_removal_delay[0] =
+            90000 * (uint64_t)ctx->hrd_params.initial_buffer_fullness / ctx->hrd_params.buffer_size;
+        bp->nal.initial_cpb_removal_delay_offset[0] = 0;
+    } else {
+        sps->vui.nal_hrd_parameters_present_flag = 0;
+        sps->vui.low_delay_hrd_flag              = 1 - sps->vui.fixed_frame_rate_flag;
+    }
+
+    sps->vui.bitstream_restriction_flag              = 1;
+    sps->vui.motion_vectors_over_pic_boundaries_flag = 1;
+#ifdef FOR_QUICKTIME
+    sps->vui.log2_max_mv_length_horizontal = 10;
+    sps->vui.log2_max_mv_length_vertical   = 8;
+#else
+    sps->vui.log2_max_mv_length_horizontal = 15;
+    sps->vui.log2_max_mv_length_vertical   = 15;
+#endif
+#ifdef FOR_QUICKTIME
+    if (ctx->vast_param->adaptiveGOPEn && ctx->vast_param->bBPyramid != 0) {
+        sps->vui.max_num_reorder_frames  = 3;
+        sps->vui.max_dec_frame_buffering = 4;
+    } else if (ctx->vast_param->bBPyramid == 0) {
+        sps->vui.max_num_reorder_frames  = 1;
+        sps->vui.max_dec_frame_buffering = 2;
+    } else {
+        sps->vui.max_num_reorder_frames  = ctx->max_b_depth;
+        sps->vui.max_dec_frame_buffering = ctx->max_b_depth + 1;
+    }
+#else
+    sps->vui.max_num_reorder_frames        = ctx->max_b_depth;
+    sps->vui.max_dec_frame_buffering       = ctx->max_b_depth + 1;
+#endif
+#ifdef FOR_QUICKTIME
+    pps->nal_unit_header.nal_ref_idc = 1;
+#else
+    pps->nal_unit_header.nal_ref_idc       = 3;
+#endif
+    pps->nal_unit_header.nal_unit_type = H264_NAL_PPS;
+
+    pps->pic_parameter_set_id = 0;
+    pps->seq_parameter_set_id = 0;
+
+    pps->entropy_coding_mode_flag =
+        !(sps->profile_idc == FF_PROFILE_H264_BASELINE || sps->profile_idc == FF_PROFILE_H264_EXTENDED ||
+          sps->profile_idc == FF_PROFILE_H264_CAVLC_444);
+    if (!priv->coder && pps->entropy_coding_mode_flag)
+        pps->entropy_coding_mode_flag = 0;
+
+    pps->num_ref_idx_l0_default_active_minus1 = 0;
+    pps->num_ref_idx_l1_default_active_minus1 = 0;
+
+    pps->pic_init_qp_minus26 = priv->fixed_qp_idr - 26;
+
+    if (sps->profile_idc == FF_PROFILE_H264_BASELINE || sps->profile_idc == FF_PROFILE_H264_EXTENDED ||
+        sps->profile_idc == FF_PROFILE_H264_MAIN) {
+        pps->more_rbsp_data = 0;
+    } else {
+        pps->more_rbsp_data = 1;
+
+        pps->transform_8x8_mode_flag = 1;
+    }
+#ifdef FOR_QUICKTIME
+    pps->deblocking_filter_control_present_flag = 1;
+#endif
+
+    *vseq = (VASTEncSequenceParameterBufferH264) {
+        .seq_parameter_set_id = sps->seq_parameter_set_id,
+        .level_idc        = sps->level_idc,
+        .intra_period = ctx->vast_param->intraPicRate,     //vastai
+        .intra_idr_period = ctx->vast_param->intraPicRate, //vastai
+        .ip_period        = ctx->b_per_p + 1,
+
+        .bits_per_second       = ctx->va_bit_rate,
+        .max_num_ref_frames    = sps->max_num_ref_frames,
+        .picture_width_in_mbs  = sps->pic_width_in_mbs_minus1 + 1,
+        .picture_height_in_mbs = sps->pic_height_in_map_units_minus1 + 1,
+
+        .seq_fields.bits = {
+            .chroma_format_idc                 = sps->chroma_format_idc,
+            .frame_mbs_only_flag               = sps->frame_mbs_only_flag,
+            .mb_adaptive_frame_field_flag      = sps->mb_adaptive_frame_field_flag,
+            .seq_scaling_matrix_present_flag   = sps->seq_scaling_matrix_present_flag,
+            .direct_8x8_inference_flag         = sps->direct_8x8_inference_flag,
+            .log2_max_frame_num_minus4         = sps->log2_max_frame_num_minus4,
+            .pic_order_cnt_type                = sps->pic_order_cnt_type,
+            .log2_max_pic_order_cnt_lsb_minus4 = sps->log2_max_pic_order_cnt_lsb_minus4,
+            .delta_pic_order_always_zero_flag  = sps->delta_pic_order_always_zero_flag,
+        },
+
+        .bit_depth_luma_minus8   = sps->bit_depth_luma_minus8,
+        .bit_depth_chroma_minus8 = sps->bit_depth_chroma_minus8,
+
+        .frame_cropping_flag      = sps->frame_cropping_flag,
+        .frame_crop_left_offset   = sps->frame_crop_left_offset,
+        .frame_crop_right_offset  = sps->frame_crop_right_offset,
+        .frame_crop_top_offset    = sps->frame_crop_top_offset,
+        .frame_crop_bottom_offset = sps->frame_crop_bottom_offset,
+
+        .vui_parameters_present_flag = sps->vui_parameters_present_flag,
+
+        .vui_fields.bits = {
+            .aspect_ratio_info_present_flag = sps->vui.aspect_ratio_info_present_flag,
+            .timing_info_present_flag       = sps->vui.timing_info_present_flag,
+            .bitstream_restriction_flag     = sps->vui.bitstream_restriction_flag,
+            .log2_max_mv_length_horizontal  = sps->vui.log2_max_mv_length_horizontal,
+            .log2_max_mv_length_vertical    = sps->vui.log2_max_mv_length_vertical,
+        },
+
+        .aspect_ratio_idc  = sps->vui.aspect_ratio_idc,
+        .sar_width         = sps->vui.sar_width,
+        .sar_height        = sps->vui.sar_height,
+        .num_units_in_tick = sps->vui.num_units_in_tick,
+        .time_scale        = sps->vui.time_scale,
+    };
+
+    *vpic = (VASTEncPictureParameterBufferH264) {
+        .CurrPic = {
+            .picture_id = VAST_INVALID_ID,
+            .flags      = VAST_PICTURE_H264_INVALID,
+        },
+
+        .coded_buf = VAST_INVALID_ID,
+
+        .pic_parameter_set_id = pps->pic_parameter_set_id,
+        .seq_parameter_set_id = pps->seq_parameter_set_id,
+
+        .pic_init_qp                  = pps->pic_init_qp_minus26 + 26,
+        .num_ref_idx_l0_active_minus1 = pps->num_ref_idx_l0_default_active_minus1,
+        .num_ref_idx_l1_active_minus1 = pps->num_ref_idx_l1_default_active_minus1,
+
+        .chroma_qp_index_offset        = pps->chroma_qp_index_offset,
+        .second_chroma_qp_index_offset = pps->second_chroma_qp_index_offset,
+
+        .pic_fields.bits = {
+            .entropy_coding_mode_flag        = pps->entropy_coding_mode_flag,
+            .weighted_pred_flag              = pps->weighted_pred_flag,
+            .weighted_bipred_idc             = pps->weighted_bipred_idc,
+            .constrained_intra_pred_flag     = pps->constrained_intra_pred_flag,
+            .transform_8x8_mode_flag         = pps->transform_8x8_mode_flag,
+            .deblocking_filter_control_present_flag =
+                pps->deblocking_filter_control_present_flag,
+            .redundant_pic_cnt_present_flag  = pps->redundant_pic_cnt_present_flag,
+            .pic_order_present_flag          =
+                pps->bottom_field_pic_order_in_frame_present_flag,
+            .pic_scaling_matrix_present_flag = pps->pic_scaling_matrix_present_flag,
+        },
+    };
+
+    return 0;
+}
+
+static int vastapi_encode_h264_init_picture_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic)
+{
+    VASTAPIEncodeContext              *ctx   = avctx->priv_data;
+    VASTAPIEncodeH264Context          *priv  = avctx->priv_data;
+    VASTAPIEncodeH264Picture          *hpic  = pic->priv_data;
+    VASTAPIEncodePicture              *prev  = pic->prev;
+    VASTAPIEncodeH264Picture          *hprev = prev ? prev->priv_data : NULL;
+    VASTEncPictureParameterBufferH264 *vpic  = pic->codec_picture_params;
+    int                                i;
+
+    int                   left  = 0;
+    VASTAPIEncodePicture *inPic = NULL;
+    for (inPic = ctx->pic_start; inPic; inPic = inPic->next) {
+        if (!inPic->encode_issued) {
+            left++;
+        }
+    }
+    av_log(avctx, AV_LOG_DEBUG, "h264 isAtlast=%d\n", left);
+    if (ctx->end_of_stream && left == 1) {
+        vpic->last_picture = 1;
+    }
+    if (pic->type == PICTURE_TYPE_IDR) {
+        av_assert0(pic->display_order == pic->encode_order);
+
+        hpic->frame_num      = 0;
+        hpic->last_idr_frame = pic->display_order;
+        hpic->idr_pic_id     = hprev ? hprev->idr_pic_id + 1 : 0;
+
+        hpic->primary_pic_type = 0;
+        hpic->slice_type       = 7;
+    } else if (pic->type != CODETYPE_FLUSH) { // vframe bug{
+        av_assert0(prev);
+
+        hpic->frame_num = hprev->frame_num + prev->is_reference;
+
+        hpic->last_idr_frame = hprev->last_idr_frame;
+        hpic->idr_pic_id     = hprev->idr_pic_id;
+
+        if (pic->type == PICTURE_TYPE_I) {
+            hpic->slice_type       = 7;
+            hpic->primary_pic_type = 0;
+        } else if (pic->type == PICTURE_TYPE_P) {
+            hpic->slice_type       = 5;
+            hpic->primary_pic_type = 1;
+        } else {
+            hpic->slice_type       = 6;
+            hpic->primary_pic_type = 2;
+        }
+    }
+
+    hpic->pic_order_cnt = pic->display_order - hpic->last_idr_frame;
+    hpic->dpb_delay     = pic->display_order - pic->encode_order + ctx->max_b_depth;
+    hpic->cpb_delay     = pic->encode_order - hpic->last_idr_frame;
+
+    if (priv->aud) {
+        priv->aud_needed = 1;
+        priv->raw_aud = (H264RawAUD) {
+            .nal_unit_header = {
+                .nal_unit_type = H264_NAL_AUD,
+            },
+            .primary_pic_type  = hpic->primary_pic_type,
+        };
+    } else {
+        priv->aud_needed = 0;
+    }
+
+    priv->sei_needed = 0;
+
+    if (priv->sei & SEI_IDENTIFIER && pic->encode_order == 0)
+        priv->sei_needed |= SEI_IDENTIFIER;
+
+    if (priv->sei & SEI_TIMING) {
+        priv->sei_pic_timing = (H264RawSEIPicTiming){
+            .cpb_removal_delay = 2 * hpic->cpb_delay,
+            .dpb_output_delay  = 2 * hpic->dpb_delay,
+        };
+
+        priv->sei_needed |= SEI_TIMING;
+    }
+
+    if (priv->sei & SEI_RECOVERY_POINT && pic->type == PICTURE_TYPE_I) {
+        priv->sei_recovery_point = (H264RawSEIRecoveryPoint){
+            .recovery_frame_cnt = 0,
+            .exact_match_flag   = 1,
+            .broken_link_flag   = ctx->b_per_p > 0,
+        };
+
+        priv->sei_needed |= SEI_RECOVERY_POINT;
+    }
+
+    vpic->CurrPic = (VASTPictureH264){
+        .picture_id          = pic->recon_surface,
+        .frame_idx           = hpic->frame_num,
+        .flags               = 0,
+        .TopFieldOrderCnt    = hpic->pic_order_cnt,
+        .BottomFieldOrderCnt = hpic->pic_order_cnt,
+    };
+
+    for (i = 0; i < pic->nb_refs; i++) {
+        VASTAPIEncodePicture     *ref = pic->refs[i];
+        VASTAPIEncodeH264Picture *href;
+
+        av_assert0(ref && ref->encode_order < pic->encode_order);
+
+        href = ref->priv_data;
+
+        vpic->ReferenceFrames[i] = (VASTPictureH264){
+            .picture_id          = ref->recon_surface,
+            .frame_idx           = href->frame_num,
+            .flags               = VAST_PICTURE_H264_SHORT_TERM_REFERENCE,
+            .TopFieldOrderCnt    = href->pic_order_cnt,
+            .BottomFieldOrderCnt = href->pic_order_cnt,
+        };
+    }
+    for (; i < FF_ARRAY_ELEMS(vpic->ReferenceFrames); i++) {
+        vpic->ReferenceFrames[i] = (VASTPictureH264){
+            .picture_id = VAST_INVALID_ID,
+            .flags      = VAST_PICTURE_H264_INVALID,
+        };
+    }
+
+    vpic->coded_buf = pic->output_buffer;
+
+    vpic->frame_num = hpic->frame_num;
+
+    vpic->pic_fields.bits.idr_pic_flag       = (pic->type == PICTURE_TYPE_IDR);
+    vpic->pic_fields.bits.reference_pic_flag = (pic->type != PICTURE_TYPE_B);
+
+    return 0;
+}
+
+static int vastapi_encode_h264_init_slice_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic,
+                                                 VASTAPIEncodeSlice *slice)
+{
+    VASTAPIEncodeH264Context          *priv   = avctx->priv_data;
+    VASTAPIEncodeH264Picture          *hpic   = pic->priv_data;
+    VASTAPIEncodePicture              *prev   = pic->prev;
+    H264RawSPS                        *sps    = &priv->raw_sps;
+    H264RawPPS                        *pps    = &priv->raw_pps;
+    H264RawSliceHeader                *sh     = &priv->raw_slice.header;
+    VASTEncPictureParameterBufferH264 *vpic   = pic->codec_picture_params;
+    VASTEncSliceParameterBufferH264   *vslice = slice->codec_slice_params;
+    int                                i, j;
+    VastapiFunctions                  *func = (VastapiFunctions *)(priv->common.vst_func);
+
+    if (pic->type == PICTURE_TYPE_IDR) {
+        sh->nal_unit_header.nal_unit_type = H264_NAL_IDR_SLICE;
+#ifdef FOR_QUICKTIME
+        sh->nal_unit_header.nal_ref_idc = 1;
+#else
+        sh->nal_unit_header.nal_ref_idc = 3;
+#endif
+    } else {
+        sh->nal_unit_header.nal_unit_type = H264_NAL_SLICE;
+        sh->nal_unit_header.nal_ref_idc   = pic->is_reference;
+    }
+
+    sh->first_mb_in_slice = slice->block_start;
+    sh->slice_type        = hpic->slice_type;
+
+    sh->pic_parameter_set_id = pps->pic_parameter_set_id;
+
+    sh->frame_num         = hpic->frame_num & ((1 << (4 + sps->log2_max_frame_num_minus4)) - 1);
+    sh->idr_pic_id        = hpic->idr_pic_id;
+    sh->pic_order_cnt_lsb = hpic->pic_order_cnt & ((1 << (4 + sps->log2_max_pic_order_cnt_lsb_minus4)) - 1);
+
+    sh->direct_spatial_mv_pred_flag = 1;
+
+    if (pic->type == PICTURE_TYPE_B)
+        sh->slice_qp_delta = priv->fixed_qp_b - (pps->pic_init_qp_minus26 + 26);
+    else if (pic->type == PICTURE_TYPE_P)
+        sh->slice_qp_delta = priv->fixed_qp_p - (pps->pic_init_qp_minus26 + 26);
+    else
+        sh->slice_qp_delta = priv->fixed_qp_idr - (pps->pic_init_qp_minus26 + 26);
+
+    if (pic->is_reference && (pic->type != PICTURE_TYPE_IDR && pic->type != CODETYPE_FLUSH)) {
+        VASTAPIEncodePicture *discard_list[MAX_DPB_SIZE];
+        int                   discard = 0, keep = 0;
+
+        // Discard everything which is in the DPB of the previous frame but
+        // not in the DPB of this one.
+        for (i = 0; i < prev->nb_dpb_pics; i++) {
+            for (j = 0; j < pic->nb_dpb_pics; j++) {
+                if (prev->dpb[i] == pic->dpb[j])
+                    break;
+            }
+            if (j == pic->nb_dpb_pics) {
+                discard_list[discard] = prev->dpb[i];
+                ++discard;
+            } else {
+                ++keep;
+            }
+        }
+        // av_assert0(keep <= priv->dpb_frames);
+
+        if (discard == 0) {
+            sh->adaptive_ref_pic_marking_mode_flag = 0;
+        } else {
+            sh->adaptive_ref_pic_marking_mode_flag = 1;
+            for (i = 0; i < discard; i++) {
+                VASTAPIEncodeH264Picture *old = discard_list[i]->priv_data;
+                // if(pic->passmodel != ONLY2PASS)
+                av_assert0(old->frame_num < hpic->frame_num);
+                sh->mmco[i].memory_management_control_operation = 1;
+                sh->mmco[i].difference_of_pic_nums_minus1       = hpic->frame_num - old->frame_num - 1;
+            }
+            sh->mmco[i].memory_management_control_operation = 0;
+        }
+    }
+
+    // If the intended references are not the first entries of RefPicListN
+    // by default, use ref-pic-list-modification to move them there.
+    if (pic->type == PICTURE_TYPE_P || pic->type == PICTURE_TYPE_B) {
+        VASTAPIEncodePicture     *def_l0[MAX_DPB_SIZE], *def_l1[MAX_DPB_SIZE];
+        VASTAPIEncodeH264Picture *href;
+        int                       n;
+
+        func->vastapiEncH264DefaultRefPicList(pic, def_l0, def_l1, &n);
+
+        if (pic->type == PICTURE_TYPE_P) {
+            int need_rplm = 0;
+            for (i = 0; i < pic->nb_refs; i++) {
+                av_assert0(pic->refs[i]);
+                if (pic->refs[i] != def_l0[i])
+                    need_rplm = 1;
+            }
+
+            sh->ref_pic_list_modification_flag_l0 = need_rplm;
+            if (need_rplm) {
+                int pic_num = hpic->frame_num;
+                for (i = 0; i < pic->nb_refs; i++) {
+                    href = pic->refs[i]->priv_data;
+                    av_assert0(href->frame_num != pic_num);
+                    if (href->frame_num < pic_num) {
+                        sh->rplm_l0[i].modification_of_pic_nums_idc = 0;
+                        sh->rplm_l0[i].abs_diff_pic_num_minus1      = pic_num - href->frame_num - 1;
+                    } else {
+                        sh->rplm_l0[i].modification_of_pic_nums_idc = 1;
+                        sh->rplm_l0[i].abs_diff_pic_num_minus1      = href->frame_num - pic_num - 1;
+                    }
+                    pic_num = href->frame_num;
+                }
+                sh->rplm_l0[i].modification_of_pic_nums_idc = 3;
+            }
+
+        } else {
+            int need_rplm_l0 = 0, need_rplm_l1 = 0;
+            int n0 = 0, n1 = 0;
+            for (i = 0; i < pic->nb_refs; i++) {
+                av_assert0(pic->refs[i]);
+                href = pic->refs[i]->priv_data;
+                // if(pic->passmodel != ONLY2PASS)
+                av_assert0(href->pic_order_cnt != hpic->pic_order_cnt);
+                // else
+                //     if(!href) continue;
+                if (href->pic_order_cnt < hpic->pic_order_cnt) {
+                    if (pic->refs[i] != def_l0[n0])
+                        need_rplm_l0 = 1;
+                    ++n0;
+                } else {
+                    if (pic->refs[i] != def_l1[n1])
+                        need_rplm_l1 = 1;
+                    ++n1;
+                }
+            }
+
+            sh->ref_pic_list_modification_flag_l0 = need_rplm_l0;
+            if (need_rplm_l0) {
+                int pic_num = hpic->frame_num;
+                for (i = j = 0; i < pic->nb_refs; i++) {
+                    href = pic->refs[i]->priv_data;
+                    if (href->pic_order_cnt > hpic->pic_order_cnt)
+                        continue;
+                    av_assert0(href->frame_num != pic_num);
+                    if (href->frame_num < pic_num) {
+                        sh->rplm_l0[j].modification_of_pic_nums_idc = 0;
+                        sh->rplm_l0[j].abs_diff_pic_num_minus1      = pic_num - href->frame_num - 1;
+                    } else {
+                        sh->rplm_l0[j].modification_of_pic_nums_idc = 1;
+                        sh->rplm_l0[j].abs_diff_pic_num_minus1      = href->frame_num - pic_num - 1;
+                    }
+                    pic_num = href->frame_num;
+                    ++j;
+                }
+                av_assert0(j == n0);
+                sh->rplm_l0[j].modification_of_pic_nums_idc = 3;
+            }
+
+            sh->ref_pic_list_modification_flag_l1 = need_rplm_l1;
+            if (need_rplm_l1) {
+                int pic_num = hpic->frame_num;
+                for (i = j = 0; i < pic->nb_refs; i++) {
+                    href = pic->refs[i]->priv_data;
+                    if (href->pic_order_cnt < hpic->pic_order_cnt)
+                        continue;
+                    av_assert0(href->frame_num != pic_num);
+                    if (href->frame_num < pic_num) {
+                        sh->rplm_l1[j].modification_of_pic_nums_idc = 0;
+                        sh->rplm_l1[j].abs_diff_pic_num_minus1      = pic_num - href->frame_num - 1;
+                    } else {
+                        sh->rplm_l1[j].modification_of_pic_nums_idc = 1;
+                        sh->rplm_l1[j].abs_diff_pic_num_minus1      = href->frame_num - pic_num - 1;
+                    }
+                    pic_num = href->frame_num;
+                    ++j;
+                }
+                av_assert0(j == n1);
+                sh->rplm_l1[j].modification_of_pic_nums_idc = 3;
+            }
+        }
+    }
+
+    vslice->macroblock_address = slice->block_start;
+    vslice->num_macroblocks    = slice->block_size;
+
+    vslice->macroblock_info = VAST_INVALID_ID;
+
+    vslice->slice_type           = sh->slice_type % 5;
+    vslice->pic_parameter_set_id = sh->pic_parameter_set_id;
+    vslice->idr_pic_id           = sh->idr_pic_id;
+
+    vslice->pic_order_cnt_lsb = sh->pic_order_cnt_lsb;
+
+    vslice->direct_spatial_mv_pred_flag = sh->direct_spatial_mv_pred_flag;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(vslice->RefPicList0); i++) {
+        vslice->RefPicList0[i].picture_id = VAST_INVALID_ID;
+        vslice->RefPicList0[i].flags      = VAST_PICTURE_H264_INVALID;
+        vslice->RefPicList1[i].picture_id = VAST_INVALID_ID;
+        vslice->RefPicList1[i].flags      = VAST_PICTURE_H264_INVALID;
+    }
+
+    av_assert0(pic->nb_refs <= 2);
+    if (pic->nb_refs >= 1) {
+        // Backward reference for P- or B-frame.
+        av_assert0(pic->type == PICTURE_TYPE_P || pic->type == PICTURE_TYPE_B || pic->type == CODETYPE_FLUSH);
+        vslice->RefPicList0[0] = vpic->ReferenceFrames[0];
+    }
+    if (pic->nb_refs >= 2) {
+        // Forward reference for B-frame.
+        av_assert0(pic->type == PICTURE_TYPE_B || pic->type == CODETYPE_FLUSH);
+        vslice->RefPicList1[0] = vpic->ReferenceFrames[1];
+    }
+
+    vslice->slice_qp_delta = sh->slice_qp_delta;
+
+    return 0;
+}
+
+static av_cold int vastapi_encode_h264_configure(AVCodecContext *avctx)
+{
+    // Random (version 4) ISO 11578 UUID.
+    static const uint8_t vastapi_encode_h264_sei_identifier_uuid[16] = {
+        0x59, 0x94, 0x8b, 0x28, 0x11, 0xec, 0x45, 0xaf, 0x96, 0x75, 0x19, 0xd4, 0x1f, 0xea, 0xa9, 0x4d,
+    };
+
+    VASTAPIEncodeContext     *ctx  = avctx->priv_data;
+    VastapiFunctions         *func = (VastapiFunctions *)ctx->vst_func;
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+    int                       err;
+
+    err = ff_cbs_init(&priv->cbc, AV_CODEC_ID_H264, avctx);
+    if (err < 0)
+        return err;
+
+    priv->mb_width  = FFALIGN(avctx->width, 16) / 16;
+    priv->mb_height = FFALIGN(avctx->height, 16) / 16;
+
+#ifdef FOR_QUICKTIME
+    if (ctx->vast_param->brc.qpHdr == -1) {
+        priv->fixed_qp_idr = 26;
+        priv->fixed_qp_p   = 26;
+        priv->fixed_qp_b   = 26;
+    } else {
+        priv->fixed_qp_idr = ctx->vast_param->brc.qpHdr;
+        priv->fixed_qp_p   = ctx->vast_param->brc.qpHdr;
+        priv->fixed_qp_b   = ctx->vast_param->brc.qpHdr;
+    }
+#else
+    if (ctx->va_rc_mode == VAST_RC_CQP) {
+        priv->fixed_qp_p = av_clip(ctx->rc_quality, 1, 51);
+        if (avctx->i_quant_factor > 0.0)
+            priv->fixed_qp_idr =
+                av_clip((avctx->i_quant_factor * priv->fixed_qp_p + avctx->i_quant_offset) + 0.5, 1, 51);
+        else
+            priv->fixed_qp_idr = priv->fixed_qp_p;
+        if (avctx->b_quant_factor > 0.0)
+            priv->fixed_qp_b = av_clip((avctx->b_quant_factor * priv->fixed_qp_p + avctx->b_quant_offset) + 0.5, 1, 51);
+        else
+            priv->fixed_qp_b = priv->fixed_qp_p;
+
+        av_log(avctx, AV_LOG_DEBUG,
+               "Using fixed QP = "
+               "%d / %d / %d for IDR- / P- / B-frames.\n",
+               priv->fixed_qp_idr, priv->fixed_qp_p, priv->fixed_qp_b);
+
+    } else {
+        // These still need to be  set for pic_init_qp/slice_qp_delta.
+        priv->fixed_qp_idr = 26;
+        priv->fixed_qp_p   = 26;
+        priv->fixed_qp_b   = 26;
+    }
+#endif
+
+    if (!ctx->rc_mode->hrd) {
+        // Timing SEI requires a mode respecting HRD parameters.
+        priv->sei &= ~SEI_TIMING;
+    }
+
+    if (priv->sei & SEI_IDENTIFIER) {
+        const char *lavc    = LIBAVCODEC_IDENT;
+        const char *vastapi = VA_VERSION_S;
+        const char *driver;
+        int         len;
+
+        memcpy(priv->sei_identifier.uuid_iso_iec_11578, vastapi_encode_h264_sei_identifier_uuid,
+               sizeof(priv->sei_identifier.uuid_iso_iec_11578));
+
+        driver = func->vastapiQueryVendorString(AVVASTAPIDeviceContextPtr(ctx->hwctx)->display);
+        if (!driver)
+            driver = "unknown driver";
+
+        len = snprintf(NULL, 0, "%s / VASTAPI %s / %s", lavc, vastapi, driver);
+        if (len >= 0) {
+            priv->sei_identifier_string = av_malloc(len + 1);
+            if (!priv->sei_identifier_string)
+                return AVERROR(ENOMEM);
+
+            snprintf(priv->sei_identifier_string, len + 1, "%s / VASTAPI %s / %s", lavc, vastapi, driver);
+
+            priv->sei_identifier.data        = priv->sei_identifier_string;
+            priv->sei_identifier.data_length = len + 1;
+        }
+    }
+
+    ctx->roi_quant_range = 51 + 6 * (ctx->profile->depth - 8);
+
+    return 0;
+}
+
+static const VASTAPIEncodeProfile vastapi_encode_h264_profiles[] = {
+    { FF_PROFILE_H264_HIGH, 8, 3, 1, 1, VASTProfileH264High },
+    { FF_PROFILE_H264_HIGH, 8, 3, 0, 0, VASTProfileH264High },
+#if VA_CHECK_VERSION(0, 37, 0) // for h264_profile_high10
+    { FF_PROFILE_H264_HIGH_10, 10, 3, 1, 1, HANTROProfileH264High10 },
+#endif
+    { FF_PROFILE_H264_MAIN, 8, 3, 1, 1, VASTProfileH264Main },
+    { FF_PROFILE_H264_MAIN, 8, 3, 0, 0, VASTProfileH264Main },
+    { FF_PROFILE_H264_CONSTRAINED_BASELINE, 8, 3, 1, 1, VASTProfileH264ConstrainedBaseline },
+    { FF_PROFILE_H264_CONSTRAINED_BASELINE, 8, 3, 0, 0, VASTProfileH264ConstrainedBaseline },
+    { FF_PROFILE_UNKNOWN }
+};
+
+static const VASTAPIEncodeType vastapi_encode_type_h264 = {
+    .profiles = vastapi_encode_h264_profiles,
+
+    .flags = FLAG_SLICE_CONTROL | FLAG_B_PICTURES | FLAG_B_PICTURE_REFERENCES | FLAG_NON_IDR_KEY_PICTURES,
+
+    .default_quality = 20,
+
+    .configure = &vastapi_encode_h264_configure,
+
+    .picture_priv_data_size = sizeof(VASTAPIEncodeH264Picture),
+
+    .sequence_params_size = sizeof(VASTEncSequenceParameterBufferH264),
+    .init_sequence_params = &vastapi_encode_h264_init_sequence_params,
+
+    .picture_params_size = sizeof(VASTEncPictureParameterBufferH264),
+    .init_picture_params = &vastapi_encode_h264_init_picture_params,
+
+    .slice_params_size = sizeof(VASTEncSliceParameterBufferH264),
+    .init_slice_params = &vastapi_encode_h264_init_slice_params,
+
+    .sequence_header_type  = VASTEncPackedHeaderSequence,
+    .write_sequence_header = &vastapi_encode_h264_write_sequence_header,
+
+    .slice_header_type  = VASTEncPackedHeaderH264_Slice,
+    .write_slice_header = &vastapi_encode_h264_write_slice_header,
+
+    .write_extra_header = &vastapi_encode_h264_write_extra_header,
+};
+
+static av_cold int vastapi_encode_h264_init(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext     *ctx  = avctx->priv_data;
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+
+    ctx->codec = &vastapi_encode_type_h264;
+
+    if (avctx->profile == FF_PROFILE_UNKNOWN)
+        avctx->profile = priv->profile;
+    if (avctx->level == FF_LEVEL_UNKNOWN)
+        avctx->level = priv->level;
+    if (avctx->compression_level == FF_COMPRESSION_DEFAULT)
+        avctx->compression_level = priv->quality;
+
+    // Reject unsupported profiles.
+    switch (avctx->profile) {
+    case FF_PROFILE_H264_BASELINE:
+        av_log(avctx, AV_LOG_WARNING,
+               "H.264 baseline profile is not "
+               "supported, using constrained baseline profile instead.\n");
+        avctx->profile = FF_PROFILE_H264_CONSTRAINED_BASELINE;
+        break;
+    case FF_PROFILE_H264_EXTENDED:
+        av_log(avctx, AV_LOG_ERROR,
+               "H.264 extended profile "
+               "is not supported.\n");
+        return AVERROR_PATCHWELCOME;
+    case FF_PROFILE_H264_HIGH_10:
+        avctx->profile = FF_PROFILE_H264_HIGH_10; // for h264_profile_high10
+        break;
+    case FF_PROFILE_H264_HIGH_10_INTRA:
+        av_log(avctx, AV_LOG_ERROR,
+               "H.264 10-bit profiles "
+               "are not supported.\n");
+        return AVERROR_PATCHWELCOME;
+    case FF_PROFILE_H264_HIGH_422:
+    case FF_PROFILE_H264_HIGH_422_INTRA:
+    case FF_PROFILE_H264_HIGH_444:
+    case FF_PROFILE_H264_HIGH_444_PREDICTIVE:
+    case FF_PROFILE_H264_HIGH_444_INTRA:
+    case FF_PROFILE_H264_CAVLC_444:
+        av_log(avctx, AV_LOG_ERROR,
+               "H.264 non-4:2:0 profiles "
+               "are not supported.\n");
+        return AVERROR_PATCHWELCOME;
+    }
+
+    if (avctx->level != FF_LEVEL_UNKNOWN && avctx->level & ~0xff) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Invalid level %d: must fit "
+               "in 8-bit unsigned integer.\n",
+               avctx->level);
+        return AVERROR(EINVAL);
+    }
+
+    ctx->desired_packed_headers = VAST_ENC_PACKED_HEADER_SEQUENCE | // SPS
+                                  VAST_ENC_PACKED_HEADER_PICTURE |  // PPS
+                                  //   VAST_ENC_PACKED_HEADER_SLICE | // Slice headers.
+                                  VAST_ENC_PACKED_HEADER_MISC; // SEI.
+
+    ctx->surface_width  = FFALIGN(avctx->width, 16);
+    ctx->surface_height = FFALIGN(avctx->height, 16);
+
+    ctx->slice_block_height = ctx->slice_block_width = 16;
+    ctx->vast_last_frame                             = 0;
+    if (priv->qp > 0)
+        ctx->explicit_qp = priv->qp;
+
+    return _vastapi_encode_init(avctx);
+}
+
+static av_cold int vastapi_encode_h264_close(AVCodecContext *avctx)
+{
+    VASTAPIEncodeH264Context *priv = avctx->priv_data;
+
+    ff_cbs_fragment_free(PRIV_CBC & priv->current_access_unit);
+    ff_cbs_close(&priv->cbc);
+    av_freep(&priv->sei_identifier_string);
+
+    return _vastapi_encode_close(avctx);
+}
+
+#if FF_LT(N441)
+#define SEIRawMasteringDisplayColourVolume H265RawSEIMasteringDisplayColourVolume
+#define SEIRawContentLightLevelInfo H265RawSEIContentLightLevelInfo
+#endif
+
+static int vastapi_encode_h265_write_access_unit(AVCodecContext *avctx, char *data, size_t *data_len,
+                                                 CodedBitstreamFragment *au)
+{
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+    int                       err;
+
+    err = ff_cbs_write_fragment_data(priv->cbc, au);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to write packed header.\n");
+        return err;
+    }
+
+    if (*data_len < 8 * au->data_size - au->data_bit_padding) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Access unit too large: "
+               "%zu < %zu.\n",
+               *data_len, 8 * au->data_size - au->data_bit_padding);
+        return AVERROR(ENOSPC);
+    }
+
+    memcpy(data, au->data, au->data_size);
+    *data_len = 8 * au->data_size - au->data_bit_padding;
+
+    return 0;
+}
+
+static int vastapi_encode_h265_add_nal(AVCodecContext *avctx, CodedBitstreamFragment *au, void *nal_unit)
+{
+    VASTAPIEncodeH265Context *priv   = avctx->priv_data;
+    H265RawNALUnitHeader     *header = nal_unit;
+    int                       err;
+
+    err = ff_cbs_insert_unit_content(PRIV_CBC au, -1, header->nal_unit_type, nal_unit, NULL);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to add NAL unit: "
+               "type = %d.\n",
+               header->nal_unit_type);
+        return err;
+    }
+
+    return 0;
+}
+
+static int vastapi_encode_h265_write_sequence_header(AVCodecContext *avctx, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err;
+
+    if (priv->aud_needed) {
+        err = vastapi_encode_h265_add_nal(avctx, au, &priv->raw_aud);
+        if (err < 0)
+            goto fail;
+        priv->aud_needed = 0;
+    }
+
+    err = vastapi_encode_h265_add_nal(avctx, au, &priv->raw_vps);
+    if (err < 0)
+        goto fail;
+
+    err = vastapi_encode_h265_add_nal(avctx, au, &priv->raw_sps);
+    if (err < 0)
+        goto fail;
+
+    err = vastapi_encode_h265_add_nal(avctx, au, &priv->raw_pps);
+    if (err < 0)
+        goto fail;
+
+    err = vastapi_encode_h265_write_access_unit(avctx, data, data_len, au);
+fail:
+    ff_cbs_fragment_reset(PRIV_CBC au);
+    return err;
+}
+
+static int vastapi_encode_h265_write_slice_header(AVCodecContext *avctx, VASTAPIEncodePicture *pic,
+                                                  VASTAPIEncodeSlice *slice, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err;
+
+    if (priv->aud_needed) {
+        err = vastapi_encode_h265_add_nal(avctx, au, &priv->raw_aud);
+        if (err < 0)
+            goto fail;
+        priv->aud_needed = 0;
+    }
+
+    err = vastapi_encode_h265_add_nal(avctx, au, &priv->raw_slice);
+    if (err < 0)
+        goto fail;
+
+    err = vastapi_encode_h265_write_access_unit(avctx, data, data_len, au);
+fail:
+    ff_cbs_fragment_reset(PRIV_CBC au);
+    return err;
+}
+
+#if FF_LT(N441)
+static int vastapi_encode_h265_write_extra_header(AVCodecContext *avctx, VASTAPIEncodePicture *pic, int index,
+                                                  int *type, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err, i;
+
+    if (priv->sei_needed) {
+        H265RawSEI *sei = &priv->raw_sei;
+
+        if (priv->aud_needed) {
+            err = vastapi_encode_h265_add_nal(avctx, au, &priv->aud);
+            if (err < 0)
+                goto fail;
+            priv->aud_needed = 0;
+        }
+
+        *sei = (H265RawSEI) {
+            .nal_unit_header = {
+                .nal_unit_type         = HEVC_NAL_SEI_PREFIX,
+                .nuh_layer_id          = 0,
+                .nuh_temporal_id_plus1 = 1,
+            },
+        };
+
+        i = 0;
+
+        if (priv->sei_needed & SEI_MASTERING_DISPLAY) {
+            sei->payload[i].payload_type              = HEVC_SEI_TYPE_MASTERING_DISPLAY_INFO;
+            sei->payload[i].payload.mastering_display = priv->sei_mastering_display;
+            ++i;
+        }
+
+        if (priv->sei_needed & SEI_CONTENT_LIGHT_LEVEL) {
+            sei->payload[i].payload_type                = HEVC_SEI_TYPE_CONTENT_LIGHT_LEVEL_INFO;
+            sei->payload[i].payload.content_light_level = priv->sei_content_light_level;
+            ++i;
+        }
+
+        sei->payload_count = i;
+        av_assert0(sei->payload_count > 0);
+
+        err = vastapi_encode_h265_add_nal(avctx, au, sei);
+        if (err < 0)
+            goto fail;
+        priv->sei_needed = 0;
+
+        err = vastapi_encode_h265_write_access_unit(avctx, data, data_len, au);
+        if (err < 0)
+            goto fail;
+
+        ff_cbs_fragment_reset(priv->cbc, au);
+
+        *type = VASTEncPackedHeaderRawData;
+        return 0;
+    } else {
+        return AVERROR_EOF;
+    }
+
+fail:
+    ff_cbs_fragment_reset(priv->cbc, au);
+    return err;
+}
+#else
+static int vastapi_encode_h265_write_extra_header(AVCodecContext *avctx, VASTAPIEncodePicture *pic, int index,
+                                                  int *type, char *data, size_t *data_len)
+{
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+    CodedBitstreamFragment   *au   = &priv->current_access_unit;
+    int                       err;
+
+    if (priv->sei_needed) {
+        if (priv->aud_needed) {
+            err = vastapi_encode_h265_add_nal(avctx, au, &priv->aud);
+            if (err < 0)
+                goto fail;
+            priv->aud_needed = 0;
+        }
+
+        if (priv->sei_needed & SEI_MASTERING_DISPLAY) {
+            err = ff_cbs_sei_add_message(priv->cbc, au, 1, SEI_TYPE_MASTERING_DISPLAY_COLOUR_VOLUME,
+                                         &priv->sei_mastering_display, NULL);
+            if (err < 0)
+                goto fail;
+        }
+
+        if (priv->sei_needed & SEI_CONTENT_LIGHT_LEVEL) {
+            err = ff_cbs_sei_add_message(priv->cbc, au, 1, SEI_TYPE_CONTENT_LIGHT_LEVEL_INFO,
+                                         &priv->sei_content_light_level, NULL);
+            if (err < 0)
+                goto fail;
+        }
+
+        priv->sei_needed = 0;
+
+        err = vastapi_encode_h265_write_access_unit(avctx, data, data_len, au);
+        if (err < 0)
+            goto fail;
+
+        ff_cbs_fragment_reset(au);
+
+        *type = VASTEncPackedHeaderRawData;
+        return 0;
+    } else {
+        return AVERROR_EOF;
+    }
+
+fail:
+    ff_cbs_fragment_reset(au);
+    return err;
+}
+#endif
+
+static int vastapi_encode_h265_init_sequence_params(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext               *ctx  = avctx->priv_data;
+    VASTAPIEncodeH265Context           *priv = avctx->priv_data;
+    H265RawVPS                         *vps  = &priv->raw_vps;
+    H265RawSPS                         *sps  = &priv->raw_sps;
+    H265RawPPS                         *pps  = &priv->raw_pps;
+    H265RawProfileTierLevel            *ptl  = &vps->profile_tier_level;
+    H265RawVUI                         *vui  = &sps->vui;
+    VASTEncSequenceParameterBufferHEVC *vseq = ctx->codec_sequence_params;
+    VASTEncPictureParameterBufferHEVC  *vpic = ctx->codec_picture_params;
+    const AVPixFmtDescriptor           *desc;
+    int                                 chroma_format, bit_depth;
+    int                                 i;
+
+    memset(vps, 0, sizeof(*vps));
+    memset(sps, 0, sizeof(*sps));
+    memset(pps, 0, sizeof(*pps));
+
+    desc = av_pix_fmt_desc_get(AVHWFramesContextPtr(priv->common.input_frames)->sw_format);
+    av_assert0(desc);
+    if (desc->nb_components == 1) {
+        chroma_format = 0;
+    } else {
+        if (desc->log2_chroma_w == 1 && desc->log2_chroma_h == 1) {
+            chroma_format = 1;
+        } else if (desc->log2_chroma_w == 1 && desc->log2_chroma_h == 0) {
+            chroma_format = 2;
+        } else if (desc->log2_chroma_w == 0 && desc->log2_chroma_h == 0) {
+            chroma_format = 3;
+        } else {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Chroma format of input pixel format "
+                   "%s is not supported.\n",
+                   desc->name);
+            return AVERROR(EINVAL);
+        }
+    }
+    bit_depth = desc->comp[0].depth;
+
+    // VPS
+
+    vps->nal_unit_header = (H265RawNALUnitHeader){
+        .nal_unit_type         = HEVC_NAL_VPS,
+        .nuh_layer_id          = 0,
+        .nuh_temporal_id_plus1 = 1,
+    };
+
+    vps->vps_video_parameter_set_id = 0;
+
+    vps->vps_base_layer_internal_flag  = 1;
+    vps->vps_base_layer_available_flag = 1;
+    vps->vps_max_layers_minus1         = 0;
+    vps->vps_max_sub_layers_minus1     = 0;
+    vps->vps_temporal_id_nesting_flag  = 1;
+
+    ptl->general_profile_space = 0;
+    ptl->general_profile_idc   = avctx->profile;
+    ptl->general_tier_flag     = ctx->vast_param->tier == DEFAULT_VAST ? priv->tier : ctx->vast_param->tier; // vastai
+
+    if (chroma_format == 1) {
+        ptl->general_profile_compatibility_flag[1] = bit_depth == 8;
+        ptl->general_profile_compatibility_flag[2] = bit_depth <= 10;
+    }
+    
+    if(ptl->general_profile_idc == 4) 
+        ptl->general_profile_compatibility_flag[4] = 1;
+
+    ptl->general_progressive_source_flag    = 1;
+    ptl->general_interlaced_source_flag     = 0;
+    ptl->general_non_packed_constraint_flag = 1;
+    ptl->general_frame_only_constraint_flag = 1;
+
+    ptl->general_max_12bit_constraint_flag = bit_depth <= 12;
+    ptl->general_max_10bit_constraint_flag = bit_depth <= 10;
+    ptl->general_max_8bit_constraint_flag  = bit_depth == 8;
+
+    ptl->general_max_422chroma_constraint_flag  = chroma_format <= 2;
+    ptl->general_max_420chroma_constraint_flag  = chroma_format <= 1;
+    ptl->general_max_monochrome_constraint_flag = chroma_format == 0;
+
+    ptl->general_intra_constraint_flag = ctx->gop_size == 1;
+
+    ptl->general_lower_bit_rate_constraint_flag = 1;
+
+    if (avctx->level != FF_LEVEL_UNKNOWN) {
+        ptl->general_level_idc = avctx->level;
+    } else {
+        ptl->general_level_idc = 180; // for vastai default
+    }
+
+    vps->vps_sub_layer_ordering_info_present_flag = 0;
+    vps->vps_max_dec_pic_buffering_minus1[0]      = ctx->max_b_depth + 1;
+    vps->vps_max_num_reorder_pics[0]              = ctx->max_b_depth;
+    vps->vps_max_latency_increase_plus1[0]        = 0;
+
+    vps->vps_max_layer_id             = 0;
+    vps->vps_num_layer_sets_minus1    = 0;
+    vps->layer_id_included_flag[0][0] = 1;
+
+    vps->vps_timing_info_present_flag = 1;
+    if (avctx->framerate.num > 0 && avctx->framerate.den > 0) {
+        vps->vps_num_units_in_tick               = avctx->framerate.den;
+        vps->vps_time_scale                      = avctx->framerate.num;
+        vps->vps_poc_proportional_to_timing_flag = 1;
+        vps->vps_num_ticks_poc_diff_one_minus1   = 0;
+    } else {
+        vps->vps_num_units_in_tick               = avctx->time_base.num;
+        vps->vps_time_scale                      = avctx->time_base.den;
+        vps->vps_poc_proportional_to_timing_flag = 0;
+    }
+    vps->vps_num_hrd_parameters = 0;
+
+    // SPS
+
+    sps->nal_unit_header = (H265RawNALUnitHeader){
+        .nal_unit_type         = HEVC_NAL_SPS,
+        .nuh_layer_id          = 0,
+        .nuh_temporal_id_plus1 = 1,
+    };
+
+    sps->sps_video_parameter_set_id = vps->vps_video_parameter_set_id;
+
+    sps->sps_max_sub_layers_minus1    = vps->vps_max_sub_layers_minus1;
+    sps->sps_temporal_id_nesting_flag = vps->vps_temporal_id_nesting_flag;
+
+    sps->profile_tier_level = vps->profile_tier_level;
+
+    sps->sps_seq_parameter_set_id = 0;
+
+    sps->chroma_format_idc          = chroma_format;
+    sps->separate_colour_plane_flag = 0;
+
+    int min_cu_size = 8;
+    sps->pic_width_in_luma_samples = FFALIGN(avctx->width, min_cu_size);
+    sps->pic_height_in_luma_samples = FFALIGN(avctx->height, min_cu_size);
+
+    if (avctx->width != ctx->surface_width || avctx->height != ctx->surface_height) {
+        sps->conformance_window_flag = 1;
+        sps->conf_win_left_offset    = 0;
+        sps->conf_win_right_offset   = (ctx->surface_width - avctx->width) >> desc->log2_chroma_w;
+        sps->conf_win_top_offset     = 0;
+        sps->conf_win_bottom_offset  = (ctx->surface_height - avctx->height) >> desc->log2_chroma_h;
+    } else {
+        sps->conformance_window_flag = 0;
+    }
+
+    sps->bit_depth_luma_minus8   = bit_depth - 8;
+    sps->bit_depth_chroma_minus8 = bit_depth - 8;
+
+    // vastai
+    sps->log2_max_pic_order_cnt_lsb_minus4 = ctx->vast_param->log2MaxPicOrderCntLsb - 4;
+
+    sps->sps_sub_layer_ordering_info_present_flag = vps->vps_sub_layer_ordering_info_present_flag;
+    for (i = 0; i <= sps->sps_max_sub_layers_minus1; i++) {
+        sps->sps_max_dec_pic_buffering_minus1[i] = vps->vps_max_dec_pic_buffering_minus1[i];
+        sps->sps_max_num_reorder_pics[i]         = vps->vps_max_num_reorder_pics[i];
+        sps->sps_max_latency_increase_plus1[i]   = vps->vps_max_latency_increase_plus1[i];
+    }
+
+    // These have to come from the capabilities of the encoder.  We have no
+    // way to query them, so just hardcode parameters which work on the Intel
+    // driver.
+    // CTB size from 8x8 to 32x32.
+    sps->log2_min_luma_coding_block_size_minus3   = 0;
+    sps->log2_diff_max_min_luma_coding_block_size = 3;
+    // Transform size from 4x4 to 32x32.
+    sps->log2_min_luma_transform_block_size_minus2   = 0;
+    sps->log2_diff_max_min_luma_transform_block_size = 3;
+    // Full transform hierarchy allowed (2-5).
+    sps->max_transform_hierarchy_depth_inter = 3;
+    sps->max_transform_hierarchy_depth_intra = 2;
+    // AMP works.
+    sps->amp_enabled_flag = 1;
+    // SAO and temporal MVP do not work.
+    sps->sample_adaptive_offset_enabled_flag = 1; // default enable sao for better quality
+    sps->sps_temporal_mvp_enabled_flag       = 0;
+
+    sps->pcm_enabled_flag = 0;
+
+    // STRPSs should ideally be here rather than defined individually in
+    // each slice, but the structure isn't completely fixed so for now
+    // don't bother.
+    sps->num_short_term_ref_pic_sets     = 0;
+    sps->long_term_ref_pics_present_flag = 0;
+
+    sps->vui_parameters_present_flag = 1;
+
+    if (avctx->sample_aspect_ratio.num != 0 && avctx->sample_aspect_ratio.den != 0) {
+        static const AVRational sar_idc[] = {
+            { 0, 0 },   { 1, 1 },   { 12, 11 }, { 10, 11 }, { 16, 11 },  { 40, 33 }, { 24, 11 }, { 20, 11 }, { 32, 11 },
+            { 80, 33 }, { 18, 11 }, { 15, 11 }, { 64, 33 }, { 160, 99 }, { 4, 3 },   { 3, 2 },   { 2, 1 },
+        };
+        int num, den, i;
+        av_reduce(&num, &den, avctx->sample_aspect_ratio.num, avctx->sample_aspect_ratio.den, 65535);
+        for (i = 0; i < FF_ARRAY_ELEMS(sar_idc); i++) {
+            if (num == sar_idc[i].num && den == sar_idc[i].den) {
+                vui->aspect_ratio_idc = i;
+                break;
+            }
+        }
+        if (i >= FF_ARRAY_ELEMS(sar_idc)) {
+            vui->aspect_ratio_idc = 255;
+            vui->sar_width        = num;
+            vui->sar_height       = den;
+        }
+        vui->aspect_ratio_info_present_flag = 1;
+    }
+
+    if (avctx->color_range != AVCOL_RANGE_UNSPECIFIED || avctx->color_primaries != AVCOL_PRI_UNSPECIFIED ||
+        avctx->color_trc != AVCOL_TRC_UNSPECIFIED || avctx->colorspace != AVCOL_SPC_UNSPECIFIED) {
+        vui->video_signal_type_present_flag = 1;
+        vui->video_format                   = 5; // Unspecified.
+        vui->video_full_range_flag          = avctx->color_range == AVCOL_RANGE_JPEG;
+
+        if (avctx->color_primaries != AVCOL_PRI_UNSPECIFIED || avctx->color_trc != AVCOL_TRC_UNSPECIFIED ||
+            avctx->colorspace != AVCOL_SPC_UNSPECIFIED) {
+            vui->colour_description_present_flag = 1;
+            vui->colour_primaries                = avctx->color_primaries;
+            vui->transfer_characteristics        = avctx->color_trc;
+            vui->matrix_coefficients             = avctx->colorspace;
+        } else {
+            vui->colour_description_present_flag = 0;
+            vui->colour_primaries                = avctx->color_primaries;
+            vui->transfer_characteristics        = avctx->color_trc;
+            vui->matrix_coefficients             = avctx->colorspace;
+        }
+    } else {
+        vui->video_format             = 5;
+        vui->video_full_range_flag    = 0;
+        vui->colour_primaries         = avctx->color_primaries;
+        vui->transfer_characteristics = avctx->color_trc;
+        vui->matrix_coefficients      = avctx->colorspace;
+    }
+
+    if (avctx->chroma_sample_location != AVCHROMA_LOC_UNSPECIFIED) {
+        vui->chroma_loc_info_present_flag     = 1;
+        vui->chroma_sample_loc_type_top_field = vui->chroma_sample_loc_type_bottom_field =
+            avctx->chroma_sample_location - 1;
+    }
+
+    vui->vui_timing_info_present_flag        = 1;
+    vui->vui_num_units_in_tick               = vps->vps_num_units_in_tick;
+    vui->vui_time_scale                      = vps->vps_time_scale;
+    vui->vui_poc_proportional_to_timing_flag = vps->vps_poc_proportional_to_timing_flag;
+    vui->vui_num_ticks_poc_diff_one_minus1   = vps->vps_num_ticks_poc_diff_one_minus1;
+    vui->vui_hrd_parameters_present_flag     = 0;
+
+    vui->bitstream_restriction_flag              = 1;
+    vui->motion_vectors_over_pic_boundaries_flag = 1;
+    vui->restricted_ref_pic_lists_flag           = 1;
+    vui->max_bytes_per_pic_denom                 = 0;
+    vui->max_bits_per_min_cu_denom               = 0;
+    vui->log2_max_mv_length_horizontal           = 15;
+    vui->log2_max_mv_length_vertical             = 15;
+
+    // PPS
+
+    pps->nal_unit_header = (H265RawNALUnitHeader){
+        .nal_unit_type         = HEVC_NAL_PPS,
+        .nuh_layer_id          = 0,
+        .nuh_temporal_id_plus1 = 1,
+    };
+
+    pps->pps_pic_parameter_set_id = 0;
+    pps->pps_seq_parameter_set_id = sps->sps_seq_parameter_set_id;
+
+    pps->num_ref_idx_l0_default_active_minus1 = 0;
+    pps->num_ref_idx_l1_default_active_minus1 = 0;
+
+    pps->init_qp_minus26 = priv->fixed_qp_idr - 26;
+    av_log(avctx, AV_LOG_DEBUG, "vastapi_encode_h265_init_sequence_params ctx->va_rc_mode=%d\n", ctx->va_rc_mode);
+    pps->cu_qp_delta_enabled_flag = (ctx->va_rc_mode != VAST_RC_CQP);
+    av_log(avctx, AV_LOG_DEBUG, "vastapi_encode_h265_init_sequence_params pps->cu_qp_delta_enabled_flag=%d\n",
+           pps->cu_qp_delta_enabled_flag);
+    pps->diff_cu_qp_delta_depth = 0;
+
+    pps->pps_loop_filter_across_slices_enabled_flag = 1;
+
+    // Fill VASTAPI parameter buffers.
+
+    *vseq = (VASTEncSequenceParameterBufferHEVC) {
+        .general_profile_idc = vps->profile_tier_level.general_profile_idc,
+        .general_level_idc   = vps->profile_tier_level.general_level_idc,
+        .general_tier_flag   = vps->profile_tier_level.general_tier_flag,
+
+        .intra_period     = ctx->vast_param->intraPicRate, //vastai add cfg
+        .intra_idr_period = ctx->vast_param->intraPicRate, //vastai add cfg
+        .ip_period        = ctx->b_per_p + 1,
+        .bits_per_second  = ctx->va_bit_rate,
+
+        .pic_width_in_luma_samples  = sps->pic_width_in_luma_samples,
+        .pic_height_in_luma_samples = sps->pic_height_in_luma_samples,
+
+        .seq_fields.bits = {
+            .chroma_format_idc             = sps->chroma_format_idc,
+            .separate_colour_plane_flag    = sps->separate_colour_plane_flag,
+            .bit_depth_luma_minus8         = sps->bit_depth_luma_minus8,
+            .bit_depth_chroma_minus8       = sps->bit_depth_chroma_minus8,
+            .scaling_list_enabled_flag     = sps->scaling_list_enabled_flag,
+            .strong_intra_smoothing_enabled_flag =
+                sps->strong_intra_smoothing_enabled_flag,
+            .amp_enabled_flag              = sps->amp_enabled_flag,
+            .sample_adaptive_offset_enabled_flag =
+                sps->sample_adaptive_offset_enabled_flag,
+            .pcm_enabled_flag              = sps->pcm_enabled_flag,
+            .pcm_loop_filter_disabled_flag = sps->pcm_loop_filter_disabled_flag,
+            .sps_temporal_mvp_enabled_flag = sps->sps_temporal_mvp_enabled_flag,
+        },
+
+        .log2_min_luma_coding_block_size_minus3 =
+            sps->log2_min_luma_coding_block_size_minus3,
+        .log2_diff_max_min_luma_coding_block_size =
+            sps->log2_diff_max_min_luma_coding_block_size,
+        .log2_min_transform_block_size_minus2 =
+            sps->log2_min_luma_transform_block_size_minus2,
+        .log2_diff_max_min_transform_block_size =
+            sps->log2_diff_max_min_luma_transform_block_size,
+        .max_transform_hierarchy_depth_inter =
+            sps->max_transform_hierarchy_depth_inter,
+        .max_transform_hierarchy_depth_intra =
+            sps->max_transform_hierarchy_depth_intra,
+
+        .pcm_sample_bit_depth_luma_minus1 =
+            sps->pcm_sample_bit_depth_luma_minus1,
+        .pcm_sample_bit_depth_chroma_minus1 =
+            sps->pcm_sample_bit_depth_chroma_minus1,
+        .log2_min_pcm_luma_coding_block_size_minus3 =
+            sps->log2_min_pcm_luma_coding_block_size_minus3,
+        .log2_max_pcm_luma_coding_block_size_minus3 =
+            sps->log2_min_pcm_luma_coding_block_size_minus3 +
+            sps->log2_diff_max_min_pcm_luma_coding_block_size,
+
+        .vui_parameters_present_flag = 0,
+    };
+
+    *vpic = (VASTEncPictureParameterBufferHEVC) {
+        .decoded_curr_pic = {
+            .picture_id = VAST_INVALID_ID,
+            .flags      = VAST_PICTURE_HEVC_INVALID,
+        },
+
+        .coded_buf = VAST_INVALID_ID,
+
+        .collocated_ref_pic_index = 0xff,
+
+        .last_picture = 0,
+
+        .pic_init_qp            = pps->init_qp_minus26 + 26,
+        .diff_cu_qp_delta_depth = pps->diff_cu_qp_delta_depth,
+        .pps_cb_qp_offset       = pps->pps_cb_qp_offset,
+        .pps_cr_qp_offset       = pps->pps_cr_qp_offset,
+
+        .num_tile_columns_minus1 = pps->num_tile_columns_minus1,
+        .num_tile_rows_minus1    = pps->num_tile_rows_minus1,
+
+        .log2_parallel_merge_level_minus2 = pps->log2_parallel_merge_level_minus2,
+        .ctu_max_bitsize_allowed          = 0,
+
+        .num_ref_idx_l0_default_active_minus1 =
+            pps->num_ref_idx_l0_default_active_minus1,
+        .num_ref_idx_l1_default_active_minus1 =
+            pps->num_ref_idx_l1_default_active_minus1,
+
+        .slice_pic_parameter_set_id = pps->pps_pic_parameter_set_id,
+
+        .pic_fields.bits = {
+            .sign_data_hiding_enabled_flag  = pps->sign_data_hiding_enabled_flag,
+            .constrained_intra_pred_flag    = pps->constrained_intra_pred_flag,
+            .transform_skip_enabled_flag    = pps->transform_skip_enabled_flag,
+            .cu_qp_delta_enabled_flag       = pps->cu_qp_delta_enabled_flag,
+            .weighted_pred_flag             = pps->weighted_pred_flag,
+            .weighted_bipred_flag           = pps->weighted_bipred_flag,
+            .transquant_bypass_enabled_flag = pps->transquant_bypass_enabled_flag,
+            .tiles_enabled_flag             = pps->tiles_enabled_flag,
+            .entropy_coding_sync_enabled_flag = pps->entropy_coding_sync_enabled_flag,
+            .loop_filter_across_tiles_enabled_flag =
+                pps->loop_filter_across_tiles_enabled_flag,
+            .scaling_list_data_present_flag = (sps->sps_scaling_list_data_present_flag |
+                                               pps->pps_scaling_list_data_present_flag),
+            .screen_content_flag            = 0,
+            .enable_gpu_weighted_prediction = 0,
+            .no_output_of_prior_pics_flag   = 0,
+        },
+    };
+
+    return 0;
+}
+
+static int vastapi_encode_h265_init_picture_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic)
+{
+    VASTAPIEncodeContext              *ctx   = avctx->priv_data;
+    VASTAPIEncodeH265Context          *priv  = avctx->priv_data;
+    VASTAPIEncodeH265Picture          *hpic  = pic->priv_data;
+    VASTAPIEncodePicture              *prev  = pic->prev;
+    VASTAPIEncodeH265Picture          *hprev = prev ? prev->priv_data : NULL;
+    VASTEncPictureParameterBufferHEVC *vpic  = pic->codec_picture_params;
+    int                                i;
+
+    int                   left  = 0;
+    VASTAPIEncodePicture *inPic = NULL;
+    for (inPic = ctx->pic_start; inPic; inPic = inPic->next) {
+        if (!inPic->encode_issued) {
+            left++;
+        }
+    }
+    av_log(avctx, AV_LOG_DEBUG, "h265 isAtlast=%d\n", left);
+    if (ctx->end_of_stream && left == 1) {
+        vpic->last_picture = 1;
+    }
+
+    if (pic->type == PICTURE_TYPE_IDR) {
+        if (pic->display_order != pic->encode_order) {
+            av_log(avctx, AV_LOG_ERROR, "pic->display_order != pic->encode_order %d\n");
+            return AVERROR(EINVAL);
+        }
+
+        hpic->last_idr_frame = pic->display_order;
+
+        hpic->slice_nal_unit = HEVC_NAL_IDR_W_RADL;
+        hpic->slice_type     = HEVC_SLICE_I;
+        hpic->pic_type       = 0;
+    } else if (pic->type != CODETYPE_FLUSH) {
+        av_assert0(prev);
+        hpic->last_idr_frame = hprev->last_idr_frame;
+
+        if (pic->type == PICTURE_TYPE_I) {
+            hpic->slice_nal_unit = HEVC_NAL_CRA_NUT;
+            hpic->slice_type     = HEVC_SLICE_I;
+            hpic->pic_type       = 0;
+        } else if (pic->type == PICTURE_TYPE_P) {
+            av_assert0(pic->refs[0]);
+            hpic->slice_nal_unit = HEVC_NAL_TRAIL_R;
+            hpic->slice_type     = HEVC_SLICE_P;
+            hpic->pic_type       = 1;
+        } else {
+            VASTAPIEncodePicture *irap_ref;
+            av_assert0(pic->refs[0] && pic->refs[1]);
+            for (irap_ref = pic; irap_ref; irap_ref = irap_ref->refs[1]) {
+                if (irap_ref->type == PICTURE_TYPE_I)
+                    break;
+            }
+            if (pic->b_depth == ctx->max_b_depth) {
+                hpic->slice_nal_unit = irap_ref ? HEVC_NAL_RASL_N : HEVC_NAL_TRAIL_N;
+            } else {
+                hpic->slice_nal_unit = irap_ref ? HEVC_NAL_RASL_R : HEVC_NAL_TRAIL_R;
+            }
+            hpic->slice_type = HEVC_SLICE_B;
+            hpic->pic_type   = 2;
+        }
+    }
+    hpic->pic_order_cnt = pic->display_order - hpic->last_idr_frame;
+
+    if (priv->aud) {
+        priv->aud_needed = 1;
+        priv->raw_aud = (H265RawAUD) {
+            .nal_unit_header = {
+                .nal_unit_type         = HEVC_NAL_AUD,
+                .nuh_layer_id          = 0,
+                .nuh_temporal_id_plus1 = 1,
+            },
+            .pic_type = hpic->pic_type,
+        };
+    } else {
+        priv->aud_needed = 0;
+    }
+
+    priv->sei_needed = 0;
+
+    // Only look for the metadata on I/IDR frame on the output. We
+    // may force an IDR frame on the output where the medadata gets
+    // changed on the input frame.
+    if ((priv->sei & SEI_MASTERING_DISPLAY) && (pic->type == PICTURE_TYPE_I || pic->type == PICTURE_TYPE_IDR)) {
+        AVFrameSideData *sd = av_frame_get_side_data(pic->input_image, AV_FRAME_DATA_MASTERING_DISPLAY_METADATA);
+
+        if (sd) {
+            AVMasteringDisplayMetadata *mdm = (AVMasteringDisplayMetadata *)sd->data;
+
+            // SEI is needed when both the primaries and luminance are set
+            if (mdm->has_primaries && mdm->has_luminance) {
+                SEIRawMasteringDisplayColourVolume *mdcv       = &priv->sei_mastering_display;
+                const int                           mapping[3] = { 1, 2, 0 };
+                const int                           chroma_den = 50000;
+                const int                           luma_den   = 10000;
+
+                for (i = 0; i < 3; i++) {
+                    const int j = mapping[i];
+                    mdcv->display_primaries_x[i] =
+                        FFMIN(lrint(chroma_den * av_q2d(mdm->display_primaries[j][0])), chroma_den);
+                    mdcv->display_primaries_y[i] =
+                        FFMIN(lrint(chroma_den * av_q2d(mdm->display_primaries[j][1])), chroma_den);
+                }
+
+                mdcv->white_point_x = FFMIN(lrint(chroma_den * av_q2d(mdm->white_point[0])), chroma_den);
+                mdcv->white_point_y = FFMIN(lrint(chroma_den * av_q2d(mdm->white_point[1])), chroma_den);
+
+                mdcv->max_display_mastering_luminance = lrint(luma_den * av_q2d(mdm->max_luminance));
+                mdcv->min_display_mastering_luminance =
+                    FFMIN(lrint(luma_den * av_q2d(mdm->min_luminance)), mdcv->max_display_mastering_luminance);
+
+                priv->sei_needed |= SEI_MASTERING_DISPLAY;
+            }
+        }
+    }
+
+    if ((priv->sei & SEI_CONTENT_LIGHT_LEVEL) && (pic->type == PICTURE_TYPE_I || pic->type == PICTURE_TYPE_IDR)) {
+        AVFrameSideData *sd = av_frame_get_side_data(pic->input_image, AV_FRAME_DATA_CONTENT_LIGHT_LEVEL);
+
+        if (sd) {
+            AVContentLightMetadata      *clm  = (AVContentLightMetadata *)sd->data;
+            SEIRawContentLightLevelInfo *clli = &priv->sei_content_light_level;
+
+            clli->max_content_light_level     = FFMIN(clm->MaxCLL, 65535);
+            clli->max_pic_average_light_level = FFMIN(clm->MaxFALL, 65535);
+
+            priv->sei_needed |= SEI_CONTENT_LIGHT_LEVEL;
+        }
+    }
+
+    vpic->decoded_curr_pic = (VASTPictureHEVC){
+        .picture_id    = pic->recon_surface,
+        .pic_order_cnt = hpic->pic_order_cnt,
+        .flags         = 0,
+    };
+
+    for (i = 0; i < pic->nb_refs; i++) {
+        VASTAPIEncodePicture     *ref = pic->refs[i];
+        VASTAPIEncodeH265Picture *href;
+
+        av_assert0(ref && ref->encode_order < pic->encode_order);
+        href = ref->priv_data;
+
+        vpic->reference_frames[i] = (VASTPictureHEVC){
+            .picture_id    = ref->recon_surface,
+            .pic_order_cnt = href->pic_order_cnt,
+            .flags         = (ref->display_order < pic->display_order ? VAST_PICTURE_HEVC_RPS_ST_CURR_BEFORE : 0) |
+                     (ref->display_order > pic->display_order ? VAST_PICTURE_HEVC_RPS_ST_CURR_AFTER : 0),
+        };
+    }
+    for (; i < FF_ARRAY_ELEMS(vpic->reference_frames); i++) {
+        vpic->reference_frames[i] = (VASTPictureHEVC){
+            .picture_id = VAST_INVALID_ID,
+            .flags      = VAST_PICTURE_HEVC_INVALID,
+        };
+    }
+
+    vpic->coded_buf = pic->output_buffer;
+
+    vpic->nal_unit_type = hpic->slice_nal_unit;
+
+    switch (pic->type) {
+    case PICTURE_TYPE_IDR:
+        vpic->pic_fields.bits.idr_pic_flag       = 1;
+        vpic->pic_fields.bits.coding_type        = 1;
+        vpic->pic_fields.bits.reference_pic_flag = 1;
+        break;
+    case PICTURE_TYPE_I:
+        vpic->pic_fields.bits.idr_pic_flag       = 0;
+        vpic->pic_fields.bits.coding_type        = 1;
+        vpic->pic_fields.bits.reference_pic_flag = 1;
+        break;
+    case PICTURE_TYPE_P:
+        vpic->pic_fields.bits.idr_pic_flag       = 0;
+        vpic->pic_fields.bits.coding_type        = 2;
+        vpic->pic_fields.bits.reference_pic_flag = 1;
+        break;
+    case PICTURE_TYPE_B:
+        vpic->pic_fields.bits.idr_pic_flag       = 0;
+        vpic->pic_fields.bits.coding_type        = 3;
+        vpic->pic_fields.bits.reference_pic_flag = 0;
+        break;
+    case CODETYPE_FLUSH:
+        break;
+    default:
+        av_assert0(0 && "invalid picture type");
+    }
+
+    return 0;
+}
+
+static int vastapi_encode_h265_init_slice_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic,
+                                                 VASTAPIEncodeSlice *slice)
+{
+    VASTAPIEncodeH265Context          *priv   = avctx->priv_data;
+    VASTAPIEncodeH265Picture          *hpic   = pic->priv_data;
+    const H265RawSPS                  *sps    = &priv->raw_sps;
+    const H265RawPPS                  *pps    = &priv->raw_pps;
+    H265RawSliceHeader                *sh     = &priv->raw_slice.header;
+    VASTEncPictureParameterBufferHEVC *vpic   = pic->codec_picture_params;
+    VASTEncSliceParameterBufferHEVC   *vslice = slice->codec_slice_params;
+    int                                i;
+
+    sh->nal_unit_header = (H265RawNALUnitHeader){
+        .nal_unit_type         = hpic->slice_nal_unit,
+        .nuh_layer_id          = 0,
+        .nuh_temporal_id_plus1 = 1,
+    };
+
+    sh->slice_pic_parameter_set_id = pps->pps_pic_parameter_set_id;
+
+    sh->first_slice_segment_in_pic_flag = slice->index == 0;
+    sh->slice_segment_address           = slice->block_start;
+
+    sh->slice_type = hpic->slice_type;
+
+    sh->slice_pic_order_cnt_lsb = hpic->pic_order_cnt & (1 << (sps->log2_max_pic_order_cnt_lsb_minus4 + 4)) - 1;
+
+    if (pic->type != PICTURE_TYPE_IDR) {
+        H265RawSTRefPicSet             *rps;
+        const VASTAPIEncodeH265Picture *strp;
+        int                             rps_poc[MAX_DPB_SIZE];
+        int                             rps_used[MAX_DPB_SIZE];
+        int                             i, j, poc, rps_pics;
+
+        sh->short_term_ref_pic_set_sps_flag = 0;
+
+        rps = &sh->short_term_ref_pic_set;
+        memset(rps, 0, sizeof(*rps));
+
+        rps_pics = 0;
+        for (i = 0; i < pic->nb_refs; i++) {
+            strp               = pic->refs[i]->priv_data;
+            rps_poc[rps_pics]  = strp->pic_order_cnt;
+            rps_used[rps_pics] = 1;
+            ++rps_pics;
+        }
+        for (i = 0; i < pic->nb_dpb_pics; i++) {
+            if (pic->dpb[i] == pic)
+                continue;
+            for (j = 0; j < pic->nb_refs; j++) {
+                if (pic->dpb[i] == pic->refs[j])
+                    break;
+            }
+            if (j < pic->nb_refs)
+                continue;
+            strp               = pic->dpb[i]->priv_data;
+            rps_poc[rps_pics]  = strp->pic_order_cnt;
+            rps_used[rps_pics] = 0;
+            ++rps_pics;
+        }
+
+        for (i = 1; i < rps_pics; i++) {
+            for (j = i; j > 0; j--) {
+                if (rps_poc[j] > rps_poc[j - 1])
+                    break;
+                av_assert0(rps_poc[j] != rps_poc[j - 1]);
+                FFSWAP(int, rps_poc[j], rps_poc[j - 1]);
+                FFSWAP(int, rps_used[j], rps_used[j - 1]);
+            }
+        }
+
+        av_log(avctx, AV_LOG_DEBUG, "RPS for POC %d:", hpic->pic_order_cnt);
+        for (i = 0; i < rps_pics; i++) {
+            av_log(avctx, AV_LOG_DEBUG, " (%d,%d)", rps_poc[i], rps_used[i]);
+        }
+        av_log(avctx, AV_LOG_DEBUG, "\n");
+
+        for (i = 0; i < rps_pics; i++) {
+            av_assert0(rps_poc[i] != hpic->pic_order_cnt);
+            if (rps_poc[i] > hpic->pic_order_cnt)
+                break;
+        }
+
+        rps->num_negative_pics = i;
+        poc                    = hpic->pic_order_cnt;
+        for (j = i - 1; j >= 0; j--) {
+            rps->delta_poc_s0_minus1[i - 1 - j]      = poc - rps_poc[j] - 1;
+            rps->used_by_curr_pic_s0_flag[i - 1 - j] = rps_used[j];
+            poc                                      = rps_poc[j];
+        }
+
+        rps->num_positive_pics = rps_pics - i;
+        poc                    = hpic->pic_order_cnt;
+        for (j = i; j < rps_pics; j++) {
+            rps->delta_poc_s1_minus1[j - i]      = rps_poc[j] - poc - 1;
+            rps->used_by_curr_pic_s1_flag[j - i] = rps_used[j];
+            poc                                  = rps_poc[j];
+        }
+
+        sh->num_long_term_sps  = 0;
+        sh->num_long_term_pics = 0;
+
+        sh->slice_temporal_mvp_enabled_flag = sps->sps_temporal_mvp_enabled_flag;
+        if (sh->slice_temporal_mvp_enabled_flag) {
+            sh->collocated_from_l0_flag = sh->slice_type == HEVC_SLICE_B;
+            sh->collocated_ref_idx      = 0;
+        }
+
+        sh->num_ref_idx_active_override_flag = 0;
+        sh->num_ref_idx_l0_active_minus1     = pps->num_ref_idx_l0_default_active_minus1;
+        sh->num_ref_idx_l1_active_minus1     = pps->num_ref_idx_l1_default_active_minus1;
+    }
+
+    sh->slice_sao_luma_flag = sh->slice_sao_chroma_flag = sps->sample_adaptive_offset_enabled_flag;
+
+    if (pic->type == PICTURE_TYPE_B)
+        sh->slice_qp_delta = priv->fixed_qp_b - (pps->init_qp_minus26 + 26);
+    else if (pic->type == PICTURE_TYPE_P)
+        sh->slice_qp_delta = priv->fixed_qp_p - (pps->init_qp_minus26 + 26);
+    else
+        sh->slice_qp_delta = priv->fixed_qp_idr - (pps->init_qp_minus26 + 26);
+
+    *vslice = (VASTEncSliceParameterBufferHEVC) {
+        .slice_segment_address = sh->slice_segment_address,
+        .num_ctu_in_slice      = slice->block_size,
+
+        .slice_type                 = sh->slice_type,
+        .slice_pic_parameter_set_id = sh->slice_pic_parameter_set_id,
+
+        .num_ref_idx_l0_active_minus1 = sh->num_ref_idx_l0_active_minus1,
+        .num_ref_idx_l1_active_minus1 = sh->num_ref_idx_l1_active_minus1,
+
+        .luma_log2_weight_denom         = sh->luma_log2_weight_denom,
+        .delta_chroma_log2_weight_denom = sh->delta_chroma_log2_weight_denom,
+
+        .max_num_merge_cand = 5 - sh->five_minus_max_num_merge_cand,
+
+        .slice_qp_delta     = sh->slice_qp_delta,
+        .slice_cb_qp_offset = sh->slice_cb_qp_offset,
+        .slice_cr_qp_offset = sh->slice_cr_qp_offset,
+
+        .slice_beta_offset_div2 = sh->slice_beta_offset_div2,
+        .slice_tc_offset_div2   = sh->slice_tc_offset_div2,
+
+        .slice_fields.bits = {
+            .last_slice_of_pic_flag       = slice->index == pic->nb_slices - 1,
+            .dependent_slice_segment_flag = sh->dependent_slice_segment_flag,
+            .colour_plane_id              = sh->colour_plane_id,
+            .slice_temporal_mvp_enabled_flag =
+                sh->slice_temporal_mvp_enabled_flag,
+            .slice_sao_luma_flag          = sh->slice_sao_luma_flag,
+            .slice_sao_chroma_flag        = sh->slice_sao_chroma_flag,
+            .num_ref_idx_active_override_flag =
+                sh->num_ref_idx_active_override_flag,
+            .mvd_l1_zero_flag             = sh->mvd_l1_zero_flag,
+            .cabac_init_flag              = sh->cabac_init_flag,
+            .slice_deblocking_filter_disabled_flag =
+                sh->slice_deblocking_filter_disabled_flag,
+            .slice_loop_filter_across_slices_enabled_flag =
+                sh->slice_loop_filter_across_slices_enabled_flag,
+            .collocated_from_l0_flag      = sh->collocated_from_l0_flag,
+        },
+    };
+
+    for (i = 0; i < FF_ARRAY_ELEMS(vslice->ref_pic_list0); i++) {
+        vslice->ref_pic_list0[i].picture_id = VAST_INVALID_ID;
+        vslice->ref_pic_list0[i].flags      = VAST_PICTURE_HEVC_INVALID;
+        vslice->ref_pic_list1[i].picture_id = VAST_INVALID_ID;
+        vslice->ref_pic_list1[i].flags      = VAST_PICTURE_HEVC_INVALID;
+    }
+
+    av_assert0(pic->nb_refs <= 2);
+    if (pic->nb_refs >= 1) {
+        // Backward reference for P- or B-frame.
+        av_assert0(pic->type == PICTURE_TYPE_P || pic->type == PICTURE_TYPE_B || pic->type == CODETYPE_FLUSH);
+        vslice->ref_pic_list0[0] = vpic->reference_frames[0];
+    }
+    if (pic->nb_refs >= 2) {
+        // Forward reference for B-frame.
+        av_assert0(pic->type == PICTURE_TYPE_B || pic->type == CODETYPE_FLUSH);
+        vslice->ref_pic_list1[0] = vpic->reference_frames[1];
+    }
+
+    return 0;
+}
+
+static av_cold int vastapi_encode_h265_configure(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext     *ctx  = avctx->priv_data;
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+    int                       err;
+
+    err = ff_cbs_init(&priv->cbc, AV_CODEC_ID_HEVC, avctx);
+    if (err < 0)
+        return err;
+
+    if (ctx->va_rc_mode == VAST_RC_CQP) {
+        // Note that VASTAPI only supports positive QP values - the range is
+        // therefore always bounded below by 1, even in 10-bit mode where
+        // it should go down to -12.
+
+        priv->fixed_qp_p = av_clip(ctx->rc_quality, 1, 51);
+        if (avctx->i_quant_factor > 0.0)
+            priv->fixed_qp_idr =
+                av_clip((avctx->i_quant_factor * priv->fixed_qp_p + avctx->i_quant_offset) + 0.5, 1, 51);
+        else
+            priv->fixed_qp_idr = priv->fixed_qp_p;
+        if (avctx->b_quant_factor > 0.0)
+            priv->fixed_qp_b = av_clip((avctx->b_quant_factor * priv->fixed_qp_p + avctx->b_quant_offset) + 0.5, 1, 51);
+        else
+            priv->fixed_qp_b = priv->fixed_qp_p;
+
+        av_log(avctx, AV_LOG_DEBUG,
+               "Using fixed QP = "
+               "%d / %d / %d for IDR- / P- / B-frames.\n",
+               priv->fixed_qp_idr, priv->fixed_qp_p, priv->fixed_qp_b);
+
+    } else {
+        // These still need to be set for init_qp/slice_qp_delta.
+        priv->fixed_qp_idr = 30;
+        priv->fixed_qp_p   = 30;
+        priv->fixed_qp_b   = 30;
+    }
+
+    ctx->roi_quant_range = 51 + 6 * (ctx->profile->depth - 8);
+
+    return 0;
+}
+
+static const VASTAPIEncodeProfile vastapi_encode_h265_profiles[] = {
+    { FF_PROFILE_HEVC_MAIN, 8, 3, 1, 1, VASTProfileHEVCMain },
+    { FF_PROFILE_HEVC_MAIN, 8, 3, 0, 0, VASTProfileHEVCMain },
+    { FF_PROFILE_HEVC_REXT, 8, 3, 1, 1, VASTProfileHEVCMain },
+    { FF_PROFILE_HEVC_REXT, 8, 3, 0, 0, VASTProfileHEVCMain },
+#if VA_CHECK_VERSION(0, 37, 0)
+    { FF_PROFILE_HEVC_MAIN_10, 10, 3, 1, 1, VASTProfileHEVCMain10 },
+    { FF_PROFILE_HEVC_REXT, 10, 3, 1, 1, VASTProfileHEVCMain10 },
+#endif
+    { FF_PROFILE_UNKNOWN }
+};
+
+static const VASTAPIEncodeType vastapi_encode_type_h265 = {
+    .profiles = vastapi_encode_h265_profiles,
+
+    .flags = FLAG_SLICE_CONTROL | FLAG_B_PICTURES | FLAG_B_PICTURE_REFERENCES | FLAG_NON_IDR_KEY_PICTURES,
+
+    .default_quality = 25,
+
+    .configure = &vastapi_encode_h265_configure,
+
+    .picture_priv_data_size = sizeof(VASTAPIEncodeH265Picture),
+
+    .sequence_params_size = sizeof(VASTEncSequenceParameterBufferHEVC),
+    .init_sequence_params = &vastapi_encode_h265_init_sequence_params,
+
+    .picture_params_size = sizeof(VASTEncPictureParameterBufferHEVC),
+    .init_picture_params = &vastapi_encode_h265_init_picture_params,
+
+    .slice_params_size = sizeof(VASTEncSliceParameterBufferHEVC),
+    .init_slice_params = &vastapi_encode_h265_init_slice_params,
+
+    .sequence_header_type  = VASTEncPackedHeaderSequence,
+    .write_sequence_header = &vastapi_encode_h265_write_sequence_header,
+
+    .slice_header_type  = VASTEncPackedHeaderHEVC_Slice,
+    .write_slice_header = &vastapi_encode_h265_write_slice_header,
+
+    .write_extra_header = &vastapi_encode_h265_write_extra_header,
+};
+
+static av_cold int vastapi_encode_h265_init(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext     *ctx  = avctx->priv_data;
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+
+    ctx->codec = &vastapi_encode_type_h265;
+
+    if (avctx->profile == FF_PROFILE_UNKNOWN)
+        avctx->profile = priv->profile;
+    if (avctx->level == FF_LEVEL_UNKNOWN)
+        avctx->level = priv->level;
+
+    if (avctx->level != FF_LEVEL_UNKNOWN && avctx->level & ~0xff) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Invalid level %d: must fit "
+               "in 8-bit unsigned integer.\n",
+               avctx->level);
+        return AVERROR(EINVAL);
+    }
+
+    ctx->desired_packed_headers = VAST_ENC_PACKED_HEADER_SEQUENCE | // VPS, SPS
+                                  VAST_ENC_PACKED_HEADER_PICTURE |  // PPS
+                                                                    //   VAST_ENC_PACKED_HEADER_SLICE | // Slice headers
+                                  VAST_ENC_PACKED_HEADER_MISC;      // SEI
+
+    ctx->surface_width  = FFALIGN(avctx->width, 64);  // changed by vastai (vsi align 16 -> 64)
+    ctx->surface_height = FFALIGN(avctx->height, 64); // changed by vastai (height not align)
+
+    // CTU size is currently hard-coded to 32.
+    ctx->slice_block_width = ctx->slice_block_height = 32;
+
+    ctx->vast_last_frame = 0; // 2pass
+
+    if (priv->qp > 0)
+        ctx->explicit_qp = priv->qp;
+
+    return _vastapi_encode_init(avctx);
+}
+
+static av_cold int vastapi_encode_h265_close(AVCodecContext *avctx)
+{
+    VASTAPIEncodeH265Context *priv = avctx->priv_data;
+
+    ff_cbs_fragment_free(PRIV_CBC & priv->current_access_unit);
+    ff_cbs_close(&priv->cbc);
+
+    return _vastapi_encode_close(avctx);
+}
+
+#if FF_LT(N441)
+#undef SEIRawMasteringDisplayColourVolume // H265RawSEIMasteringDisplayColourVolume
+#undef SEIRawContentLightLevelInfo        // H265RawSEIContentLightLevelInfo
+#endif
+
+static int vastapi_encode_av1_write_obu(AVCodecContext *avctx, char *data, size_t *data_len,
+                                        CodedBitstreamFragment *bs)
+{
+    VASTAPIEncodeAV1Context *priv = avctx->priv_data;
+    int ret;
+
+    ret = ff_cbs_write_fragment_data(priv->cbc, bs);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to write packed header.\n");
+        return ret;
+    }
+
+    if ((size_t)8 * MAX_PARAM_BUFFER_SIZE < 8 * bs->data_size - bs->data_bit_padding) {
+        av_log(avctx, AV_LOG_ERROR, "Access unit too large: "
+               "%zu < %zu.\n", (size_t)8 * MAX_PARAM_BUFFER_SIZE,
+               8 * bs->data_size - bs->data_bit_padding);
+        return AVERROR(ENOSPC);
+    }
+
+    memcpy(data, bs->data, bs->data_size);
+    *data_len = 8 * bs->data_size - bs->data_bit_padding;
+
+    return 0;
+}
+
+static int vastapi_encode_av1_add_obu(AVCodecContext *avctx, CodedBitstreamFragment *au, uint8_t type, void *obu_unit)
+{
+    int ret;
+
+    ret = ff_cbs_insert_unit_content(au, -1,
+                                     type, obu_unit, NULL);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to add OBU unit: "
+               "type = %d.\n", type);
+        return ret;
+    }
+
+    return 0;
+}
+
+static int vastapi_encode_av1_write_sequence_header(AVCodecContext *avctx, char *data, size_t *data_len)
+{
+    VASTAPIEncodeAV1Context *priv = avctx->priv_data;
+
+    memcpy(data, &priv->sh_data, MAX_PARAM_BUFFER_SIZE * sizeof(char));
+    *data_len = priv->sh_data_len;
+
+    return 0;
+}
+
+static int vastapi_encode_av1_init_sequence_params(AVCodecContext *avctx)
+{
+    av_log(avctx, AV_LOG_DEBUG, ">>> vastapi_encode_av1_init_sequence_params\n");
+    VASTAPIEncodeContext               *ctx  = avctx->priv_data;
+    VASTAPIEncodeAV1Context            *priv = avctx->priv_data;
+    VASTEncSequenceParameterBufferAV1 *vseq = ctx->codec_sequence_params;
+    VASTEncPictureParameterBufferAV1  *vpic = ctx->codec_picture_params;
+
+    AV1RawOBU                *sh_obu = &priv->sh;
+    AV1RawSequenceHeader     *seq = &sh_obu->obu.sequence_header;
+    CodedBitstreamFragment   *obu = &priv->current_obu;
+    const AVPixFmtDescriptor *desc;
+    int ret;
+
+    memset(sh_obu, 0, sizeof(*sh_obu));
+    sh_obu->header.obu_type = AV1_OBU_SEQUENCE_HEADER;
+
+    memset(obu, 0, sizeof(*obu));
+    av_log(avctx, AV_LOG_DEBUG, "av1 avctx->profile=%d,avctx->level=%d\n", avctx->profile, avctx->level);
+    seq->seq_profile = avctx->profile;
+    if (avctx->level != FF_LEVEL_UNKNOWN) {
+        seq->seq_level_idx[0] = avctx->level;
+    } else {
+        seq->seq_level_idx[0] = 13; // vast default
+    }
+    if (seq->seq_level_idx[0] > 7)
+        seq->seq_tier[0] = 1;
+    else
+        seq->seq_tier[0] = 0;
+
+    uint32_t num_bits_width;
+    uint32_t num_bits_height;
+
+    seq->max_frame_width_minus_1  = avctx->width - 1;
+    seq->max_frame_height_minus_1 = avctx->height - 1;
+    num_bits_width                = av_log2(avctx->width);
+    num_bits_height               = av_log2(avctx->height);
+    num_bits_width++;
+    num_bits_height++;
+
+    av_assert0(num_bits_width <= 16);
+    av_assert0(num_bits_height <= 16);
+
+    seq->frame_width_bits_minus_1 = num_bits_width - 1;
+    seq->frame_height_bits_minus_1 = num_bits_height - 1;
+
+    seq->frame_id_numbers_present_flag = 0;
+    if (seq->frame_id_numbers_present_flag) {
+        seq->delta_frame_id_length_minus_2      = 12; // DELTA_FRAME_ID_LENGTH - 2;
+        seq->additional_frame_id_length_minus_1 = 0;  // FRAME_ID_LENGTH - DELTA_FRAME_ID_LENGTH - 1;
+    }
+
+    seq->use_128x128_superblock = 0;
+    seq->enable_filter_intra    = 0;
+    if ((ctx->vast_param->brc.gdr_duration != 0) || (ctx->vast_param->intraPicRate == 0) ||
+        (ctx->vast_param->intraPicRate > ((1 << 8)))) // DEFAULT_EXPLICIT_ORDER_HINT_BITS
+        seq->enable_order_hint = 0;
+    else
+        seq->enable_order_hint = 1;
+    
+    if(seq->enable_order_hint)
+        seq->order_hint_bits_minus_1 = 7;//DEFAULT_EXPLICIT_ORDER_HINT_BITS - 1;
+
+    seq->enable_cdef = ctx->vast_param->coding_ctrl.enableSao;
+
+    if (seq->seq_force_screen_content_tools == 0)
+        seq->seq_force_integer_mv = AV1_SELECT_INTEGER_MV;
+
+    if (ctx->vast_param->bitDepthLuma == DEFAULT_VAST)
+    {
+        seq->color_config.high_bitdepth = 0;
+    }
+    else if (((ctx->vast_param->bitDepthLuma - 8) > 0) && (seq->seq_profile == 2)) // SW_PROFILE_2
+    {
+        seq->color_config.high_bitdepth = 1;
+        if ((ctx->vast_param->bitDepthLuma - 8) == 12)
+            seq->color_config.twelve_bit = 1;
+    } else {
+        seq->color_config.high_bitdepth = (ctx->vast_param->bitDepthLuma - 8) > 0 ? 1 : 0;
+    }
+
+    seq->color_config.mono_chrome = ctx->vast_param->preprocess.codedChromaIdc == 0 ? 1 : 0;
+
+    if (avctx->color_range != AVCOL_RANGE_UNSPECIFIED || avctx->color_primaries != AVCOL_PRI_UNSPECIFIED ||
+        avctx->color_trc != AVCOL_TRC_UNSPECIFIED || avctx->colorspace != AVCOL_SPC_UNSPECIFIED) {
+        seq->color_config.color_description_present_flag = 1;
+        if (avctx->color_range == AVCOL_RANGE_JPEG)
+            seq->color_config.color_range = 1;
+        else
+            seq->color_config.color_range = 0;
+
+        if (avctx->color_primaries != AVCOL_PRI_UNSPECIFIED || avctx->color_trc != AVCOL_TRC_UNSPECIFIED ||
+            avctx->colorspace != AVCOL_SPC_UNSPECIFIED) {
+            seq->color_config.color_description_present_flag = 1;
+            seq->color_config.color_primaries                = avctx->color_primaries;
+            seq->color_config.transfer_characteristics       = avctx->color_trc;
+            seq->color_config.matrix_coefficients            = avctx->colorspace;
+        } else {
+            seq->color_config.color_description_present_flag = 0;
+            seq->color_config.color_primaries                = avctx->color_primaries;
+            seq->color_config.transfer_characteristics       = avctx->color_trc;
+            seq->color_config.matrix_coefficients            = avctx->colorspace;
+        }
+    } else {
+        seq->color_config.color_primaries          = avctx->color_primaries;
+        seq->color_config.transfer_characteristics = avctx->color_trc;
+        seq->color_config.matrix_coefficients      = avctx->colorspace;
+    }
+
+    if (seq->color_config.mono_chrome) {
+        seq->color_config.subsampling_x          = 1;
+        seq->color_config.subsampling_y          = 1;
+        seq->color_config.chroma_sample_position = AV1_CSP_UNKNOWN;
+        seq->color_config.separate_uv_delta_q    = 0;
+    } else if (seq->color_config.color_primaries == AVCOL_PRI_BT709 &&
+               seq->color_config.transfer_characteristics == AVCOL_TRC_IEC61966_2_1 &&
+               seq->color_config.matrix_coefficients == AVCOL_SPC_RGB) {
+        seq->color_config.color_range   = 1;
+        seq->color_config.subsampling_x = 0;
+        seq->color_config.subsampling_y = 0;
+    } else {
+        if (seq->seq_profile == FF_PROFILE_AV1_MAIN) {
+            seq->color_config.subsampling_x = 1;
+            seq->color_config.subsampling_y = 1;
+            seq->color_config.chroma_sample_position = AV1_CSP_VERTICAL;
+        } else if (seq->seq_profile == FF_PROFILE_AV1_HIGH) {
+            seq->color_config.subsampling_x = 0;
+            seq->color_config.subsampling_y = 0;
+        } else {
+            seq->color_config.subsampling_x = 1;
+            seq->color_config.subsampling_y = 0;
+        }
+    }
+
+
+
+    ret = vastapi_encode_av1_add_obu(avctx, obu, AV1_OBU_SEQUENCE_HEADER, &priv->sh);
+    if (ret < 0)
+        goto fail;
+
+    ret = vastapi_encode_av1_write_obu(avctx, priv->sh_data, &priv->sh_data_len, obu);
+    if (ret < 0)
+        goto fail;
+
+    if(seq->seq_level_idx[0] != 13){
+        seq->seq_level_idx[0] = 13; // vast
+        av_log(avctx, AV_LOG_WARNING, "hardware AV1 not support this level, using levle 13 instead!\n");
+    }
+    // Fill VASTAPI parameter buffers.
+    *vseq = (VASTEncSequenceParameterBufferAV1) {
+        .general_profile_idc = seq->seq_profile,
+        .general_level_idc   = seq->seq_level_idx[0],
+        .general_tier_flag   = seq->seq_tier[0],
+
+        .intra_period     = ctx->vast_param->intraPicRate, //vastai add cfg
+        .intra_idr_period = ctx->vast_param->intraPicRate, //vastai add cfg
+        .ip_period        = ctx->b_per_p + 1,
+        .bits_per_second  = ctx->va_bit_rate,
+    };
+
+fail:
+    ff_cbs_fragment_reset(obu);
+    return ret;
+}
+
+static int vastapi_encode_av1_init_picture_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic)
+{
+    VASTAPIEncodeContext *ctx  = avctx->priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->vst_func;
+
+    return func->vastapiEncAV1InitPicParams(ctx, pic);
+}
+
+static int vastapi_encode_av1_init_slice_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic,
+                                                VASTAPIEncodeSlice *slice)
+{
+    VASTAPIEncodeContext *ctx  = avctx->priv_data;
+    VastapiFunctions     *func = (VastapiFunctions *)ctx->vst_func;
+    return func->vastapiEncAV1InitSliceParam(pic, slice);
+}
+
+static av_cold int vastapi_encode_av1_configure(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext    *ctx  = avctx->priv_data;
+    VASTAPIEncodeAV1Context *priv = avctx->priv_data;
+    int                      err;
+
+    err = ff_cbs_init(&priv->cbc, AV_CODEC_ID_AV1, avctx);
+    if (err < 0)
+        return err;
+
+    return 0;
+}
+
+static const VASTAPIEncodeProfile vastapi_encode_av1_profiles[] = {
+    { FF_PROFILE_AV1_MAIN, 8, 3, 1, 1, VASTProfileAV1Main },
+    { FF_PROFILE_AV1_MAIN, 8, 3, 0, 0, VASTProfileAV1Main },
+    { FF_PROFILE_AV1_MAIN, 10, 3, 1, 1, VASTProfileAV1Main },
+    { FF_PROFILE_UNKNOWN }
+};
+
+static const VASTAPIEncodeType vastapi_encode_type_av1 = {
+    .profiles = vastapi_encode_av1_profiles,
+
+    .flags = FLAG_SLICE_CONTROL | FLAG_B_PICTURES | FLAG_B_PICTURE_REFERENCES | FLAG_NON_IDR_KEY_PICTURES,
+
+    .default_quality = 100,
+
+    .picture_priv_data_size = sizeof(VASTAPIEncodeAV1Picture),
+
+    .configure = &vastapi_encode_av1_configure,
+
+    .sequence_params_size = sizeof(VASTEncSequenceParameterBufferAV1),
+    .init_sequence_params = &vastapi_encode_av1_init_sequence_params,
+
+    .picture_params_size = sizeof(VASTEncPictureParameterBufferAV1),
+    .init_picture_params = &vastapi_encode_av1_init_picture_params,
+
+    .slice_params_size = sizeof(VASTEncSliceParameterBufferAV1),
+    .init_slice_params = &vastapi_encode_av1_init_slice_params,
+
+    .sequence_header_type  = VASTEncPackedHeaderSequence,
+    .write_sequence_header = &vastapi_encode_av1_write_sequence_header,
+};
+
+static av_cold int vastapi_encode_av1_init(AVCodecContext *avctx)
+{
+    // printf(">>> vastapi_encode_av1_init\n");
+    VASTAPIEncodeContext    *ctx  = avctx->priv_data;
+    VASTAPIEncodeAV1Context *priv = avctx->priv_data;
+
+    ctx->codec = &vastapi_encode_type_av1;
+
+    // No packed headers are currently desired.  They could be written,
+    // but there isn't any reason to do so - the one usable driver (i965)
+    // can write its own headers and there is no metadata to include.
+    ctx->desired_packed_headers = 0;
+
+    if (avctx->profile == FF_PROFILE_UNKNOWN)
+        avctx->profile = priv->profile;
+    if (avctx->level == FF_LEVEL_UNKNOWN)
+        avctx->level = priv->level;
+
+// Reject unsupported profiles.
+    switch (avctx->profile) {
+    case FF_PROFILE_AV1_HIGH:
+    case FF_PROFILE_AV1_PROFESSIONAL:
+        av_log(avctx, AV_LOG_WARNING,
+               "AV1 high and professional profile is not "
+               "supported hardware, using main profile instead.\n");
+        avctx->profile = FF_PROFILE_AV1_MAIN;
+        break;
+    }
+
+    if (avctx->level != FF_LEVEL_UNKNOWN && avctx->level & ~0xff) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Invalid level %d: must fit "
+               "in 8-bit unsigned integer.\n",
+               avctx->level);
+        return AVERROR(EINVAL);
+    }
+
+    ctx->desired_packed_headers = VAST_ENC_PACKED_HEADER_SEQUENCE | // VPS, SPS and PPS.
+                                  VAST_ENC_PACKED_HEADER_PICTURE |  // Slice headers.
+                                  VAST_ENC_PACKED_HEADER_MISC;      // SEI
+
+    // Surfaces must be aligned to superblock boundaries.
+    ctx->surface_width  = FFALIGN(avctx->width, 64);
+    ctx->surface_height = FFALIGN(avctx->height, 64);
+
+    ctx->slice_block_width = ctx->slice_block_height = 32;
+
+    ctx->vast_last_frame = 0; // 2pass
+
+    return _vastapi_encode_init(avctx);
+}
+
+static av_cold int vastapi_encode_av1_close(AVCodecContext *avctx)
+{
+    //    printf(">>> vastapi_encode_av1_close\n");
+    VASTAPIEncodeAV1Context *priv = avctx->priv_data;
+    ff_cbs_fragment_free(PRIV_CBC & priv->current_obu);
+    ff_cbs_close(&priv->cbc);
+
+    return _vastapi_encode_close(avctx);
+}
+
+// Standard JPEG quantisation tables, in zigzag order.
+static const unsigned char vastapi_encode_mjpeg_quant_luminance[64] = {
+    16, 11,  12, 14, 12, 10, 16,  14,  13,  14, 18, 17,  16,  19,  24,  40,  26, 24,  22,  22, 24, 49,
+    35, 37,  29, 40, 58, 51, 61,  60,  57,  51, 56, 55,  64,  72,  92,  78,  64, 68,  87,  69, 55, 56,
+    80, 109, 81, 87, 95, 98, 103, 104, 103, 62, 77, 113, 121, 112, 100, 120, 92, 101, 103, 99,
+};
+static const unsigned char vastapi_encode_mjpeg_quant_chrominance[64] = {
+    17, 18, 18, 24, 21, 24, 47, 26, 26, 47, 99, 66, 56, 66, 99, 99, 99, 99, 99, 99, 99, 99,
+    99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99,
+    99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99,
+};
+
+static int vastapi_encode_mjpeg_write_image_header(AVCodecContext *avctx, VASTAPIEncodePicture *pic,
+                                                   VASTAPIEncodeSlice *slice, char *data, size_t *data_len)
+{
+    VASTAPIEncodeMJPEGContext *priv = avctx->priv_data;
+    CodedBitstreamFragment    *frag = &priv->current_fragment;
+    int                        err;
+
+    if (priv->jfif) {
+        err = ff_cbs_insert_unit_content(PRIV_CBC frag, -1, JPEG_MARKER_APPN + 0, &priv->jfif_header, NULL);
+        if (err < 0)
+            goto fail;
+    }
+
+    err = ff_cbs_insert_unit_content(PRIV_CBC frag, -1, JPEG_MARKER_DQT, &priv->quant_tables, NULL);
+    if (err < 0)
+        goto fail;
+
+    err = ff_cbs_insert_unit_content(PRIV_CBC frag, -1, JPEG_MARKER_SOF0, &priv->frame_header, NULL);
+    if (err < 0)
+        goto fail;
+
+    if (priv->huffman) {
+        err = ff_cbs_insert_unit_content(PRIV_CBC frag, -1, JPEG_MARKER_DHT, &priv->huffman_tables, NULL);
+        if (err < 0)
+            goto fail;
+    }
+
+    err = ff_cbs_insert_unit_content(PRIV_CBC frag, -1, JPEG_MARKER_SOS, &priv->scan, NULL);
+    if (err < 0)
+        goto fail;
+
+    err = ff_cbs_write_fragment_data(priv->cbc, frag);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to write image header.\n");
+        goto fail;
+    }
+
+    if (*data_len < 8 * frag->data_size) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Image header too large: "
+               "%zu < %zu.\n",
+               *data_len, 8 * frag->data_size);
+        err = AVERROR(ENOSPC);
+        goto fail;
+    }
+
+    // Remove the EOI at the end of the fragment.
+    memcpy(data, frag->data, frag->data_size - 2);
+    *data_len = 8 * (frag->data_size - 2);
+
+    err = 0;
+fail:
+    ff_cbs_fragment_reset(PRIV_CBC frag);
+    return err;
+}
+
+static int vastapi_encode_mjpeg_write_extra_buffer(AVCodecContext *avctx, VASTAPIEncodePicture *pic, int index,
+                                                   int *type, char *data, size_t *data_len)
+{
+    VASTAPIEncodeMJPEGContext *priv = avctx->priv_data;
+    int                        t, i, k;
+
+    if (index == 0) {
+        // Write quantisation tables.
+        JPEGRawFrameHeader                    *fh  = &priv->frame_header;
+        JPEGRawQuantisationTableSpecification *dqt = &priv->quant_tables;
+        VASTQMatrixBufferJPEG                 *quant;
+
+        if (*data_len < sizeof(*quant))
+            return AVERROR(ENOSPC);
+        *type     = VASTQMatrixBufferType;
+        *data_len = sizeof(*quant);
+
+        quant = (VASTQMatrixBufferJPEG *)data;
+        memset(quant, 0, sizeof(*quant));
+
+        quant->load_lum_quantiser_matrix = 1;
+        for (i = 0; i < 64; i++)
+            quant->lum_quantiser_matrix[i] = dqt->table[fh->Tq[0]].Q[i];
+
+        if (fh->Nf > 1) {
+            quant->load_chroma_quantiser_matrix = 1;
+            for (i = 0; i < 64; i++)
+                quant->chroma_quantiser_matrix[i] = dqt->table[fh->Tq[1]].Q[i];
+        }
+
+    } else if (index == 1) {
+        // Write huffman tables.
+        JPEGRawScanHeader                  *sh  = &priv->scan.header;
+        JPEGRawHuffmanTableSpecification   *dht = &priv->huffman_tables;
+        VASTHuffmanTableBufferJPEGBaseline *huff;
+
+        if (*data_len < sizeof(*huff))
+            return AVERROR(ENOSPC);
+        *type     = VASTHuffmanTableBufferType;
+        *data_len = sizeof(*huff);
+
+        huff = (VASTHuffmanTableBufferJPEGBaseline *)data;
+        memset(huff, 0, sizeof(*huff));
+
+        for (t = 0; t < 1 + (sh->Ns > 1); t++) {
+            const JPEGRawHuffmanTable *ht;
+
+            huff->load_huffman_table[t] = 1;
+
+            ht = &dht->table[2 * t];
+            for (i = k = 0; i < 16; i++)
+                k += (huff->huffman_table[t].num_dc_codes[i] = ht->L[i]);
+            av_assert0(k <= sizeof(huff->huffman_table[t].dc_values));
+            for (i = 0; i < k; i++)
+                huff->huffman_table[t].dc_values[i] = ht->V[i];
+
+            ht = &dht->table[2 * t + 1];
+            for (i = k = 0; i < 16; i++)
+                k += (huff->huffman_table[t].num_ac_codes[i] = ht->L[i]);
+            av_assert0(k <= sizeof(huff->huffman_table[t].ac_values));
+            for (i = 0; i < k; i++)
+                huff->huffman_table[t].ac_values[i] = ht->V[i];
+        }
+
+    } else {
+        return AVERROR_EOF;
+    }
+    return 0;
+}
+
+static int vastapi_encode_mjpeg_init_picture_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic)
+{
+    VASTAPIEncodeMJPEGContext         *priv = avctx->priv_data;
+    JPEGRawFrameHeader                *fh   = &priv->frame_header;
+    JPEGRawScanHeader                 *sh   = &priv->scan.header;
+    VASTEncPictureParameterBufferJPEG *vpic = pic->codec_picture_params;
+    const AVPixFmtDescriptor          *desc;
+    const uint8_t                      components_rgb[3] = { 'R', 'G', 'B' };
+    const uint8_t                      components_yuv[3] = { 1, 2, 3 };
+    const uint8_t                     *components;
+    int                                t, i, quant_scale, len;
+
+    desc = av_pix_fmt_desc_get(AVHWFramesContextPtr(priv->common.input_frames)->sw_format);
+    av_assert0(desc);
+    if (desc->flags & AV_PIX_FMT_FLAG_RGB)
+        components = components_rgb;
+    else
+        components = components_yuv;
+
+    // Frame header.
+
+    fh->P  = 8;
+    fh->Y  = avctx->height;
+    fh->X  = avctx->width;
+    fh->Nf = desc->nb_components;
+
+    for (i = 0; i < fh->Nf; i++) {
+        fh->C[i] = components[i];
+        fh->H[i] = 1 + (i == 0 ? desc->log2_chroma_w : 0);
+        fh->V[i] = 1 + (i == 0 ? desc->log2_chroma_h : 0);
+
+        fh->Tq[i] = !!i;
+    }
+
+    fh->Lf = 8 + 3 * fh->Nf;
+
+    // JFIF header.
+    if (priv->jfif) {
+        JPEGRawApplicationData *app = &priv->jfif_header;
+        AVRational              sar = AVFramePtr(pic->input_image)->sample_aspect_ratio;
+        int                     sar_w, sar_h;
+        PutByteContext          pbc;
+
+        bytestream2_init_writer(&pbc, priv->jfif_data, sizeof(priv->jfif_data));
+
+        bytestream2_put_buffer(&pbc, "JFIF", 5);
+        bytestream2_put_be16(&pbc, 0x0102);
+        bytestream2_put_byte(&pbc, 0);
+
+        av_reduce(&sar_w, &sar_h, sar.num, sar.den, 65535);
+        if (sar_w && sar_h) {
+            bytestream2_put_be16(&pbc, sar_w);
+            bytestream2_put_be16(&pbc, sar_h);
+        } else {
+            bytestream2_put_be16(&pbc, 1);
+            bytestream2_put_be16(&pbc, 1);
+        }
+
+        bytestream2_put_byte(&pbc, 0);
+        bytestream2_put_byte(&pbc, 0);
+
+        av_assert0(bytestream2_get_bytes_left_p(&pbc) == 0);
+
+        app->Lp     = 2 + sizeof(priv->jfif_data);
+        app->Ap     = priv->jfif_data;
+        app->Ap_ref = NULL;
+    }
+
+    // Quantisation tables.
+
+    if (priv->quality < 50)
+        quant_scale = 5000 / priv->quality;
+    else
+        quant_scale = 200 - 2 * priv->quality;
+
+    len = 2;
+
+    for (t = 0; t < 1 + (fh->Nf > 1); t++) {
+        JPEGRawQuantisationTable *quant = &priv->quant_tables.table[t];
+        const uint8_t *data = t == 0 ? vastapi_encode_mjpeg_quant_luminance : vastapi_encode_mjpeg_quant_chrominance;
+
+        quant->Pq = 0;
+        quant->Tq = t;
+        for (i = 0; i < 64; i++)
+            quant->Q[i] = av_clip(data[i] * quant_scale / 100, 1, 255);
+
+        len += 65;
+    }
+
+    priv->quant_tables.Lq = len;
+
+    // Huffman tables.
+
+    len = 2;
+
+#if FF_GE(N500)
+#define MJPEG_VAR(x) ff_##x
+#else
+#define MJPEG_VAR(x) avpriv_##x
+#endif
+
+    for (t = 0; t < 2 + 2 * (fh->Nf > 1); t++) {
+        JPEGRawHuffmanTable *huff = &priv->huffman_tables.table[t];
+        const uint8_t       *lengths, *values;
+        int                  k;
+
+        switch (t) {
+        case 0:
+            lengths = MJPEG_VAR(mjpeg_bits_dc_luminance) + 1;
+            values  = MJPEG_VAR(mjpeg_val_dc);
+            break;
+        case 1:
+            lengths = MJPEG_VAR(mjpeg_bits_ac_luminance) + 1;
+            values  = MJPEG_VAR(mjpeg_val_ac_luminance);
+            break;
+        case 2:
+            lengths = MJPEG_VAR(mjpeg_bits_dc_chrominance) + 1;
+            values  = MJPEG_VAR(mjpeg_val_dc);
+            break;
+        case 3:
+            lengths = MJPEG_VAR(mjpeg_bits_ac_chrominance) + 1;
+            values  = MJPEG_VAR(mjpeg_val_ac_chrominance);
+            break;
+        }
+
+#undef MJPEG_VAR
+
+        huff->Tc = t % 2;
+        huff->Th = t / 2;
+
+        for (i = k = 0; i < 16; i++)
+            k += (huff->L[i] = lengths[i]);
+
+        for (i = 0; i < k; i++)
+            huff->V[i] = values[i];
+
+        len += 17 + k;
+    }
+
+    priv->huffman_tables.Lh = len;
+
+    // Scan header.
+
+    sh->Ns = fh->Nf;
+
+    for (i = 0; i < fh->Nf; i++) {
+        sh->Cs[i] = fh->C[i];
+        sh->Td[i] = i > 0;
+        sh->Ta[i] = i > 0;
+    }
+
+    sh->Ss = 0;
+    sh->Se = 63;
+    sh->Ah = 0;
+    sh->Al = 0;
+
+    sh->Ls = 6 + 2 * sh->Ns;
+
+    *vpic = (VASTEncPictureParameterBufferJPEG) {
+        .reconstructed_picture = pic->recon_surface,
+        .coded_buf             = pic->output_buffer,
+
+        .picture_width  = fh->X,
+        .picture_height = fh->Y,
+
+        .pic_flags.bits = {
+            .profile      = 0,
+            .progressive  = 0,
+            .huffman      = 1,
+            .interleaved  = 0,
+            .differential = 0,
+        },
+
+        .sample_bit_depth = fh->P,
+        .num_scan         = 1,
+        .num_components   = fh->Nf,
+
+        // The driver modifies the provided quantisation tables according
+        // to this quality value; the middle value of 50 makes that the
+        // identity so that they are used unchanged.
+        .quality = 50,
+    };
+
+    for (i = 0; i < fh->Nf; i++) {
+        vpic->component_id[i]             = fh->C[i];
+        vpic->quantiser_table_selector[i] = fh->Tq[i];
+    }
+
+    pic->nb_slices = 1;
+
+    return 0;
+}
+
+static int vastapi_encode_mjpeg_init_slice_params(AVCodecContext *avctx, VASTAPIEncodePicture *pic,
+                                                  VASTAPIEncodeSlice *slice)
+{
+    VASTAPIEncodeMJPEGContext       *priv   = avctx->priv_data;
+    JPEGRawScanHeader               *sh     = &priv->scan.header;
+    VASTEncSliceParameterBufferJPEG *vslice = slice->codec_slice_params;
+    int                              i;
+
+    *vslice = (VASTEncSliceParameterBufferJPEG){
+        .restart_interval = 0,
+        .num_components   = sh->Ns,
+    };
+
+    for (i = 0; i < sh->Ns; i++) {
+        vslice->components[i].component_selector = sh->Cs[i];
+        vslice->components[i].dc_table_selector  = sh->Td[i];
+        vslice->components[i].ac_table_selector  = sh->Ta[i];
+    }
+
+    return 0;
+}
+
+static av_cold int vastapi_encode_mjpeg_configure(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext      *ctx  = avctx->priv_data;
+    VASTAPIEncodeMJPEGContext *priv = avctx->priv_data;
+    int                        err  = 0;
+
+    priv->quality = ctx->rc_quality;
+    if (priv->quality < 1 || priv->quality > 100) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Invalid quality value %d "
+               "(must be 1-100).\n",
+               priv->quality);
+        return AVERROR(EINVAL);
+    }
+
+    // Hack: the implementation calls the JPEG image header (which we
+    // will use in the same way as a slice header) generic "raw data".
+    // Therefore, if after the packed header capability check we have
+    // PACKED_HEADER_RAW_DATA available, rewrite it as
+    // PACKED_HEADER_SLICE so that the header-writing code can do the
+    // right thing.
+    if (ctx->va_packed_headers & VAST_ENC_PACKED_HEADER_RAW_DATA) {
+        ctx->va_packed_headers &= ~VAST_ENC_PACKED_HEADER_RAW_DATA;
+        ctx->va_packed_headers |= VAST_ENC_PACKED_HEADER_SLICE;
+    }
+
+    err = ff_cbs_init(&priv->cbc, AV_CODEC_ID_MJPEG, avctx);
+    return err;
+}
+
+static const VASTAPIEncodeProfile vastapi_encode_mjpeg_profiles[] = {
+    { FF_PROFILE_MJPEG_HUFFMAN_BASELINE_DCT, 8, 1, 0, 0, VASTProfileJPEGBaseline },
+    { FF_PROFILE_MJPEG_HUFFMAN_BASELINE_DCT, 8, 3, 1, 1, VASTProfileJPEGBaseline },
+    { FF_PROFILE_MJPEG_HUFFMAN_BASELINE_DCT, 8, 3, 1, 0, VASTProfileJPEGBaseline },
+    { FF_PROFILE_MJPEG_HUFFMAN_BASELINE_DCT, 8, 3, 0, 0, VASTProfileJPEGBaseline },
+    { FF_PROFILE_UNKNOWN }
+};
+
+static const VASTAPIEncodeType vastapi_encode_type_mjpeg = {
+    .profiles = vastapi_encode_mjpeg_profiles,
+
+    .flags = FLAG_CONSTANT_QUALITY_ONLY | FLAG_INTRA_ONLY,
+
+    .configure = &vastapi_encode_mjpeg_configure,
+
+    .default_quality = 80,
+
+    .picture_params_size = sizeof(VASTEncPictureParameterBufferJPEG),
+    .init_picture_params = &vastapi_encode_mjpeg_init_picture_params,
+
+    .slice_params_size = sizeof(VASTEncSliceParameterBufferJPEG),
+    .init_slice_params = &vastapi_encode_mjpeg_init_slice_params,
+
+    .slice_header_type  = VASTEncPackedHeaderRawData,
+    .write_slice_header = &vastapi_encode_mjpeg_write_image_header,
+
+    .write_extra_buffer = &vastapi_encode_mjpeg_write_extra_buffer,
+};
+
+static av_cold int vastapi_encode_mjpeg_init(AVCodecContext *avctx)
+{
+    VASTAPIEncodeContext *ctx = avctx->priv_data;
+
+    ctx->codec = &vastapi_encode_type_mjpeg;
+
+    // The JPEG image header - see note above.
+    ctx->desired_packed_headers = VAST_ENC_PACKED_HEADER_RAW_DATA;
+
+    ctx->surface_width  = FFALIGN(avctx->width, 8);
+    ctx->surface_height = FFALIGN(avctx->height, 8);
+
+    return _vastapi_encode_init(avctx);
+}
+
+static av_cold int vastapi_encode_mjpeg_close(AVCodecContext *avctx)
+{
+    VASTAPIEncodeMJPEGContext *priv = avctx->priv_data;
+
+    ff_cbs_fragment_free(PRIV_CBC & priv->current_fragment);
+    ff_cbs_close(&priv->cbc);
+
+    return _vastapi_encode_close(avctx);
+}
+
+///
+
+av_cold int ff_vastapi_encode_init(AVCodecContext *avctx)
+{
+    int ret = -1;
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_H264:
+        ret = vastapi_encode_h264_init(avctx);
+        break;
+    case AV_CODEC_ID_HEVC:
+        ret = vastapi_encode_h265_init(avctx);
+        break;
+    case AV_CODEC_ID_AV1:
+        ret = vastapi_encode_av1_init(avctx);
+        break;
+    case AV_CODEC_ID_MJPEG:
+        ret = vastapi_encode_mjpeg_init(avctx);
+        break;
+    }
+
+    return ret;
+}
+
+av_cold int ff_vastapi_encode_close(AVCodecContext *avctx)
+{
+    int ret = -1;
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_H264:
+        ret = vastapi_encode_h264_close(avctx);
+        break;
+    case AV_CODEC_ID_HEVC:
+        ret = vastapi_encode_h265_close(avctx);
+        break;
+    case AV_CODEC_ID_AV1:
+        ret = vastapi_encode_av1_close(avctx);
+        break;
+    case AV_CODEC_ID_MJPEG:
+        ret = vastapi_encode_mjpeg_close(avctx);
+        break;
+    }
+
+    return ret;
+}
+
+const AVCodecHWConfigInternal *ff_vastapi_encode_hw_configs[] = {
+    HW_CONFIG_ENCODER_FRAMES(VASTAPI, VASTAPI),
+    NULL,
+};
+
+const enum AVPixelFormat ff_vaenc_pix_fmts[] = {
+    AV_PIX_FMT_VASTAPI,
+    AV_PIX_FMT_NONE,
+};
diff --git a/libavcodec/vastapi_encode.h b/libavcodec/vastapi_encode.h
new file mode 100644
index 0000000..04f92f3
--- /dev/null
+++ b/libavcodec/vastapi_encode.h
@@ -0,0 +1,323 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVCODEC_VASTAPI_ENCODE_H
+#define AVCODEC_VASTAPI_ENCODE_H
+
+#include <stdint.h>
+
+#include "version.h"
+
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_vastapi.h"
+#include "libavutil/avassert.h"
+#include "libavutil/common.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "libavutil/mastering_display_metadata.h"
+
+#include "internal.h"
+#include "put_bits.h"
+#include "bytestream.h"
+#include "hwconfig.h"
+
+#include "avcodec.h"
+#include "cbs.h"
+#include "cbs_h264.h"
+#include "h264.h"
+#include "h264_levels.h"
+#include "h264_sei.h"
+
+#include "cbs_h265.h"
+#include "h265_profile_level.h"
+#include "hevc.h"
+#include "hevc_sei.h"
+
+#include "cbs_av1.h"
+#include "av1.h"
+
+#include "cbs_jpeg.h"
+#include "mjpeg.h"
+#include "jpegtables.h"
+
+#include "vastva/vastapi.h"
+#include "vastva/vastapi_dynlink_loader.h"
+
+#define FF_N412 AV_VERSION_INT(58, 35, 100)
+#define FF_N423 AV_VERSION_INT(58, 54, 100)
+#define FF_N430 AV_VERSION_INT(58, 91, 100)
+#define FF_N441 AV_VERSION_INT(58, 134, 100)
+#define FF_N500 AV_VERSION_INT(59, 18, 100)
+#define FF_N512 AV_VERSION_INT(59, 37, 100)
+#define FF_N600 AV_VERSION_INT(60, 3, 100)
+
+#define FF_LT(NXXX) (LIBAVCODEC_BUILD < FF_##NXXX)
+#define FF_LE(NXXX) (LIBAVCODEC_BUILD <= FF_##NXXX)
+#define FF_EQ(NXXX) (LIBAVCODEC_BUILD == FF_##NXXX)
+#define FF_GE(NXXX) (LIBAVCODEC_BUILD >= FF_##NXXX)
+#define FF_GT(NXXX) (LIBAVCODEC_BUILD > FF_##NXXX)
+
+#if FF_LT(N441)
+#define SEIRawUserDataUnregistered H264RawSEIUserDataUnregistered
+#endif
+
+typedef struct VASTAPIEncodeH264Context {
+    VASTAPIEncodeContext common;
+
+    // User options.
+    int qp;
+    int quality;
+    int coder;
+    int aud;
+    int sei;
+    int profile;
+    int level;
+
+    // Derived settings.
+    int mb_width;
+    int mb_height;
+
+    int fixed_qp_idr;
+    int fixed_qp_p;
+    int fixed_qp_b;
+
+    int dpb_frames;
+
+    // Writer structures.
+    CodedBitstreamContext *cbc;
+    CodedBitstreamFragment current_access_unit;
+
+    H264RawAUD   raw_aud;
+    H264RawSPS   raw_sps;
+    H264RawPPS   raw_pps;
+    H264RawSEI   raw_sei;
+    H264RawSlice raw_slice;
+
+    H264RawSEIBufferingPeriod  sei_buffering_period;
+    H264RawSEIPicTiming        sei_pic_timing;
+    H264RawSEIRecoveryPoint    sei_recovery_point;
+    SEIRawUserDataUnregistered sei_identifier;
+    char                      *sei_identifier_string;
+
+    int aud_needed;
+    int sei_needed;
+    int sei_cbr_workaround_needed;
+} VASTAPIEncodeH264Context;
+
+#if FF_LT(N441)
+#undef SEIRawUserDataUnregistered // H264RawSEIUserDataUnregistered
+#endif
+
+#if FF_LT(N441)
+#define SEIRawMasteringDisplayColourVolume H265RawSEIMasteringDisplayColourVolume
+#define SEIRawContentLightLevelInfo H265RawSEIContentLightLevelInfo
+#endif
+
+typedef struct VASTAPIEncodeH265Context {
+    VASTAPIEncodeContext common;
+
+    // User options.
+    int qp;
+    int aud;
+    int profile;
+    int tier;
+    int level;
+    int sei;
+
+    // Derived settings.
+    int fixed_qp_idr;
+    int fixed_qp_p;
+    int fixed_qp_b;
+
+    // Writer structures.
+    H265RawAUD   raw_aud;
+    H265RawVPS   raw_vps;
+    H265RawSPS   raw_sps;
+    H265RawPPS   raw_pps;
+    H265RawSEI   raw_sei;
+    H265RawSlice raw_slice;
+
+    SEIRawMasteringDisplayColourVolume sei_mastering_display;
+    SEIRawContentLightLevelInfo        sei_content_light_level;
+
+    CodedBitstreamContext *cbc;
+    CodedBitstreamFragment current_access_unit;
+    int                    aud_needed;
+    int                    sei_needed;
+    short                  rate_emu;
+} VASTAPIEncodeH265Context;
+
+#if FF_LT(N441)
+#undef SEIRawMasteringDisplayColourVolume // H265RawSEIMasteringDisplayColourVolume
+#undef SEIRawContentLightLevelInfo        // H265RawSEIContentLightLevelInfo
+#endif
+
+typedef struct VASTAPIEncodeAV1Context {
+    VASTAPIEncodeContext common;
+    AV1RawOBU sh; /**< sequence header.*/
+    AV1RawOBU fh; /**< frame header.*/
+    AV1RawOBU mh[4]; /**< metadata header.*/
+    int nb_mh;
+    CodedBitstreamContext *cbc;
+    CodedBitstreamFragment current_obu;
+
+    char sh_data[MAX_PARAM_BUFFER_SIZE]; /**< coded sequence header data. */
+    size_t sh_data_len; /**< bit length of sh_data. */
+    char fh_data[MAX_PARAM_BUFFER_SIZE]; /**< coded frame header data. */
+    size_t fh_data_len; /**< bit length of fh_data. */
+
+    uint8_t uniform_tile;
+    uint8_t use_128x128_superblock;
+    int sb_cols;
+    int sb_rows;
+    int tile_cols_log2;
+    int tile_rows_log2;
+    int max_tile_width_sb;
+    int max_tile_height_sb;
+    uint8_t width_in_sbs_minus_1[AV1_MAX_TILE_COLS];
+    uint8_t height_in_sbs_minus_1[AV1_MAX_TILE_ROWS];
+
+    int min_log2_tile_cols;
+    int max_log2_tile_cols;
+    int min_log2_tile_rows;
+    int max_log2_tile_rows;
+
+    int q_idx_idr;
+    int q_idx_p;
+    int q_idx_b;
+
+    /** bit positions in current frame header */
+    int qindex_offset;
+    int loopfilter_offset;
+    int cdef_start_offset;
+    int cdef_param_size;
+
+    /** user options */
+    int profile;
+    int level;
+    int tier;
+    int tile_cols, tile_rows;
+    int tile_groups;
+
+} VASTAPIEncodeAV1Context;
+
+typedef struct VASTAPIEncodeMJPEGContext {
+    VASTAPIEncodeContext common;
+
+    // User options.
+    int jfif;
+    int huffman;
+
+    // Derived settings.
+    int     quality;
+    uint8_t jfif_data[14];
+
+    // Writer structures.
+    JPEGRawFrameHeader                    frame_header;
+    JPEGRawScan                           scan;
+    JPEGRawApplicationData                jfif_header;
+    JPEGRawQuantisationTableSpecification quant_tables;
+    JPEGRawHuffmanTableSpecification      huffman_tables;
+
+    CodedBitstreamContext *cbc;
+    CodedBitstreamFragment current_fragment;
+} VASTAPIEncodeMJPEGContext;
+
+typedef union {
+    VASTAPIEncodeH264Context  h264;
+    VASTAPIEncodeH265Context  hevc;
+    VASTAPIEncodeAV1Context   av1;
+    VASTAPIEncodeMJPEGContext mjpeg;
+} VaEncContext;
+
+#if FF_LT(N441)
+int ff_vastapi_encode_send_frame(AVCodecContext *avctx, const AVFrame *frame);
+#endif
+int ff_vastapi_encode_receive_packet(AVCodecContext *avctx, AVPacket *pkt);
+
+int ff_vastapi_encode_init(AVCodecContext *avctx);
+int ff_vastapi_encode_close(AVCodecContext *avctx);
+int ff_vastapi_encode_reset_init(AVCodecContext *avctx);
+int ff_vastapi_encode_reset_close(AVCodecContext *avctx);
+int ff_vastapi_encode_reset_flush(AVCodecContext *avctx); // vastai reset
+
+extern const AVCodecHWConfigInternal *ff_vastapi_encode_hw_configs[];
+extern const enum AVPixelFormat       ff_vaenc_pix_fmts[];
+
+#define VASTAPI_ENCODE_COMMON_OPTIONS                                                                                  \
+    { "crf",                                                                                                           \
+      "Select the quality for constant quality mode",                                                                  \
+      OFFSET(common.explicit_crf),                                                                                     \
+      AV_OPT_TYPE_INT,                                                                                                 \
+      { .i64 = 0 },                                                                                                    \
+      0,                                                                                                               \
+      51,                                                                                                              \
+      FLAGS },                                                                                                         \
+        { "low_power",                                                                                                 \
+          "Use low-power encoding mode (only available on some platforms; "                                            \
+          "may not support all encoding features)",                                                                    \
+          OFFSET(common.low_power),                                                                                    \
+          AV_OPT_TYPE_BOOL,                                                                                            \
+          { .i64 = 0 },                                                                                                \
+          0,                                                                                                           \
+          1,                                                                                                           \
+          FLAGS },                                                                                                     \
+        { "idr_interval",                                                                                              \
+          "Distance (in I-frames) between IDR frames",                                                                 \
+          OFFSET(common.idr_interval),                                                                                 \
+          AV_OPT_TYPE_INT,                                                                                             \
+          { .i64 = 0 },                                                                                                \
+          0,                                                                                                           \
+          INT_MAX,                                                                                                     \
+          FLAGS },                                                                                                     \
+    {                                                                                                                  \
+        "b_depth", "Maximum B-frame reference depth", OFFSET(common.desired_b_depth), AV_OPT_TYPE_INT, { .i64 = 1 },   \
+            1, INT_MAX, FLAGS                                                                                          \
+    }
+
+#define VASTAPI_ENCODE_RC_MODE(name, desc)                                                                             \
+    {                                                                                                                  \
+#name, desc, 0, AV_OPT_TYPE_CONST, { .i64 = RC_MODE_##name }, 0, 0, FLAGS, "rc_mode"                           \
+    }
+#define VASTAPI_ENCODE_RC_OPTIONS                                                                                      \
+    { "rc_mode",                                                                                                       \
+      "Set rate control mode",                                                                                         \
+      OFFSET(common.explicit_rc_mode),                                                                                 \
+      AV_OPT_TYPE_INT,                                                                                                 \
+      { .i64 = RC_MODE_AUTO },                                                                                         \
+      RC_MODE_AUTO,                                                                                                    \
+      RC_MODE_MAX,                                                                                                     \
+      FLAGS,                                                                                                           \
+      "rc_mode" },                                                                                                     \
+        { "auto",                                                                                                      \
+          "Choose mode automatically based on other parameters",                                                       \
+          0,                                                                                                           \
+          AV_OPT_TYPE_CONST,                                                                                           \
+          { .i64 = RC_MODE_AUTO },                                                                                     \
+          0,                                                                                                           \
+          0,                                                                                                           \
+          FLAGS,                                                                                                       \
+          "rc_mode" },                                                                                                 \
+        VASTAPI_ENCODE_RC_MODE(CQP, "Constant-quality"), VASTAPI_ENCODE_RC_MODE(CBR, "Constant-bitrate"),              \
+        VASTAPI_ENCODE_RC_MODE(VBR, "Variable-bitrate"), VASTAPI_ENCODE_RC_MODE(ICQ, "Intelligent constant-quality"),  \
+        VASTAPI_ENCODE_RC_MODE(QVBR, "Quality-defined variable-bitrate"),                                              \
+        VASTAPI_ENCODE_RC_MODE(AVBR, "Average variable-bitrate")
+
+#endif /* AVCODEC_VASTAPI_ENCODE_H */
diff --git a/libavcodec/vastapi_encode_av1.c b/libavcodec/vastapi_encode_av1.c
new file mode 100755
index 0000000..17432be
--- /dev/null
+++ b/libavcodec/vastapi_encode_av1.c
@@ -0,0 +1,140 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/internal.h"
+#include "avcodec.h"
+#include "vastapi_encode.h"
+#if FF_GE(N512)
+#include "codec_internal.h"
+#endif
+
+#define OFFSET(x) offsetof(VASTAPIEncodeAV1Context, x)
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM)
+static const AVOption vastapi_encode_av1_options[] = {
+    VASTAPI_ENCODE_COMMON_OPTIONS,
+    VASTAPI_ENCODE_RC_OPTIONS,
+
+    { "udu_sei",
+      "Use user data unregistered SEI if available",
+      offsetof(VASTAPIEncodeContext, udu_sei),
+      AV_OPT_TYPE_BOOL,
+      { .i64 = 0 },
+      0,
+      1,
+      FLAGS },
+
+    { "profile",
+      "Set profile (general_profile_idc)",
+      OFFSET(profile),
+      AV_OPT_TYPE_INT,
+      { .i64 = FF_PROFILE_UNKNOWN },
+      FF_PROFILE_UNKNOWN,
+      0xff,
+      FLAGS,
+      "profile" },
+
+#define PROFILE(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, { .i64 = value }, 0, 0, FLAGS, "profile"
+    { PROFILE("main", FF_PROFILE_AV1_MAIN) },
+    { PROFILE("high", FF_PROFILE_AV1_HIGH) },
+    { PROFILE("professional", FF_PROFILE_AV1_PROFESSIONAL) },
+#undef PROFILE
+
+{ "level",
+      "Set level (general_level_idc)",
+      OFFSET(level),
+      AV_OPT_TYPE_INT,
+      { .i64 = FF_LEVEL_UNKNOWN },
+      FF_LEVEL_UNKNOWN,
+      0xff,
+      FLAGS,
+      "level" },
+
+#define LEVEL(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, { .i64 = value }, 0, 0, FLAGS, "level"
+    { LEVEL("5.1", 13) },
+#undef LEVEL
+
+    { "vast-params",
+      "set the hantro vastapi configuration using a :-separated list of key=value parameters",
+      offsetof(VASTAPIEncodeContext, vast_opts),
+      AV_OPT_TYPE_DICT,
+      { .str = NULL },
+      0,
+      0,
+      FLAGS },
+    { "rate_emu", "-re case", offsetof(VASTAPIEncodeContext, rate_emu), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, FLAGS },
+
+    { NULL },
+};
+
+#if FF_GE(N512)
+static const FFCodecDefault
+#else
+static const AVCodecDefault
+#endif
+    vastapi_encode_av1_defaults[] = {
+        { "b", "0" },           { "bf", "2" },        { "g", "350" },   { "i_qfactor", "1" }, { "i_qoffset", "0" },
+        { "b_qfactor", "6/5" }, { "b_qoffset", "0" }, { "qmin", "-1" }, { "qmax", "-1" },     { NULL },
+    };
+
+static const AVClass vastapi_encode_av1_class = {
+    .class_name = "av1_vastapi",
+    .item_name  = av_default_item_name,
+    .option     = vastapi_encode_av1_options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+#if FF_GE(N512)
+const FFCodec ff_av1_vastapi_encoder = {
+    .p.name         = "av1_vastapi",
+    .p.long_name    = NULL_IF_CONFIG_SMALL("AV1 (VASTAPI)"),
+    .p.type         = AVMEDIA_TYPE_VIDEO,
+    .p.id           = AV_CODEC_ID_AV1,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+    FF_CODEC_RECEIVE_PACKET_CB(&ff_vastapi_encode_receive_packet),
+    .close          = &ff_vastapi_encode_close,
+    .p.priv_class   = &vastapi_encode_av1_class,
+    .p.capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_av1_defaults,
+    .p.pix_fmts     = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .p.wrapper_name = "vastapi",
+};
+#else
+AVCodec ff_av1_vastapi_encoder = {
+    .name           = "av1_vastapi",
+    .long_name      = NULL_IF_CONFIG_SMALL("AV1 (VASTAPI)"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_AV1,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+#if FF_LT(N441)
+    .send_frame     = &ff_vastapi_encode_send_frame,
+#endif
+    .receive_packet = &ff_vastapi_encode_receive_packet,
+    .close          = &ff_vastapi_encode_close,
+    .priv_class     = &vastapi_encode_av1_class,
+    .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_av1_defaults,
+    .pix_fmts       = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .wrapper_name   = "vastapi",
+};
+#endif
diff --git a/libavcodec/vastapi_encode_h264.c b/libavcodec/vastapi_encode_h264.c
new file mode 100644
index 0000000..e483619
--- /dev/null
+++ b/libavcodec/vastapi_encode_h264.c
@@ -0,0 +1,218 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/internal.h"
+#include "avcodec.h"
+#include "vastapi_encode.h"
+#if FF_GE(N512)
+#include "codec_internal.h"
+#endif
+
+#define OFFSET(x) offsetof(VASTAPIEncodeH264Context, x)
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM)
+static const AVOption vastapi_encode_h264_options[] = {
+    VASTAPI_ENCODE_COMMON_OPTIONS,
+    VASTAPI_ENCODE_RC_OPTIONS,
+
+    { "qp",
+      "Constant QP (for P-frames; scaled by qfactor/qoffset for I/B)",
+      OFFSET(qp),
+      AV_OPT_TYPE_INT,
+      { .i64 = 0 },
+      0,
+      52,
+      FLAGS },
+    { "quality",
+      "Set encode quality (trades off against speed, higher is faster)",
+      OFFSET(quality),
+      AV_OPT_TYPE_INT,
+      { .i64 = -1 },
+      -1,
+      INT_MAX,
+      FLAGS },
+    { "coder", "Entropy coder type", OFFSET(coder), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, 1, FLAGS, "coder" },
+    { "cavlc", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 }, INT_MIN, INT_MAX, FLAGS, "coder" },
+    { "cabac", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 }, INT_MIN, INT_MAX, FLAGS, "coder" },
+    { "vlc", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 }, INT_MIN, INT_MAX, FLAGS, "coder" },
+    { "ac", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 }, INT_MIN, INT_MAX, FLAGS, "coder" },
+
+    { "aud", "Include AUD", OFFSET(aud), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, FLAGS },
+
+    { "sei",
+      "Set SEI to include",
+      OFFSET(sei),
+      AV_OPT_TYPE_FLAGS,
+      { .i64 = SEI_IDENTIFIER | SEI_TIMING | SEI_RECOVERY_POINT },
+      0,
+      INT_MAX,
+      FLAGS,
+      "sei" },
+    { "identifier",
+      "Include encoder version identifier",
+      0,
+      AV_OPT_TYPE_CONST,
+      { .i64 = SEI_IDENTIFIER },
+      INT_MIN,
+      INT_MAX,
+      FLAGS,
+      "sei" },
+    { "timing",
+      "Include timing parameters (buffering_period and pic_timing)",
+      0,
+      AV_OPT_TYPE_CONST,
+      { .i64 = SEI_TIMING },
+      INT_MIN,
+      INT_MAX,
+      FLAGS,
+      "sei" },
+    { "recovery_point",
+      "Include recovery points where appropriate",
+      0,
+      AV_OPT_TYPE_CONST,
+      { .i64 = SEI_RECOVERY_POINT },
+      INT_MIN,
+      INT_MAX,
+      FLAGS,
+      "sei" },
+
+    { "profile",
+      "Set profile (profile_idc and constraint_set*_flag)",
+      OFFSET(profile),
+      AV_OPT_TYPE_INT,
+      { .i64 = FF_PROFILE_UNKNOWN },
+      FF_PROFILE_UNKNOWN,
+      0xffff,
+      FLAGS,
+      "profile" },
+
+#define PROFILE(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, { .i64 = value }, 0, 0, FLAGS, "profile"
+    { PROFILE("constrained_baseline", FF_PROFILE_H264_CONSTRAINED_BASELINE) },
+    { PROFILE("main", FF_PROFILE_H264_MAIN) },
+    { PROFILE("high", FF_PROFILE_H264_HIGH) },
+#undef PROFILE
+
+    { "level",
+      "Set level (level_idc)",
+      OFFSET(level),
+      AV_OPT_TYPE_INT,
+      { .i64 = FF_LEVEL_UNKNOWN },
+      FF_LEVEL_UNKNOWN,
+      0xff,
+      FLAGS,
+      "level" },
+
+#define LEVEL(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, { .i64 = value }, 0, 0, FLAGS, "level"
+    { LEVEL("1", 10) },
+    { LEVEL("1.1", 11) },
+    { LEVEL("1.2", 12) },
+    { LEVEL("1.3", 13) },
+    { LEVEL("2", 20) },
+    { LEVEL("2.1", 21) },
+    { LEVEL("2.2", 22) },
+    { LEVEL("3", 30) },
+    { LEVEL("3.1", 31) },
+    { LEVEL("3.2", 32) },
+    { LEVEL("4", 40) },
+    { LEVEL("4.1", 41) },
+    { LEVEL("4.2", 42) },
+    { LEVEL("5", 50) },
+    { LEVEL("5.1", 51) },
+    { LEVEL("5.2", 52) },
+    { LEVEL("6", 60) },
+    { LEVEL("6.1", 61) },
+    { LEVEL("6.2", 62) },
+#undef LEVEL
+
+    { "udu_sei",
+      "Use user data unregistered SEI if available",
+      offsetof(VASTAPIEncodeContext, udu_sei),
+      AV_OPT_TYPE_BOOL,
+      { .i64 = 0 },
+      0,
+      1,
+      FLAGS },
+
+    { "vast-params",
+      "set the vastai vastapi configuration using a :-separated list of key=value parameters",
+      offsetof(VASTAPIEncodeContext, vast_opts),
+      AV_OPT_TYPE_DICT,
+      { .str = NULL },
+      0,
+      0,
+      FLAGS },
+    { "rate_emu", "-re case", offsetof(VASTAPIEncodeContext, rate_emu), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, FLAGS },
+    { NULL },
+};
+
+#if FF_GE(N512)
+static const FFCodecDefault
+#else
+static const AVCodecDefault
+#endif
+    vastapi_encode_h264_defaults[] = {
+        { "b", "0" },           { "bf", "2" },        { "g", "120" },   { "i_qfactor", "1" }, { "i_qoffset", "0" },
+        { "b_qfactor", "6/5" }, { "b_qoffset", "0" }, { "qmin", "-1" }, { "qmax", "-1" },     { NULL },
+    };
+
+static const AVClass vastapi_encode_h264_class = {
+    .class_name = "h264_vastapi",
+    .item_name  = av_default_item_name,
+    .option     = vastapi_encode_h264_options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+#if FF_GE(N512)
+const FFCodec ff_h264_vastapi_encoder = {
+    .p.name         = "h264_vastapi",
+    .p.long_name    = NULL_IF_CONFIG_SMALL("H.264/AVC (VASTAPI)"),
+    .p.type         = AVMEDIA_TYPE_VIDEO,
+    .p.id           = AV_CODEC_ID_H264,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+    FF_CODEC_RECEIVE_PACKET_CB(&ff_vastapi_encode_receive_packet),
+    .close          = &ff_vastapi_encode_close,
+    .p.priv_class   = &vastapi_encode_h264_class,
+    .p.capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_h264_defaults,
+    .p.pix_fmts     = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .p.wrapper_name = "vastapi",
+};
+#else
+AVCodec ff_h264_vastapi_encoder = {
+    .name           = "h264_vastapi",
+    .long_name      = NULL_IF_CONFIG_SMALL("H.264/AVC (VASTAPI)"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_H264,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+#if FF_LT(N441)
+    .send_frame     = &ff_vastapi_encode_send_frame,
+#endif
+    .receive_packet = &ff_vastapi_encode_receive_packet,
+    .close          = &ff_vastapi_encode_close,
+    .priv_class     = &vastapi_encode_h264_class,
+    .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_h264_defaults,
+    .pix_fmts       = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .wrapper_name   = "vastapi",
+};
+#endif
diff --git a/libavcodec/vastapi_encode_h265.c b/libavcodec/vastapi_encode_h265.c
new file mode 100644
index 0000000..77b40ee
--- /dev/null
+++ b/libavcodec/vastapi_encode_h265.c
@@ -0,0 +1,186 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/internal.h"
+#include "avcodec.h"
+#include "vastapi_encode.h"
+#if FF_GE(N512)
+#include "codec_internal.h"
+#endif
+
+#define OFFSET(x) offsetof(VASTAPIEncodeH265Context, x)
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM)
+static const AVOption vastapi_encode_h265_options[] = {
+    VASTAPI_ENCODE_COMMON_OPTIONS,
+    VASTAPI_ENCODE_RC_OPTIONS,
+
+    { "qp",
+      "Constant QP (for P-frames; scaled by qfactor/qoffset for I/B)",
+      OFFSET(qp),
+      AV_OPT_TYPE_INT,
+      { .i64 = 0 },
+      0,
+      52,
+      FLAGS },
+
+    { "aud", "Include AUD", OFFSET(aud), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, FLAGS },
+
+    { "profile",
+      "Set profile (general_profile_idc)",
+      OFFSET(profile),
+      AV_OPT_TYPE_INT,
+      { .i64 = FF_PROFILE_UNKNOWN },
+      FF_PROFILE_UNKNOWN,
+      0xff,
+      FLAGS,
+      "profile" },
+
+#define PROFILE(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, { .i64 = value }, 0, 0, FLAGS, "profile"
+    { PROFILE("main", FF_PROFILE_HEVC_MAIN) },
+    { PROFILE("main10", FF_PROFILE_HEVC_MAIN_10) },
+    { PROFILE("rext", FF_PROFILE_HEVC_REXT) },
+#undef PROFILE
+
+    { "tier", "Set tier (general_tier_flag)", OFFSET(tier), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, FLAGS, "tier" },
+    { "main", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 }, 0, 0, FLAGS, "tier" },
+    { "high", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 }, 0, 0, FLAGS, "tier" },
+
+    { "level",
+      "Set level (general_level_idc)",
+      OFFSET(level),
+      AV_OPT_TYPE_INT,
+      { .i64 = FF_LEVEL_UNKNOWN },
+      FF_LEVEL_UNKNOWN,
+      0xff,
+      FLAGS,
+      "level" },
+
+#define LEVEL(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, { .i64 = value }, 0, 0, FLAGS, "level"
+    { LEVEL("1", 30) },
+    { LEVEL("2", 60) },
+    { LEVEL("2.1", 63) },
+    { LEVEL("3", 90) },
+    { LEVEL("3.1", 93) },
+    { LEVEL("4", 120) },
+    { LEVEL("4.1", 123) },
+    { LEVEL("5", 150) },
+    { LEVEL("5.1", 153) },
+    { LEVEL("5.2", 156) },
+    { LEVEL("6", 180) },
+    { LEVEL("6.1", 183) },
+    { LEVEL("6.2", 186) },
+#undef LEVEL
+
+    { "sei",
+      "Set SEI to include",
+      OFFSET(sei),
+      AV_OPT_TYPE_FLAGS,
+      { .i64 = SEI_MASTERING_DISPLAY | SEI_CONTENT_LIGHT_LEVEL },
+      0,
+      INT_MAX,
+      FLAGS,
+      "sei" },
+    { "hdr",
+      "Include HDR metadata for mastering display colour volume "
+      "and content light level information",
+      0,
+      AV_OPT_TYPE_CONST,
+      { .i64 = SEI_MASTERING_DISPLAY | SEI_CONTENT_LIGHT_LEVEL },
+      INT_MIN,
+      INT_MAX,
+      FLAGS,
+      "sei" },
+
+    { "udu_sei",
+      "Use user data unregistered SEI if available",
+      offsetof(VASTAPIEncodeContext, udu_sei),
+      AV_OPT_TYPE_BOOL,
+      { .i64 = 0 },
+      0,
+      1,
+      FLAGS },
+
+    { "vast-params",
+      "set the vastai configuration using a :-separated list of key=value parameters",
+      offsetof(VASTAPIEncodeContext, vast_opts),
+      AV_OPT_TYPE_DICT,
+      { .str = NULL },
+      0,
+      0,
+      FLAGS },
+    { "rate_emu", "-re case", offsetof(VASTAPIEncodeContext, rate_emu), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, FLAGS },
+    { NULL },
+};
+
+#if FF_GE(N512)
+static const FFCodecDefault
+#else
+static const AVCodecDefault
+#endif
+    vastapi_encode_h265_defaults[] = {
+        { "b", "0" },           { "bf", "2" },        { "g", "350" },   { "i_qfactor", "1" }, { "i_qoffset", "0" },
+        { "b_qfactor", "6/5" }, { "b_qoffset", "0" }, { "qmin", "-1" }, { "qmax", "-1" },     { NULL },
+    };
+
+static const AVClass vastapi_encode_h265_class = {
+    .class_name = "h265_vastapi",
+    .item_name  = av_default_item_name,
+    .option     = vastapi_encode_h265_options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+#if FF_GE(N512)
+const FFCodec ff_hevc_vastapi_encoder = {
+    .p.name         = "hevc_vastapi",
+    .p.long_name    = NULL_IF_CONFIG_SMALL("H.265/HEVC (VASTAPI)"),
+    .p.type         = AVMEDIA_TYPE_VIDEO,
+    .p.id           = AV_CODEC_ID_HEVC,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+    FF_CODEC_RECEIVE_PACKET_CB(&ff_vastapi_encode_receive_packet),
+    .close          = &ff_vastapi_encode_close,
+    .p.priv_class   = &vastapi_encode_h265_class,
+    .p.capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_h265_defaults,
+    .p.pix_fmts     = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .p.wrapper_name = "vastapi",
+};
+#else
+AVCodec ff_hevc_vastapi_encoder = {
+    .name           = "hevc_vastapi",
+    .long_name      = NULL_IF_CONFIG_SMALL("H.265/HEVC (VASTAPI)"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_HEVC,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+#if FF_LT(N441)
+    .send_frame     = &ff_vastapi_encode_send_frame,
+#endif
+    .receive_packet = &ff_vastapi_encode_receive_packet,
+    .close          = &ff_vastapi_encode_close,
+    .priv_class     = &vastapi_encode_h265_class,
+    .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_h265_defaults,
+    .pix_fmts       = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .wrapper_name   = "vastapi",
+};
+#endif
\ No newline at end of file
diff --git a/libavcodec/vastapi_encode_mjpeg.c b/libavcodec/vastapi_encode_mjpeg.c
new file mode 100644
index 0000000..861441c
--- /dev/null
+++ b/libavcodec/vastapi_encode_mjpeg.c
@@ -0,0 +1,101 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/internal.h"
+#include "avcodec.h"
+#include "vastapi_encode.h"
+#if FF_GE(N512)
+#include "codec_internal.h"
+#endif
+
+#define OFFSET(x) offsetof(VASTAPIEncodeMJPEGContext, x)
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM)
+static const AVOption vastapi_encode_mjpeg_options[] = {
+    VASTAPI_ENCODE_COMMON_OPTIONS,
+
+    { "jfif", "Include JFIF header", OFFSET(jfif), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, FLAGS },
+    { "huffman", "Include huffman tables", OFFSET(huffman), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, FLAGS },
+    { "vast-params",
+      "set the vastai configuration using a :-separated list of key=value parameters",
+      offsetof(VASTAPIEncodeContext, vast_opts),
+      AV_OPT_TYPE_DICT,
+      { .str = NULL },
+      0,
+      0,
+      FLAGS },
+
+    { NULL },
+};
+
+#if FF_GE(N512)
+static const FFCodecDefault
+#else
+static const AVCodecDefault
+#endif
+    vastapi_encode_mjpeg_defaults[] = {
+        { "b", "0" },
+        { NULL },
+    };
+
+static const AVClass vastapi_encode_mjpeg_class = {
+    .class_name = "mjpeg_vastapi",
+    .item_name  = av_default_item_name,
+    .option     = vastapi_encode_mjpeg_options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+#if FF_GE(N512)
+const FFCodec ff_mjpeg_vastapi_encoder = {
+    .p.name         = "mjpeg_vastapi",
+    .p.long_name    = NULL_IF_CONFIG_SMALL("MJPEG (VASTAPI)"),
+    .p.type         = AVMEDIA_TYPE_VIDEO,
+    .p.id           = AV_CODEC_ID_MJPEG,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+    FF_CODEC_RECEIVE_PACKET_CB(&ff_vastapi_encode_receive_packet),
+    .close          = &ff_vastapi_encode_close,
+    .p.priv_class   = &vastapi_encode_mjpeg_class,
+    .p.capabilities = AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_mjpeg_defaults,
+    .p.pix_fmts     = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .p.wrapper_name = "vastapi",
+};
+#else
+AVCodec ff_mjpeg_vastapi_encoder = {
+    .name           = "mjpeg_vastapi",
+    .long_name      = NULL_IF_CONFIG_SMALL("MJPEG (VASTAPI)"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_MJPEG,
+    .priv_data_size = sizeof(VaEncContext),
+    .init           = &ff_vastapi_encode_init,
+#if FF_LT(N441)
+    .send_frame     = &ff_vastapi_encode_send_frame,
+#endif
+    .receive_packet = &ff_vastapi_encode_receive_packet,
+    .close          = &ff_vastapi_encode_close,
+    .priv_class     = &vastapi_encode_mjpeg_class,
+    .capabilities   = AV_CODEC_CAP_HARDWARE,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .defaults       = vastapi_encode_mjpeg_defaults,
+    .pix_fmts       = ff_vaenc_pix_fmts,
+    .hw_configs     = ff_vastapi_encode_hw_configs,
+    .wrapper_name   = "vastapi",
+};
+#endif
\ No newline at end of file
diff --git a/libavcodec/vastapi_h264.c b/libavcodec/vastapi_h264.c
new file mode 100644
index 0000000..0f86595
--- /dev/null
+++ b/libavcodec/vastapi_h264.c
@@ -0,0 +1,376 @@
+/*
+ * H.264 HW decode acceleration through VAST API
+ *
+ * Copyright (C) 2008-2009 Splitted-Desktop Systems
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "h264dec.h"
+#include "h264_ps.h"
+#include "hwconfig.h"
+#include "vastapi_decode.h"
+
+/**
+ * @file
+ * This file implements the glue code between FFmpeg's and VAST API's
+ * structures for H.264 decoding.
+ */
+
+/**
+ * Initialize an empty VAST API picture.
+ *
+ * VAST API requires a fixed-size reference picture array.
+ */
+static void init_vastapi_pic(VASTPictureH264 *va_pic)
+{
+    va_pic->picture_id          = VAST_INVALID_ID;
+    va_pic->flags               = VAST_PICTURE_H264_INVALID;
+    va_pic->TopFieldOrderCnt    = 0;
+    va_pic->BottomFieldOrderCnt = 0;
+}
+
+/**
+ * Translate an FFmpeg Picture into its VAST API form.
+ *
+ * @param[out] va_pic          A pointer to VAST API's own picture struct
+ * @param[in]  pic             A pointer to the FFmpeg picture struct to convert
+ * @param[in]  pic_structure   The picture field type (as defined in mpegvideo.h),
+ *                             supersedes pic's field type if nonzero.
+ */
+static void fill_vastapi_pic(VASTPictureH264 *va_pic, const H264Picture *pic, int pic_structure)
+{
+    if (pic_structure == 0)
+        pic_structure = pic->reference;
+    pic_structure &= PICT_FRAME; /* PICT_TOP_FIELD|PICT_BOTTOM_FIELD */
+
+    va_pic->picture_id = ff_vastapi_get_surface_id(pic->f);
+    va_pic->frame_idx  = pic->long_ref ? pic->pic_id : pic->frame_num;
+
+    va_pic->flags = 0;
+    if (pic_structure != PICT_FRAME)
+        va_pic->flags |=
+            (pic_structure & PICT_TOP_FIELD) ? VAST_PICTURE_H264_TOP_FIELD : VAST_PICTURE_H264_BOTTOM_FIELD;
+    if (pic->reference)
+        va_pic->flags |= pic->long_ref ? VAST_PICTURE_H264_LONG_TERM_REFERENCE : VAST_PICTURE_H264_SHORT_TERM_REFERENCE;
+
+    va_pic->TopFieldOrderCnt = 0;
+    if (pic->field_poc[0] != INT_MAX)
+        va_pic->TopFieldOrderCnt = pic->field_poc[0];
+
+    va_pic->BottomFieldOrderCnt = 0;
+    if (pic->field_poc[1] != INT_MAX)
+        va_pic->BottomFieldOrderCnt = pic->field_poc[1];
+}
+
+/** Decoded Picture Buffer (DPB). */
+typedef struct DPB {
+    int size;                 ///< Current number of reference frames in the DPB
+    int max_size;             ///< Max number of reference frames. This is
+                              ///< FF_ARRAY_ELEMS(VASTPictureParameterBufferH264.ReferenceFrames)
+    VASTPictureH264 *va_pics; ///< Pointer to VASTPictureParameterBufferH264.ReferenceFrames array
+} DPB;
+
+/**
+ * Append picture to the decoded picture buffer, in a VAST API form that
+ * merges the second field picture attributes with the first, if
+ * available.  The decoded picture buffer's size must be large enough
+ * to receive the new VAST API picture object.
+ */
+static int dpb_add(DPB *dpb, const H264Picture *pic)
+{
+    int i;
+
+    if (dpb->size >= dpb->max_size)
+        return -1;
+
+    for (i = 0; i < dpb->size; i++) {
+        VASTPictureH264 * const va_pic = &dpb->va_pics[i];
+        if (va_pic->picture_id == ff_vastapi_get_surface_id(pic->f)) {
+            VASTPictureH264 temp_va_pic;
+            fill_vastapi_pic(&temp_va_pic, pic, 0);
+
+            if ((temp_va_pic.flags ^ va_pic->flags) & (VAST_PICTURE_H264_TOP_FIELD | VAST_PICTURE_H264_BOTTOM_FIELD)) {
+                va_pic->flags |= temp_va_pic.flags & (VAST_PICTURE_H264_TOP_FIELD | VAST_PICTURE_H264_BOTTOM_FIELD);
+                /* Merge second field */
+                if (temp_va_pic.flags & VAST_PICTURE_H264_TOP_FIELD) {
+                    va_pic->TopFieldOrderCnt = temp_va_pic.TopFieldOrderCnt;
+                } else {
+                    va_pic->BottomFieldOrderCnt = temp_va_pic.BottomFieldOrderCnt;
+                }
+            }
+            return 0;
+        }
+    }
+
+    fill_vastapi_pic(&dpb->va_pics[dpb->size++], pic, 0);
+    return 0;
+}
+
+/** Fill in VAST API reference frames array. */
+static int fill_vastapi_ReferenceFrames(VASTPictureParameterBufferH264 *pic_param, const H264Context *h)
+{
+    DPB dpb;
+    int i;
+
+    dpb.size     = 0;
+    dpb.max_size = FF_ARRAY_ELEMS(pic_param->ReferenceFrames);
+    dpb.va_pics  = pic_param->ReferenceFrames;
+    for (i = 0; i < dpb.max_size; i++)
+        init_vastapi_pic(&dpb.va_pics[i]);
+
+    for (i = 0; i < h->short_ref_count; i++) {
+        const H264Picture *pic = h->short_ref[i];
+        if (pic && pic->reference && dpb_add(&dpb, pic) < 0)
+            return -1;
+    }
+
+    for (i = 0; i < 16; i++) {
+        const H264Picture *pic = h->long_ref[i];
+        if (pic && pic->reference && dpb_add(&dpb, pic) < 0)
+            return -1;
+    }
+    return 0;
+}
+
+/**
+ * Fill in VAST API reference picture lists from the FFmpeg reference
+ * picture list.
+ *
+ * @param[out] RefPicList  VAST API internal reference picture list
+ * @param[in]  ref_list    A pointer to the FFmpeg reference list
+ * @param[in]  ref_count   The number of reference pictures in ref_list
+ */
+static void fill_vastapi_RefPicList(VASTPictureH264 RefPicList[32], const H264Ref *ref_list, unsigned int ref_count)
+{
+    unsigned int i, n = 0;
+    for (i = 0; i < ref_count; i++)
+        if (ref_list[i].reference)
+            fill_vastapi_pic(&RefPicList[n++], ref_list[i].parent, ref_list[i].reference);
+
+    for (; n < 32; n++)
+        init_vastapi_pic(&RefPicList[n]);
+}
+
+/**
+ * Fill in prediction weight table.
+ *
+ * VAST API requires a plain prediction weight table as it does not infer
+ * any value.
+ *
+ * @param[in]  h                   A pointer to the current H.264 context
+ * @param[in]  list                The reference frame list index to use
+ * @param[out] luma_weight_flag    VAST API plain luma weight flag
+ * @param[out] luma_weight         VAST API plain luma weight table
+ * @param[out] luma_offset         VAST API plain luma offset table
+ * @param[out] chroma_weight_flag  VAST API plain chroma weight flag
+ * @param[out] chroma_weight       VAST API plain chroma weight table
+ * @param[out] chroma_offset       VAST API plain chroma offset table
+ */
+static void fill_vastapi_plain_pred_weight_table(const H264Context *h, int list, unsigned char *luma_weight_flag,
+                                                 short luma_weight[32], short luma_offset[32],
+                                                 unsigned char *chroma_weight_flag, short chroma_weight[32][2],
+                                                 short chroma_offset[32][2])
+{
+    const H264SliceContext *sl = &h->slice_ctx[0];
+    unsigned int            i, j;
+
+    *luma_weight_flag   = sl->pwt.luma_weight_flag[list];
+    *chroma_weight_flag = sl->pwt.chroma_weight_flag[list];
+
+    for (i = 0; i < sl->ref_count[list]; i++) {
+        /* VAST API also wants the inferred (default) values, not
+           only what is available in the bitstream (7.4.3.2). */
+        if (sl->pwt.luma_weight_flag[list]) {
+            luma_weight[i] = sl->pwt.luma_weight[i][list][0];
+            luma_offset[i] = sl->pwt.luma_weight[i][list][1];
+        } else {
+            luma_weight[i] = 1 << sl->pwt.luma_log2_weight_denom;
+            luma_offset[i] = 0;
+        }
+        for (j = 0; j < 2; j++) {
+            if (sl->pwt.chroma_weight_flag[list]) {
+                chroma_weight[i][j] = sl->pwt.chroma_weight[i][list][j][0];
+                chroma_offset[i][j] = sl->pwt.chroma_weight[i][list][j][1];
+            } else {
+                chroma_weight[i][j] = 1 << sl->pwt.chroma_log2_weight_denom;
+                chroma_offset[i][j] = 0;
+            }
+        }
+    }
+}
+
+/** Initialize and start decoding a frame with VAST API. */
+static int vastapi_h264_start_frame(AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)
+{
+    const H264Context             *h   = avctx->priv_data;
+    VASTAPIDecodePicture          *pic = h->cur_pic_ptr->hwaccel_picture_private;
+    const PPS                     *pps = h->ps.pps;
+    const SPS                     *sps = h->ps.sps;
+    VASTPictureParameterBufferH264 pic_param;
+    VASTIQMatrixBufferH264         iq_matrix;
+    int                            err;
+
+    pic->output_surface = ff_vastapi_get_surface_id(h->cur_pic_ptr->f);
+
+    pic_param = (VASTPictureParameterBufferH264) {
+        .picture_width_in_mbs_minus1                = h->mb_width - 1,
+        .picture_height_in_mbs_minus1               = h->mb_height - 1,
+        .bit_depth_luma_minus8                      = sps->bit_depth_luma - 8,
+        .bit_depth_chroma_minus8                    = sps->bit_depth_chroma - 8,
+        .num_ref_frames                             = sps->ref_frame_count,
+        .seq_fields.bits = {
+            .chroma_format_idc                      = sps->chroma_format_idc,
+            .residual_colour_transform_flag         = sps->residual_color_transform_flag,
+            .gaps_in_frame_num_value_allowed_flag   = sps->gaps_in_frame_num_allowed_flag,
+            .frame_mbs_only_flag                    = sps->frame_mbs_only_flag,
+            .mb_adaptive_frame_field_flag           = sps->mb_aff,
+            .direct_8x8_inference_flag              = sps->direct_8x8_inference_flag,
+            .MinLumaBiPredSize8x8                   = sps->level_idc >= 31, /* A.3.3.2 */
+            .log2_max_frame_num_minus4              = sps->log2_max_frame_num - 4,
+            .pic_order_cnt_type                     = sps->poc_type,
+            .log2_max_pic_order_cnt_lsb_minus4      = sps->log2_max_poc_lsb - 4,
+            .delta_pic_order_always_zero_flag       = sps->delta_pic_order_always_zero_flag,
+        },
+        .pic_init_qp_minus26                        = pps->init_qp - 26,
+        .pic_init_qs_minus26                        = pps->init_qs - 26,
+        .chroma_qp_index_offset                     = pps->chroma_qp_index_offset[0],
+        .second_chroma_qp_index_offset              = pps->chroma_qp_index_offset[1],
+        .pic_fields.bits = {
+            .entropy_coding_mode_flag               = pps->cabac,
+            .weighted_pred_flag                     = pps->weighted_pred,
+            .weighted_bipred_idc                    = pps->weighted_bipred_idc,
+            .transform_8x8_mode_flag                = pps->transform_8x8_mode,
+            .field_pic_flag                         = h->picture_structure != PICT_FRAME,
+            .constrained_intra_pred_flag            = pps->constrained_intra_pred,
+            .pic_order_present_flag                 = pps->pic_order_present,
+            .deblocking_filter_control_present_flag = pps->deblocking_filter_parameters_present,
+            .redundant_pic_cnt_present_flag         = pps->redundant_pic_cnt_present,
+            .reference_pic_flag                     = h->nal_ref_idc != 0,
+        },
+        .frame_num                                  = h->poc.frame_num,
+    };
+
+    fill_vastapi_pic(&pic_param.CurrPic, h->cur_pic_ptr, h->picture_structure);
+    err = fill_vastapi_ReferenceFrames(&pic_param, h);
+    if (err < 0)
+        goto fail;
+
+    err =
+        ff_vastapi_decode_make_param_buffer(avctx, pic, VASTPictureParameterBufferType, &pic_param, sizeof(pic_param));
+    if (err < 0)
+        goto fail;
+
+    memcpy(iq_matrix.ScalingList4x4, pps->scaling_matrix4, sizeof(iq_matrix.ScalingList4x4));
+    memcpy(iq_matrix.ScalingList8x8[0], pps->scaling_matrix8[0], sizeof(iq_matrix.ScalingList8x8[0]));
+    memcpy(iq_matrix.ScalingList8x8[1], pps->scaling_matrix8[3], sizeof(iq_matrix.ScalingList8x8[0]));
+
+    err = ff_vastapi_decode_make_param_buffer(avctx, pic, VASTIQMatrixBufferType, &iq_matrix, sizeof(iq_matrix));
+    if (err < 0)
+        goto fail;
+
+    err = ff_vastapi_decode_start_frame(avctx, h->cur_pic_ptr->f);
+    if (err < 0)
+        goto fail;
+
+    return 0;
+
+fail:
+    ff_vastapi_decode_cancel(avctx, pic);
+    return err;
+}
+
+/** End a hardware decoding based frame. */
+static int vastapi_h264_end_frame(AVCodecContext *avctx)
+{
+    const H264Context    *h   = avctx->priv_data;
+    VASTAPIDecodePicture *pic = h->cur_pic_ptr->hwaccel_picture_private;
+    H264SliceContext     *sl  = &h->slice_ctx[0];
+    int                   ret;
+
+    ret = ff_vastapi_decode_issue(avctx, pic);
+    if (ret < 0)
+        goto finish;
+
+    ff_h264_draw_horiz_band(h, sl, 0, h->avctx->height);
+
+finish:
+    return ret;
+}
+
+/** Decode the given H.264 slice with VAST API. */
+static int vastapi_h264_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
+{
+    const H264Context           *h   = avctx->priv_data;
+    VASTAPIDecodePicture        *pic = h->cur_pic_ptr->hwaccel_picture_private;
+    const H264SliceContext      *sl  = &h->slice_ctx[0];
+    VASTSliceParameterBufferH264 slice_param;
+    int                          err;
+
+    slice_param = (VASTSliceParameterBufferH264){
+        .slice_data_size               = size,
+        .slice_data_offset             = 0,
+        .slice_data_flag               = VAST_SLICE_DATA_FLAG_ALL,
+        .slice_data_bit_offset         = get_bits_count(&sl->gb),
+        .first_mb_in_slice             = (sl->mb_y >> FIELD_OR_MBAFF_PICTURE(h)) * h->mb_width + sl->mb_x,
+        .slice_type                    = ff_h264_get_slice_type(sl),
+        .direct_spatial_mv_pred_flag   = sl->slice_type == AV_PICTURE_TYPE_B ? sl->direct_spatial_mv_pred : 0,
+        .num_ref_idx_l0_active_minus1  = sl->list_count > 0 ? sl->ref_count[0] - 1 : 0,
+        .num_ref_idx_l1_active_minus1  = sl->list_count > 1 ? sl->ref_count[1] - 1 : 0,
+        .cabac_init_idc                = sl->cabac_init_idc,
+        .slice_qp_delta                = sl->qscale - h->ps.pps->init_qp,
+        .disable_deblocking_filter_idc = sl->deblocking_filter < 2 ? !sl->deblocking_filter : sl->deblocking_filter,
+        .slice_alpha_c0_offset_div2    = sl->slice_alpha_c0_offset / 2,
+        .slice_beta_offset_div2        = sl->slice_beta_offset / 2,
+        .luma_log2_weight_denom        = sl->pwt.luma_log2_weight_denom,
+        .chroma_log2_weight_denom      = sl->pwt.chroma_log2_weight_denom,
+    };
+
+    fill_vastapi_RefPicList(slice_param.RefPicList0, sl->ref_list[0], sl->list_count > 0 ? sl->ref_count[0] : 0);
+    fill_vastapi_RefPicList(slice_param.RefPicList1, sl->ref_list[1], sl->list_count > 1 ? sl->ref_count[1] : 0);
+
+    fill_vastapi_plain_pred_weight_table(h, 0, &slice_param.luma_weight_l0_flag, slice_param.luma_weight_l0,
+                                         slice_param.luma_offset_l0, &slice_param.chroma_weight_l0_flag,
+                                         slice_param.chroma_weight_l0, slice_param.chroma_offset_l0);
+    fill_vastapi_plain_pred_weight_table(h, 1, &slice_param.luma_weight_l1_flag, slice_param.luma_weight_l1,
+                                         slice_param.luma_offset_l1, &slice_param.chroma_weight_l1_flag,
+                                         slice_param.chroma_weight_l1, slice_param.chroma_offset_l1);
+
+    err = ff_vastapi_decode_make_slice_buffer(avctx, pic, &slice_param, sizeof(slice_param), buffer, size);
+    if (err) {
+        ff_vastapi_decode_cancel(avctx, pic);
+        return err;
+    }
+
+    return 0;
+}
+
+const AVHWAccel ff_h264_vastapi_hwaccel = {
+    .name                 = "h264_vastapi",
+    .type                 = AVMEDIA_TYPE_VIDEO,
+    .id                   = AV_CODEC_ID_H264,
+    .pix_fmt              = AV_PIX_FMT_VASTAPI,
+    .start_frame          = &vastapi_h264_start_frame,
+    .end_frame            = &vastapi_h264_end_frame,
+    .decode_slice         = &vastapi_h264_decode_slice,
+    .frame_priv_data_size = sizeof(VASTAPIDecodePicture),
+    .init                 = &ff_vastapi_decode_init,
+    .uninit               = &ff_vastapi_decode_uninit,
+    .frame_params         = &ff_vastapi_common_frame_params,
+    .priv_data_size       = sizeof(VASTAPIDecodeContext),
+    .caps_internal        = HWACCEL_CAP_ASYNC_SAFE,
+};
diff --git a/libavcodec/vastapi_hevc.c b/libavcodec/vastapi_hevc.c
new file mode 100644
index 0000000..47a2005
--- /dev/null
+++ b/libavcodec/vastapi_hevc.c
@@ -0,0 +1,451 @@
+/*
+ * HEVC HW decode acceleration through VAST API
+ *
+ * Copyright (C) 2015 Timo Rothenpieler <timo@rothenpieler.org>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "avcodec.h"
+#include "hevcdec.h"
+#include "hwconfig.h"
+#include "vastapi_decode.h"
+#include "h265_profile_level.h"
+
+typedef struct VASTAPIDecodePictureHEVC {
+    VASTPictureParameterBufferHEVC pic_param;
+    VASTSliceParameterBufferHEVC   last_slice_param;
+    const uint8_t                 *last_buffer;
+    size_t                         last_size;
+
+    VASTAPIDecodePicture pic;
+} VASTAPIDecodePictureHEVC;
+
+static void init_vastapi_pic(VASTPictureHEVC *va_pic)
+{
+    va_pic->picture_id    = VAST_INVALID_ID;
+    va_pic->flags         = VAST_PICTURE_HEVC_INVALID;
+    va_pic->pic_order_cnt = 0;
+}
+
+static void fill_vastapi_pic(VASTPictureHEVC *va_pic, const HEVCFrame *pic, int rps_type)
+{
+    va_pic->picture_id    = ff_vastapi_get_surface_id(pic->frame);
+    va_pic->pic_order_cnt = pic->poc;
+    va_pic->flags         = rps_type;
+
+    if (pic->flags & HEVC_FRAME_FLAG_LONG_REF)
+        va_pic->flags |= VAST_PICTURE_HEVC_LONG_TERM_REFERENCE;
+
+    if (pic->frame->interlaced_frame) {
+        va_pic->flags |= VAST_PICTURE_HEVC_FIELD_PIC;
+
+        if (!pic->frame->top_field_first)
+            va_pic->flags |= VAST_PICTURE_HEVC_BOTTOM_FIELD;
+    }
+}
+
+static int find_frame_rps_type(const HEVCContext *h, const HEVCFrame *pic)
+{
+    VASTSurfaceID pic_surf = ff_vastapi_get_surface_id(pic->frame);
+    int           i;
+
+    for (i = 0; i < h->rps[ST_CURR_BEF].nb_refs; i++) {
+        if (pic_surf == ff_vastapi_get_surface_id(h->rps[ST_CURR_BEF].ref[i]->frame))
+            return VAST_PICTURE_HEVC_RPS_ST_CURR_BEFORE;
+    }
+
+    for (i = 0; i < h->rps[ST_CURR_AFT].nb_refs; i++) {
+        if (pic_surf == ff_vastapi_get_surface_id(h->rps[ST_CURR_AFT].ref[i]->frame))
+            return VAST_PICTURE_HEVC_RPS_ST_CURR_AFTER;
+    }
+
+    for (i = 0; i < h->rps[LT_CURR].nb_refs; i++) {
+        if (pic_surf == ff_vastapi_get_surface_id(h->rps[LT_CURR].ref[i]->frame))
+            return VAST_PICTURE_HEVC_RPS_LT_CURR;
+    }
+
+    return 0;
+}
+
+static void fill_vastapi_reference_frames(const HEVCContext *h, VASTPictureParameterBufferHEVC *pp)
+{
+    const HEVCFrame *current_picture = h->ref;
+    int              i, j, rps_type;
+
+    for (i = 0, j = 0; i < FF_ARRAY_ELEMS(pp->ReferenceFrames); i++) {
+        const HEVCFrame *frame = NULL;
+
+        while (!frame && j < FF_ARRAY_ELEMS(h->DPB)) {
+            if (&h->DPB[j] != current_picture &&
+                (h->DPB[j].flags & (HEVC_FRAME_FLAG_LONG_REF | HEVC_FRAME_FLAG_SHORT_REF)))
+                frame = &h->DPB[j];
+            j++;
+        }
+
+        init_vastapi_pic(&pp->ReferenceFrames[i]);
+
+        if (frame) {
+            rps_type = find_frame_rps_type(h, frame);
+            fill_vastapi_pic(&pp->ReferenceFrames[i], frame, rps_type);
+        }
+    }
+}
+
+static int vastapi_hevc_start_frame(AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)
+{
+    const HEVCContext        *h   = avctx->priv_data;
+    VASTAPIDecodePictureHEVC *pic = h->ref->hwaccel_picture_private;
+    const HEVCSPS            *sps = h->ps.sps;
+    const HEVCPPS            *pps = h->ps.pps;
+
+    const ScalingList *scaling_list = NULL;
+    int                pic_param_size, err, i;
+
+    VASTPictureParameterBufferHEVC *pic_param = (VASTPictureParameterBufferHEVC *)&pic->pic_param;
+
+    pic->pic.output_surface = ff_vastapi_get_surface_id(h->ref->frame);
+
+    *pic_param = (VASTPictureParameterBufferHEVC) {
+        .pic_width_in_luma_samples                    = sps->width,
+        .pic_height_in_luma_samples                   = sps->height,
+        .log2_min_luma_coding_block_size_minus3       = sps->log2_min_cb_size - 3,
+        .sps_max_dec_pic_buffering_minus1             = sps->temporal_layer[sps->max_sub_layers - 1].max_dec_pic_buffering - 1,
+        .log2_diff_max_min_luma_coding_block_size     = sps->log2_diff_max_min_coding_block_size,
+        .log2_min_transform_block_size_minus2         = sps->log2_min_tb_size - 2,
+        .log2_diff_max_min_transform_block_size       = sps->log2_max_trafo_size  - sps->log2_min_tb_size,
+        .max_transform_hierarchy_depth_inter          = sps->max_transform_hierarchy_depth_inter,
+        .max_transform_hierarchy_depth_intra          = sps->max_transform_hierarchy_depth_intra,
+        .num_short_term_ref_pic_sets                  = sps->nb_st_rps,
+        .num_long_term_ref_pic_sps                    = sps->num_long_term_ref_pics_sps,
+        .num_ref_idx_l0_default_active_minus1         = pps->num_ref_idx_l0_default_active - 1,
+        .num_ref_idx_l1_default_active_minus1         = pps->num_ref_idx_l1_default_active - 1,
+        .init_qp_minus26                              = pps->pic_init_qp_minus26,
+        .pps_cb_qp_offset                             = pps->cb_qp_offset,
+        .pps_cr_qp_offset                             = pps->cr_qp_offset,
+        .pcm_sample_bit_depth_luma_minus1             = sps->pcm.bit_depth - 1,
+        .pcm_sample_bit_depth_chroma_minus1           = sps->pcm.bit_depth_chroma - 1,
+        .log2_min_pcm_luma_coding_block_size_minus3   = sps->pcm.log2_min_pcm_cb_size - 3,
+        .log2_diff_max_min_pcm_luma_coding_block_size = sps->pcm.log2_max_pcm_cb_size - sps->pcm.log2_min_pcm_cb_size,
+        .diff_cu_qp_delta_depth                       = pps->diff_cu_qp_delta_depth,
+        .pps_beta_offset_div2                         = pps->beta_offset / 2,
+        .pps_tc_offset_div2                           = pps->tc_offset / 2,
+        .log2_parallel_merge_level_minus2             = pps->log2_parallel_merge_level - 2,
+        .bit_depth_luma_minus8                        = sps->bit_depth - 8,
+        .bit_depth_chroma_minus8                      = sps->bit_depth - 8,
+        .log2_max_pic_order_cnt_lsb_minus4            = sps->log2_max_poc_lsb - 4,
+        .num_extra_slice_header_bits                  = pps->num_extra_slice_header_bits,
+        .pic_fields.bits = {
+            .chroma_format_idc                          = sps->chroma_format_idc,
+            .tiles_enabled_flag                         = pps->tiles_enabled_flag,
+            .separate_colour_plane_flag                 = sps->separate_colour_plane_flag,
+            .pcm_enabled_flag                           = sps->pcm_enabled_flag,
+            .scaling_list_enabled_flag                  = sps->scaling_list_enable_flag,
+            .transform_skip_enabled_flag                = pps->transform_skip_enabled_flag,
+            .amp_enabled_flag                           = sps->amp_enabled_flag,
+            .strong_intra_smoothing_enabled_flag        = sps->sps_strong_intra_smoothing_enable_flag,
+            .sign_data_hiding_enabled_flag              = pps->sign_data_hiding_flag,
+            .constrained_intra_pred_flag                = pps->constrained_intra_pred_flag,
+            .cu_qp_delta_enabled_flag                   = pps->cu_qp_delta_enabled_flag,
+            .weighted_pred_flag                         = pps->weighted_pred_flag,
+            .weighted_bipred_flag                       = pps->weighted_bipred_flag,
+            .transquant_bypass_enabled_flag             = pps->transquant_bypass_enable_flag,
+            .entropy_coding_sync_enabled_flag           = pps->entropy_coding_sync_enabled_flag,
+            .pps_loop_filter_across_slices_enabled_flag = pps->seq_loop_filter_across_slices_enabled_flag,
+            .loop_filter_across_tiles_enabled_flag      = pps->loop_filter_across_tiles_enabled_flag,
+            .pcm_loop_filter_disabled_flag              = sps->pcm.loop_filter_disable_flag,
+        },
+        .slice_parsing_fields.bits = {
+            .lists_modification_present_flag             = pps->lists_modification_present_flag,
+            .long_term_ref_pics_present_flag             = sps->long_term_ref_pics_present_flag,
+            .sps_temporal_mvp_enabled_flag               = sps->sps_temporal_mvp_enabled_flag,
+            .cabac_init_present_flag                     = pps->cabac_init_present_flag,
+            .output_flag_present_flag                    = pps->output_flag_present_flag,
+            .dependent_slice_segments_enabled_flag       = pps->dependent_slice_segments_enabled_flag,
+            .pps_slice_chroma_qp_offsets_present_flag    = pps->pic_slice_level_chroma_qp_offsets_present_flag,
+            .sample_adaptive_offset_enabled_flag         = sps->sao_enabled,
+            .deblocking_filter_override_enabled_flag     = pps->deblocking_filter_override_enabled_flag,
+            .pps_disable_deblocking_filter_flag          = pps->disable_dbf,
+            .slice_segment_header_extension_present_flag = pps->slice_header_extension_present_flag,
+            .RapPicFlag                                  = IS_IRAP(h),
+            .IdrPicFlag                                  = IS_IDR(h),
+            .IntraPicFlag                                = IS_IRAP(h),
+        },
+    };
+
+    // debug denglingling
+    int refidx;
+    for (refidx = 0; refidx < HEVC_MAX_LONG_TERM_REF_PICS; refidx++) {
+        pic_param->lt_ref_pic_poc_lsb_sps[refidx]       = sps->lt_ref_pic_poc_lsb_sps[refidx];
+        pic_param->used_by_curr_pic_lt_sps_flag[refidx] = sps->used_by_curr_pic_lt_sps_flag[refidx];
+    }
+
+    fill_vastapi_pic(&pic_param->CurrPic, h->ref, 0);
+    fill_vastapi_reference_frames(h, pic_param);
+
+    if (pps->tiles_enabled_flag) {
+        pic_param->num_tile_columns_minus1 = pps->num_tile_columns - 1;
+        pic_param->num_tile_rows_minus1    = pps->num_tile_rows - 1;
+
+        for (i = 0; i < pps->num_tile_columns; i++)
+            pic_param->column_width_minus1[i] = pps->column_width[i] - 1;
+
+        for (i = 0; i < pps->num_tile_rows; i++)
+            pic_param->row_height_minus1[i] = pps->row_height[i] - 1;
+    }
+
+    if (h->sh.short_term_ref_pic_set_sps_flag == 0 && h->sh.short_term_rps) {
+        pic_param->st_rps_bits = h->sh.short_term_ref_pic_set_size;
+    } else {
+        pic_param->st_rps_bits = 0;
+    }
+
+    pic_param_size =
+        avctx->profile == FF_PROFILE_HEVC_REXT ? sizeof(pic->pic_param) : sizeof(VASTPictureParameterBufferHEVC);
+
+    err = ff_vastapi_decode_make_param_buffer(avctx, &pic->pic, VASTPictureParameterBufferType, &pic->pic_param,
+                                              pic_param_size);
+    if (err < 0)
+        goto fail;
+
+    if (pps->scaling_list_data_present_flag)
+        scaling_list = &pps->scaling_list;
+    else if (sps->scaling_list_enable_flag)
+        scaling_list = &sps->scaling_list;
+
+    if (scaling_list) {
+        VASTIQMatrixBufferHEVC iq_matrix;
+        int                    j;
+
+        for (i = 0; i < 6; i++) {
+            for (j = 0; j < 16; j++)
+                iq_matrix.ScalingList4x4[i][j] = scaling_list->sl[0][i][j];
+            for (j = 0; j < 64; j++) {
+                iq_matrix.ScalingList8x8[i][j]   = scaling_list->sl[1][i][j];
+                iq_matrix.ScalingList16x16[i][j] = scaling_list->sl[2][i][j];
+                if (i < 2)
+                    iq_matrix.ScalingList32x32[i][j] = scaling_list->sl[3][i * 3][j];
+            }
+            iq_matrix.ScalingListDC16x16[i] = scaling_list->sl_dc[0][i];
+            if (i < 2)
+                iq_matrix.ScalingListDC32x32[i] = scaling_list->sl_dc[1][i * 3];
+        }
+
+        err = ff_vastapi_decode_make_param_buffer(avctx, &pic->pic, VASTIQMatrixBufferType, &iq_matrix,
+                                                  sizeof(iq_matrix));
+        if (err < 0)
+            goto fail;
+    }
+
+    err = ff_vastapi_decode_start_frame(avctx, h->ref->frame);
+    if (err < 0)
+        goto fail;
+
+    return 0;
+
+fail:
+    ff_vastapi_decode_cancel(avctx, &pic->pic);
+    return err;
+}
+
+static int vastapi_hevc_end_frame(AVCodecContext *avctx)
+{
+    const HEVCContext            *h                = avctx->priv_data;
+    VASTAPIDecodePictureHEVC     *pic              = h->ref->hwaccel_picture_private;
+    VASTSliceParameterBufferHEVC *last_slice_param = (VASTSliceParameterBufferHEVC *)&pic->last_slice_param;
+    int                           ret;
+
+    int slice_param_size =
+        avctx->profile == FF_PROFILE_HEVC_REXT ? sizeof(pic->last_slice_param) : sizeof(VASTSliceParameterBufferHEVC);
+
+    if (pic->last_size) {
+        last_slice_param->LongSliceFlags.fields.LastSliceOfPic = 1;
+        ret = ff_vastapi_decode_make_slice_buffer(avctx, &pic->pic, &pic->last_slice_param, slice_param_size,
+                                                  pic->last_buffer, pic->last_size);
+        if (ret < 0)
+            goto fail;
+    }
+
+    ret = ff_vastapi_decode_issue(avctx, &pic->pic);
+    if (ret < 0)
+        goto fail;
+
+    return 0;
+fail:
+    ff_vastapi_decode_cancel(avctx, &pic->pic);
+    return ret;
+}
+
+static void fill_pred_weight_table(const HEVCContext *h, const SliceHeader *sh,
+                                   VASTSliceParameterBufferHEVC *slice_param)
+{
+    int i;
+
+    memset(slice_param->delta_luma_weight_l0, 0, sizeof(slice_param->delta_luma_weight_l0));
+    memset(slice_param->delta_luma_weight_l1, 0, sizeof(slice_param->delta_luma_weight_l1));
+    memset(slice_param->luma_offset_l0, 0, sizeof(slice_param->luma_offset_l0));
+    memset(slice_param->luma_offset_l1, 0, sizeof(slice_param->luma_offset_l1));
+    memset(slice_param->delta_chroma_weight_l0, 0, sizeof(slice_param->delta_chroma_weight_l0));
+    memset(slice_param->delta_chroma_weight_l1, 0, sizeof(slice_param->delta_chroma_weight_l1));
+    memset(slice_param->ChromaOffsetL0, 0, sizeof(slice_param->ChromaOffsetL0));
+    memset(slice_param->ChromaOffsetL1, 0, sizeof(slice_param->ChromaOffsetL1));
+
+    slice_param->delta_chroma_log2_weight_denom = 0;
+    slice_param->luma_log2_weight_denom         = 0;
+
+    if (sh->slice_type == HEVC_SLICE_I || (sh->slice_type == HEVC_SLICE_P && !h->ps.pps->weighted_pred_flag) ||
+        (sh->slice_type == HEVC_SLICE_B && !h->ps.pps->weighted_bipred_flag))
+        return;
+
+    slice_param->luma_log2_weight_denom = sh->luma_log2_weight_denom;
+
+    if (h->ps.sps->chroma_format_idc) {
+        slice_param->delta_chroma_log2_weight_denom = sh->chroma_log2_weight_denom - sh->luma_log2_weight_denom;
+    }
+
+    for (i = 0; i < 15 && i < sh->nb_refs[L0]; i++) {
+        slice_param->delta_luma_weight_l0[i]      = sh->luma_weight_l0[i] - (1 << sh->luma_log2_weight_denom);
+        slice_param->luma_offset_l0[i]            = sh->luma_offset_l0[i];
+        slice_param->delta_chroma_weight_l0[i][0] = sh->chroma_weight_l0[i][0] - (1 << sh->chroma_log2_weight_denom);
+        slice_param->delta_chroma_weight_l0[i][1] = sh->chroma_weight_l0[i][1] - (1 << sh->chroma_log2_weight_denom);
+        slice_param->ChromaOffsetL0[i][0]         = sh->chroma_offset_l0[i][0];
+        slice_param->ChromaOffsetL0[i][1]         = sh->chroma_offset_l0[i][1];
+    }
+
+    if (sh->slice_type == HEVC_SLICE_B) {
+        for (i = 0; i < 15 && i < sh->nb_refs[L1]; i++) {
+            slice_param->delta_luma_weight_l1[i] = sh->luma_weight_l1[i] - (1 << sh->luma_log2_weight_denom);
+            slice_param->luma_offset_l1[i]       = sh->luma_offset_l1[i];
+            slice_param->delta_chroma_weight_l1[i][0] =
+                sh->chroma_weight_l1[i][0] - (1 << sh->chroma_log2_weight_denom);
+            slice_param->delta_chroma_weight_l1[i][1] =
+                sh->chroma_weight_l1[i][1] - (1 << sh->chroma_log2_weight_denom);
+            slice_param->ChromaOffsetL1[i][0] = sh->chroma_offset_l1[i][0];
+            slice_param->ChromaOffsetL1[i][1] = sh->chroma_offset_l1[i][1];
+        }
+    }
+}
+
+static uint8_t get_ref_pic_index(const HEVCContext *h, const HEVCFrame *frame)
+{
+    VASTAPIDecodePictureHEVC       *pic = h->ref->hwaccel_picture_private;
+    VASTPictureParameterBufferHEVC *pp  = (VASTPictureParameterBufferHEVC *)&pic->pic_param;
+    uint8_t                         i;
+
+    if (!frame)
+        return 0xff;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(pp->ReferenceFrames); i++) {
+        VASTSurfaceID pid = pp->ReferenceFrames[i].picture_id;
+        int           poc = pp->ReferenceFrames[i].pic_order_cnt;
+        if (pid != VAST_INVALID_ID && pid == ff_vastapi_get_surface_id(frame->frame) && poc == frame->poc)
+            return i;
+    }
+
+    return 0xff;
+}
+
+static int vastapi_hevc_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
+{
+    const HEVCContext            *h                = avctx->priv_data;
+    const SliceHeader            *sh               = &h->sh;
+    VASTAPIDecodePictureHEVC     *pic              = h->ref->hwaccel_picture_private;
+    VASTSliceParameterBufferHEVC *last_slice_param = (VASTSliceParameterBufferHEVC *)&pic->last_slice_param;
+
+    int slice_param_size =
+        avctx->profile == FF_PROFILE_HEVC_REXT ? sizeof(pic->last_slice_param) : sizeof(VASTSliceParameterBufferHEVC);
+
+    int nb_list = (sh->slice_type == HEVC_SLICE_B) ? 2 : (sh->slice_type == HEVC_SLICE_I ? 0 : 1);
+
+    int err, i, list_idx;
+
+    if (!sh->first_slice_in_pic_flag) {
+        err = ff_vastapi_decode_make_slice_buffer(avctx, &pic->pic, &pic->last_slice_param, slice_param_size,
+                                                  pic->last_buffer, pic->last_size);
+        pic->last_buffer = NULL;
+        pic->last_size   = 0;
+        if (err) {
+            ff_vastapi_decode_cancel(avctx, &pic->pic);
+            return err;
+        }
+    }
+
+    *last_slice_param = (VASTSliceParameterBufferHEVC) {
+        .slice_data_size               = size,
+        .slice_data_offset             = 0,
+        .slice_data_flag               = VAST_SLICE_DATA_FLAG_ALL,
+        /* Add 1 to the bits count here to account for the byte_alignment bit, which
+         * always is at least one bit and not accounted for otherwise. */
+        .slice_data_byte_offset        = (get_bits_count(&h->HEVClc->gb) + 1 + 7) / 8,
+        .slice_segment_address         = sh->slice_segment_addr,
+        .slice_qp_delta                = sh->slice_qp_delta,
+        .slice_cb_qp_offset            = sh->slice_cb_qp_offset,
+        .slice_cr_qp_offset            = sh->slice_cr_qp_offset,
+        .slice_beta_offset_div2        = sh->beta_offset / 2,
+        .slice_tc_offset_div2          = sh->tc_offset / 2,
+        .collocated_ref_idx            = sh->slice_temporal_mvp_enabled_flag ? sh->collocated_ref_idx : 0xFF,
+        .five_minus_max_num_merge_cand = sh->slice_type == HEVC_SLICE_I ? 0 : 5 - sh->max_num_merge_cand,
+        .num_ref_idx_l0_active_minus1  = sh->nb_refs[L0] ? sh->nb_refs[L0] - 1 : 0,
+        .num_ref_idx_l1_active_minus1  = sh->nb_refs[L1] ? sh->nb_refs[L1] - 1 : 0,
+
+        .LongSliceFlags.fields = {
+            .dependent_slice_segment_flag                 = sh->dependent_slice_segment_flag,
+            .slice_type                                   = sh->slice_type,
+            .color_plane_id                               = sh->colour_plane_id,
+            .mvd_l1_zero_flag                             = sh->mvd_l1_zero_flag,
+            .cabac_init_flag                              = sh->cabac_init_flag,
+            .slice_temporal_mvp_enabled_flag              = sh->slice_temporal_mvp_enabled_flag,
+            .slice_deblocking_filter_disabled_flag        = sh->disable_deblocking_filter_flag,
+            .collocated_from_l0_flag                      = sh->collocated_list == L0 ? 1 : 0,
+            .slice_loop_filter_across_slices_enabled_flag = sh->slice_loop_filter_across_slices_enabled_flag,
+            .slice_sao_luma_flag                          = sh->slice_sample_adaptive_offset_flag[0],
+            .slice_sao_chroma_flag                        = sh->slice_sample_adaptive_offset_flag[1],
+        },
+    };
+
+    memset(last_slice_param->RefPicList, 0xFF, sizeof(last_slice_param->RefPicList));
+
+    for (list_idx = 0; list_idx < nb_list; list_idx++) {
+        RefPicList *rpl = &h->ref->refPicList[list_idx];
+
+        for (i = 0; i < rpl->nb_refs; i++)
+            last_slice_param->RefPicList[list_idx][i] = get_ref_pic_index(h, rpl->ref[i]);
+    }
+
+    fill_pred_weight_table(h, sh, last_slice_param);
+
+    pic->last_buffer = buffer;
+    pic->last_size   = size;
+
+    return 0;
+}
+
+const AVHWAccel ff_hevc_vastapi_hwaccel = {
+    .name                 = "hevc_vastapi",
+    .type                 = AVMEDIA_TYPE_VIDEO,
+    .id                   = AV_CODEC_ID_HEVC,
+    .pix_fmt              = AV_PIX_FMT_VASTAPI,
+    .start_frame          = vastapi_hevc_start_frame,
+    .end_frame            = vastapi_hevc_end_frame,
+    .decode_slice         = vastapi_hevc_decode_slice,
+    .frame_priv_data_size = sizeof(VASTAPIDecodePictureHEVC),
+    .init                 = ff_vastapi_decode_init,
+    .uninit               = ff_vastapi_decode_uninit,
+    .frame_params         = ff_vastapi_common_frame_params,
+    .priv_data_size       = sizeof(VASTAPIDecodeContext),
+    .caps_internal        = HWACCEL_CAP_ASYNC_SAFE,
+};
diff --git a/libavcodec/vastapi_mjpeg.c b/libavcodec/vastapi_mjpeg.c
new file mode 100644
index 0000000..dc87c93
--- /dev/null
+++ b/libavcodec/vastapi_mjpeg.c
@@ -0,0 +1,150 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "hwconfig.h"
+#include "vastapi_decode.h"
+#include "mjpegdec.h"
+
+static int vastapi_mjpeg_start_frame(AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)
+{
+    const MJpegDecodeContext              *s   = avctx->priv_data;
+    VASTAPIDecodePicture                  *pic = s->hwaccel_picture_private;
+    VASTPictureParameterBufferJPEGBaseline pp;
+    int                                    err, i;
+
+    pic->output_surface = ff_vastapi_get_surface_id(s->picture_ptr);
+
+    pp = (VASTPictureParameterBufferJPEGBaseline){
+        .picture_width  = avctx->width,
+        .picture_height = avctx->height,
+
+        .num_components = s->nb_components,
+    };
+
+    for (i = 0; i < s->nb_components; i++) {
+        pp.components[i].component_id             = s->component_id[i];
+        pp.components[i].h_sampling_factor        = s->h_count[i];
+        pp.components[i].v_sampling_factor        = s->v_count[i];
+        pp.components[i].quantiser_table_selector = s->quant_index[i];
+    }
+
+    err = ff_vastapi_decode_make_param_buffer(avctx, pic, VASTPictureParameterBufferType, &pp, sizeof(pp));
+    if (err < 0)
+        goto fail;
+
+    err = ff_vastapi_decode_start_frame(avctx, s->picture_ptr);
+    if (err < 0)
+        goto fail;
+
+    return 0;
+
+fail:
+    ff_vastapi_decode_cancel(avctx, pic);
+    return err;
+}
+
+static int vastapi_mjpeg_end_frame(AVCodecContext *avctx)
+{
+    const MJpegDecodeContext *s   = avctx->priv_data;
+    VASTAPIDecodePicture     *pic = s->hwaccel_picture_private;
+
+    return ff_vastapi_decode_issue(avctx, pic);
+}
+
+static int vastapi_mjpeg_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)
+{
+    const MJpegDecodeContext            *s   = avctx->priv_data;
+    VASTAPIDecodePicture                *pic = s->hwaccel_picture_private;
+    VASTHuffmanTableBufferJPEGBaseline   huff;
+    VASTIQMatrixBufferJPEGBaseline       quant;
+    VASTSliceParameterBufferJPEGBaseline sp;
+    int                                  err, i, j;
+
+    memset(&huff, 0, sizeof(huff));
+    for (i = 0; i < 2; i++) {
+        huff.load_huffman_table[i] = 1;
+        for (j = 0; j < 16; j++)
+            huff.huffman_table[i].num_dc_codes[j] = s->raw_huffman_lengths[0][i][j];
+        for (j = 0; j < 12; j++)
+            huff.huffman_table[i].dc_values[j] = s->raw_huffman_values[0][i][j];
+        for (j = 0; j < 16; j++)
+            huff.huffman_table[i].num_ac_codes[j] = s->raw_huffman_lengths[1][i][j];
+        for (j = 0; j < 162; j++)
+            huff.huffman_table[i].ac_values[j] = s->raw_huffman_values[1][i][j];
+    }
+
+    err = ff_vastapi_decode_make_param_buffer(avctx, pic, VASTHuffmanTableBufferType, &huff, sizeof(huff));
+    if (err < 0)
+        goto fail;
+
+    memset(&quant, 0, sizeof(quant));
+    for (i = 0; i < 4; i++) {
+        quant.load_quantiser_table[i] = 1;
+        for (j = 0; j < 64; j++)
+            quant.quantiser_table[i][j] = s->quant_matrixes[i][j];
+    }
+
+    err = ff_vastapi_decode_make_param_buffer(avctx, pic, VASTIQMatrixBufferType, &quant, sizeof(quant));
+    if (err < 0)
+        goto fail;
+
+    sp = (VASTSliceParameterBufferJPEGBaseline){
+        .slice_data_size   = size,
+        .slice_data_offset = 0,
+        .slice_data_flag   = VAST_SLICE_DATA_FLAG_ALL,
+
+        .slice_horizontal_position = 0,
+        .slice_vertical_position   = 0,
+
+        .restart_interval = s->restart_interval,
+        .num_mcus         = s->mb_width * s->mb_height,
+    };
+
+    sp.num_components = s->nb_components;
+    for (i = 0; i < s->nb_components; i++) {
+        sp.components[i].component_selector = s->component_id[s->comp_index[i]];
+        sp.components[i].dc_table_selector  = s->dc_index[i];
+        sp.components[i].ac_table_selector  = s->ac_index[i];
+    }
+
+    err = ff_vastapi_decode_make_slice_buffer(avctx, pic, &sp, sizeof(sp), buffer, size);
+    if (err)
+        goto fail;
+
+    return 0;
+
+fail:
+    ff_vastapi_decode_cancel(avctx, pic);
+    return err;
+}
+
+const AVHWAccel ff_mjpeg_vastapi_hwaccel = {
+    .name                 = "mjpeg_vastapi",
+    .type                 = AVMEDIA_TYPE_VIDEO,
+    .id                   = AV_CODEC_ID_MJPEG,
+    .pix_fmt              = AV_PIX_FMT_VASTAPI,
+    .start_frame          = &vastapi_mjpeg_start_frame,
+    .end_frame            = &vastapi_mjpeg_end_frame,
+    .decode_slice         = &vastapi_mjpeg_decode_slice,
+    .frame_priv_data_size = sizeof(VASTAPIDecodePicture),
+    .init                 = &ff_vastapi_decode_init,
+    .uninit               = &ff_vastapi_decode_uninit,
+    .frame_params         = &ff_vastapi_common_frame_params,
+    .priv_data_size       = sizeof(VASTAPIDecodeContext),
+    .caps_internal        = HWACCEL_CAP_ASYNC_SAFE,
+};
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index 01c0338..c29b424 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -175,6 +175,7 @@ OBJS-$(CONFIG_SINE_FILTER)                   += asrc_sine.o
 OBJS-$(CONFIG_ANULLSINK_FILTER)              += asink_anullsink.o
 
 # video filters
+OBJS-$(CONFIG_MISC_VASTAPI_FILTER)           += vf_misc_vastapi.o vastapi_vpp.o
 OBJS-$(CONFIG_ADDROI_FILTER)                 += vf_addroi.o
 OBJS-$(CONFIG_ALPHAEXTRACT_FILTER)           += vf_extractplanes.o
 OBJS-$(CONFIG_ALPHAMERGE_FILTER)             += vf_alphamerge.o framesync.o
@@ -420,6 +421,7 @@ OBJS-$(CONFIG_SCALE_CUDA_FILTER)             += vf_scale_cuda.o scale_eval.o \
 OBJS-$(CONFIG_SCALE_NPP_FILTER)              += vf_scale_npp.o scale_eval.o
 OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_scale_qsv.o
 OBJS-$(CONFIG_SCALE_VAAPI_FILTER)            += vf_scale_vaapi.o scale_eval.o vaapi_vpp.o
+OBJS-$(CONFIG_MISC_VASTAPI_FILTER)           += vf_misc_vastapi.o vastapi_vpp.o
 OBJS-$(CONFIG_SCALE_VULKAN_FILTER)           += vf_scale_vulkan.o vulkan.o vulkan_filter.o
 OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale_eval.o
 OBJS-$(CONFIG_SCALE2REF_NPP_FILTER)          += vf_scale_npp.o scale_eval.o
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index caa7553..0e41464 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -402,6 +402,7 @@ extern const AVFilter ff_vf_scale_cuda;
 extern const AVFilter ff_vf_scale_npp;
 extern const AVFilter ff_vf_scale_qsv;
 extern const AVFilter ff_vf_scale_vaapi;
+extern const AVFilter ff_vf_misc_vastapi;
 extern const AVFilter ff_vf_scale_vulkan;
 extern const AVFilter ff_vf_scale2ref;
 extern const AVFilter ff_vf_scale2ref_npp;
diff --git a/libavfilter/avfilter.c b/libavfilter/avfilter.c
index 7362bcd..453c38a 100644
--- a/libavfilter/avfilter.c
+++ b/libavfilter/avfilter.c
@@ -947,10 +947,28 @@ int avfilter_init_str(AVFilterContext *filter, const char *args)
                    "options, but options were provided: %s.\n", args);
             return AVERROR(EINVAL);
         }
+#ifdef CONFIG_VASTAPI
+        if (   !strcmp(filter->filter->name, "misc_vastapi") ){
+            char * opt = "filter_opts";
+            char * arg = av_strdup(args);
+            args = NULL;
+            av_dict_set(&options,opt, arg, 0);
+            av_free(arg);
+            ret = av_opt_set_dict(filter->priv, &options);
+            if(ret < 0){
+                goto fail;
+            }
+        }else{
+            ret = process_options(filter, &options, args);
+            if (ret < 0)
+                goto fail;            
+        }
+#else
 
         ret = process_options(filter, &options, args);
         if (ret < 0)
             goto fail;
+#endif            
     }
 
     ret = avfilter_init_dict(filter, &options);
@@ -1220,6 +1238,13 @@ static int ff_filter_activate_default(AVFilterContext *filter)
     }
     return FFERROR_NOT_READY;
 }
+#ifdef CONFIG_VASTAPI
+int ff_filter_activate_default_extern(AVFilterContext *filter)
+{
+    return ff_filter_activate_default(filter);
+}
+#endif
+
 
 /*
    Filter scheduling and activation
diff --git a/libavfilter/avfilter.h b/libavfilter/avfilter.h
index b105dc3..3d287d5 100644
--- a/libavfilter/avfilter.h
+++ b/libavfilter/avfilter.h
@@ -1179,6 +1179,9 @@ char *avfilter_graph_dump(AVFilterGraph *graph, const char *options);
  */
 int avfilter_graph_request_oldest(AVFilterGraph *graph);
 
+#ifdef CONFIG_VASTAPI
+int ff_filter_activate_default_extern(AVFilterContext *filter);
+#endif
 /**
  * @}
  */
diff --git a/libavfilter/vastapi_vpp.c b/libavfilter/vastapi_vpp.c
new file mode 100644
index 0000000..280affd
--- /dev/null
+++ b/libavfilter/vastapi_vpp.c
@@ -0,0 +1,287 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <string.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/pixdesc.h"
+#include "formats.h"
+#include "internal.h"
+#include "vastapi_vpp.h"
+#include "version.h"
+
+#define FF_N441 AV_VERSION_INT(7, 110, 100)
+
+#define FF_GE(NXXX) (LIBAVFILTER_BUILD >= FF_##NXXX)
+
+int ff_vastapi_vpp_query_formats(AVFilterContext *avctx)
+{
+    enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_VASTAPI,
+        AV_PIX_FMT_NONE,
+    };
+
+    int err;
+
+#if FF_GE(N441)
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->inputs[0]->outcfg.formats);
+#else
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->inputs[0]->out_formats);
+#endif
+    if (err < 0)
+        return err;
+
+#if FF_GE(N441)
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->outputs[0]->incfg.formats);
+#else
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->outputs[0]->in_formats);
+#endif
+    if (err < 0)
+        return err;
+
+    return 0;
+}
+
+void ff_vastapi_vpp_pipeline_uninit(AVFilterContext *avctx)
+{
+    VASTAPIVPPContext *ctx  = avctx->priv;
+    VastapiFunctions  *func = NULL;
+    int                i;
+    if (ctx->vastfilter_params.hwctx) {
+        func = (VastapiFunctions *)(ctx->vastfilter_params.hwctx->vst_func);
+        func->vastapiFilterPipelineUnint(&ctx->vastfilter_params, ctx->nb_filter_buffers);
+        ctx->nb_filter_buffers = 0;
+    }
+
+    av_buffer_unref(&ctx->device_ref);
+    ctx->hwctx = NULL;
+}
+
+int ff_vastapi_vpp_config_input(AVFilterLink *inlink)
+{
+    AVFilterContext   *avctx = inlink->dst;
+    VASTAPIVPPContext *ctx   = avctx->priv;
+
+    if (ctx->pipeline_uninit)
+        ctx->pipeline_uninit(avctx);
+
+    if (!inlink->hw_frames_ctx) {
+        av_log(avctx, AV_LOG_ERROR,
+               "A hardware frames reference is "
+               "required to associate the processing device.\n");
+        return AVERROR(EINVAL);
+    }
+
+    ctx->input_frames_ref = av_buffer_ref(inlink->hw_frames_ctx);
+    if (!ctx->input_frames_ref) {
+        av_log(avctx, AV_LOG_ERROR,
+               "A input frames reference create "
+               "failed.\n");
+        return AVERROR(ENOMEM);
+    }
+    ctx->input_frames = (AVHWFramesContext *)ctx->input_frames_ref->data;
+
+    return 0;
+}
+
+int ff_vastapi_vpp_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext        *avctx       = outlink->src;
+    VASTAPIVPPContext      *ctx         = avctx->priv;
+    AVVASTAPIHWConfig      *hwconfig    = NULL;
+    AVHWFramesConstraints  *constraints = NULL;
+    VastapiFunctions       *func        = NULL;
+    AVHWFramesContext      *output_frames;
+    AVVASTAPIFramesContext *va_frames;
+    int                     vas;
+    int                     err, i;
+
+    if (ctx->pipeline_uninit)
+        ctx->pipeline_uninit(avctx);
+
+    if (!ctx->output_width)
+        ctx->output_width = avctx->inputs[0]->w & ~0x1;
+    if (!ctx->output_height)
+        ctx->output_height = avctx->inputs[0]->h & ~0x1;
+
+    av_assert0(ctx->input_frames);
+    ctx->device_ref = av_buffer_ref(ctx->input_frames->device_ref);
+    if (!ctx->device_ref) {
+        av_log(avctx, AV_LOG_ERROR,
+               "A device reference create "
+               "failed.\n");
+        return AVERROR(ENOMEM);
+    }
+    ctx->vastfilter_params.hwctx = ((AVHWDeviceContext *)ctx->device_ref->data)->hwctx;
+    func                         = (VastapiFunctions *)ctx->vastfilter_params.hwctx->vst_func;
+
+    av_assert0(ctx->vastfilter_params.va_config == VAST_INVALID_ID);
+    vas = func->vastapiFilterConfigCreate(&ctx->vastfilter_params);
+    if (0 != vas) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to create processing pipeline "
+               "config: %d.\n",
+               vas);
+        err = AVERROR(EIO);
+        goto fail;
+    }
+
+    hwconfig = av_hwdevice_hwconfig_alloc(ctx->device_ref);
+    if (!hwconfig) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    hwconfig->config_id = ctx->vastfilter_params.va_config;
+
+    constraints = av_hwdevice_get_hwframe_constraints(ctx->device_ref, hwconfig);
+    if (!constraints) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    if (ctx->output_format == AV_PIX_FMT_NONE)
+        ctx->output_format = ctx->input_frames->sw_format;
+    if (constraints->valid_sw_formats) {
+        for (i = 0; constraints->valid_sw_formats[i] != AV_PIX_FMT_NONE; i++) {
+            if (ctx->output_format == constraints->valid_sw_formats[i])
+                break;
+        }
+        if (constraints->valid_sw_formats[i] == AV_PIX_FMT_NONE) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Hardware does not support output "
+                   "format %s.\n",
+                   av_get_pix_fmt_name(ctx->output_format));
+            err = AVERROR(EINVAL);
+            goto fail;
+        }
+    }
+
+    if (ctx->output_width < constraints->min_width || ctx->output_height < constraints->min_height ||
+        ctx->output_width > constraints->max_width || ctx->output_height > constraints->max_height) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Hardware does not support scaling to "
+               "size %dx%d (constraints: width %d-%d height %d-%d).\n",
+               ctx->output_width, ctx->output_height, constraints->min_width, constraints->max_width,
+               constraints->min_height, constraints->max_height);
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+
+    outlink->hw_frames_ctx = av_hwframe_ctx_alloc(ctx->device_ref);
+    if (!outlink->hw_frames_ctx) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to create HW frame context "
+               "for output.\n");
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    output_frames = (AVHWFramesContext *)outlink->hw_frames_ctx->data;
+
+    output_frames->format    = AV_PIX_FMT_VASTAPI;
+    output_frames->sw_format = ctx->output_format;
+    output_frames->width     = ctx->output_width;
+    output_frames->height    = ctx->output_height;
+
+    output_frames->initial_pool_size = 1;
+
+    err = ff_filter_init_hw_frames(avctx, outlink, 1);
+    if (err < 0)
+        goto fail;
+
+    err = av_hwframe_ctx_init(outlink->hw_frames_ctx);
+    if (err < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to initialise VAAPI frame "
+               "context for output: %d\n",
+               err);
+        goto fail;
+    }
+
+    va_frames = output_frames->hwctx;
+
+    av_assert0(ctx->vastfilter_params.va_context == VAST_INVALID_ID);
+    vas = func->vastapiFilterContextCreate(&ctx->vastfilter_params, ctx->output_width, ctx->output_height, va_frames);
+    if (0 != vas) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to create processing pipeline "
+               "context: %d.\n",
+               vas);
+        return AVERROR(EIO);
+    }
+
+    outlink->w = ctx->output_width;
+    outlink->h = ctx->output_height;
+
+    if (ctx->build_filter_params) {
+        err = ctx->build_filter_params(avctx);
+        if (err < 0)
+            goto fail;
+    }
+
+    av_freep(&hwconfig);
+    av_hwframe_constraints_free(&constraints);
+    return 0;
+
+fail:
+    av_buffer_unref(&outlink->hw_frames_ctx);
+    av_freep(&hwconfig);
+    av_hwframe_constraints_free(&constraints);
+    return err;
+}
+
+int ff_vastapi_vpp_render_picture(AVFilterContext *avctx, VASTFilterParamer *vastfilter_params, AVFrame *output_frame)
+{
+    VASTAPIVPPContext *ctx  = avctx->priv;
+    VastapiFunctions  *func = (VastapiFunctions *)vastfilter_params->hwctx->vst_func;
+    VASTStatus         vas;
+    int                err;
+    vastfilter_params->va_surface = (VASTSurfaceID)(uintptr_t)output_frame->data[3];
+    vas                           = func->vastapiFilterRenderPicture(vastfilter_params);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to attach new picture: %d.\n", vas);
+        err = AVERROR(EIO);
+        return err;
+    }
+    return 0;
+}
+
+void ff_vastapi_vpp_ctx_init(AVFilterContext *avctx)
+{
+    int                i;
+    VASTAPIVPPContext *ctx = avctx->priv;
+
+    ctx->vastfilter_params.va_config  = VAST_INVALID_ID;
+    ctx->vastfilter_params.va_context = VAST_INVALID_ID;
+    ctx->valid_ids                    = 1;
+    ctx->vastfilter_params.hwctx      = NULL;
+
+    for (i = 0; i < VASTProcFilterCount; i++)
+        ctx->vastfilter_params.filter_buffers[i] = VAST_INVALID_ID;
+    ctx->nb_filter_buffers = 0;
+}
+
+void ff_vastapi_vpp_ctx_uninit(AVFilterContext *avctx)
+{
+    VASTAPIVPPContext *ctx = avctx->priv;
+    if (ctx->valid_ids && ctx->pipeline_uninit)
+        ctx->pipeline_uninit(avctx);
+
+    av_buffer_unref(&ctx->input_frames_ref);
+    av_buffer_unref(&ctx->device_ref);
+}
diff --git a/libavfilter/vastapi_vpp.h b/libavfilter/vastapi_vpp.h
new file mode 100644
index 0000000..b5b6cb3
--- /dev/null
+++ b/libavfilter/vastapi_vpp.h
@@ -0,0 +1,62 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVFILTER_VASTAPI_VPP_H
+#define AVFILTER_VASTAPI_VPP_H
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_vastapi.h"
+
+#include "avfilter.h"
+#include "vastva/vastapi.h"
+#include "vastva/vastapi_dynlink_loader.h"
+// ARGB black, for VAProcPipelineParameterBuffer.output_background_color.
+#define VASTAPI_VPP_BACKGROUND_BLACK 0xff000000
+
+typedef struct VASTAPIVPPContext {
+    const AVClass *class;
+
+    AVVASTAPIDeviceContext *hwctx;
+    AVBufferRef            *device_ref;
+    int                     valid_ids;
+    AVBufferRef            *input_frames_ref;
+    AVHWFramesContext      *input_frames;
+    enum AVPixelFormat      output_format;
+    int                     output_width;  // computed width
+    int                     output_height; // computed height
+    int                     nb_filter_buffers;
+    VASTFilterParamer       vastfilter_params;
+
+    int (*build_filter_params)(AVFilterContext *avctx);
+    void (*pipeline_uninit)(AVFilterContext *avctx);
+} VASTAPIVPPContext;
+
+void ff_vastapi_vpp_ctx_init(AVFilterContext *avctx);
+
+void ff_vastapi_vpp_ctx_uninit(AVFilterContext *avctx);
+
+int ff_vastapi_vpp_query_formats(AVFilterContext *avctx);
+
+void ff_vastapi_vpp_pipeline_uninit(AVFilterContext *avctx);
+
+int ff_vastapi_vpp_config_input(AVFilterLink *inlink);
+
+int ff_vastapi_vpp_config_output(AVFilterLink *outlink);
+
+int ff_vastapi_vpp_render_picture(AVFilterContext *avctx, VASTFilterParamer *vastfilter_params, AVFrame *output_frame);
+
+#endif /* AVFILTER_VASTAPI_VPP_H */
diff --git a/libavfilter/vf_misc_vastapi.c b/libavfilter/vf_misc_vastapi.c
new file mode 100644
index 0000000..9e6d7ae
--- /dev/null
+++ b/libavfilter/vf_misc_vastapi.c
@@ -0,0 +1,839 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+#include <string.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/avstring.h"
+#include "libavfilter/filters.h"
+#include "libavutil/eval.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "vastapi_vpp.h"
+#include "framesync.h"
+#include "filters.h"
+
+#include "version.h"
+
+#define FF_N441 AV_VERSION_INT(7, 110, 100)
+#define FF_N500 AV_VERSION_INT(8, 24, 100)
+
+#define FF_GE(NXXX) (LIBAVFILTER_BUILD >= FF_##NXXX)
+
+// Denoise min/max/default Values
+#define DENOISE_MIN 0
+#define DENOISE_MAX 64
+#define DENOISE_DEFAULT 0
+
+// Sharpness min/max/default values
+#define SHARPNESS_MIN 0
+#define SHARPNESS_MAX 64
+#define SHARPNESS_DEFAULT 44
+#define MAIN 0
+#define OVERLAY 1
+#include "avfilter.h"
+#define MISC_PARAM_BAD_NAME (-1)
+#define MISC_PARAM_BAD_VALUE (-2)
+
+static const char *const var_names[] = {
+   "in_w",   "iw",
+    "in_h",   "ih",
+    "out_w",  "ow",
+    "out_h",  "oh",
+    "a",
+    "sar",
+    "dar",
+    "hsub",
+    "vsub",
+    "ohsub",
+    "ovsub",
+    "n",
+    "t",
+    "pos",
+    "main_w",
+    "main_h",
+    "main_a",
+    "main_sar",
+    "main_dar", "mdar",
+    "main_hsub",
+    "main_vsub",
+    "main_n",
+    "main_t",
+    "main_pos",
+    NULL
+};
+
+enum var_name {
+    VAR_IN_W,   VAR_IW,
+    VAR_IN_H,   VAR_IH,
+    VAR_OUT_W,  VAR_OW,
+    VAR_OUT_H,  VAR_OH,
+    VAR_A,
+    VAR_SAR,
+    VAR_DAR,
+    VAR_HSUB,
+    VAR_VSUB,
+    VAR_OHSUB,
+    VAR_OVSUB,
+    VAR_N,
+    VAR_T,
+    VAR_POS,
+    VAR_S2R_MAIN_W,
+    VAR_S2R_MAIN_H,
+    VAR_S2R_MAIN_A,
+    VAR_S2R_MAIN_SAR,
+    VAR_S2R_MAIN_DAR, VAR_S2R_MDAR,
+    VAR_S2R_MAIN_HSUB,
+    VAR_S2R_MAIN_VSUB,
+    VAR_S2R_MAIN_N,
+    VAR_S2R_MAIN_T,
+    VAR_S2R_MAIN_POS,
+    VARS_NB
+};
+
+
+typedef struct MiscVASTAPIContext {
+    VASTAPIVPPContext vpp_ctx; // must be the first field
+    int               nb_inputs;
+    int               nb_outputs;
+    AVDictionary     *filter_opts;
+
+    AVFilterPad pad;
+    AVFrame    *output_frames[64];
+
+    // overlay
+    FFFrameSync  fs;
+    unsigned int is_enable;
+    int          overlay_size;
+    char        *overlay_data;
+    double var_values[VARS_NB];
+    // colorspac
+} MiscVASTAPIContext;
+
+static int overlay_vastapi_blend(FFFrameSync *fs);
+static int misc_vastapi_config_output(AVFilterLink *outlink);
+static int misc_vastapi_filter_frame(AVFilterLink *inlink, AVFrame *input_frame);
+static int misc_vastapi_config_input(AVFilterLink *inlink);
+static int misc_vastapi_params_parse(AVFilterContext *avctx);
+
+static int misc_vastapi_params_parse(AVFilterContext *avctx)
+{
+    MiscVASTAPIContext    *ctx     = avctx->priv;
+    VASTAPIVPPContext     *vpp_ctx = avctx->priv;
+    AVDictionaryEntry     *en      = NULL;
+    VastapiFunctionsNoDev *func    = NULL;
+
+    if (vastapi_nodev_load_functions(&func) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Could not dynamically load vastapi\n");
+        return AVERROR(EIO);
+    }
+
+    if(func->vastapiFilterParamInit)
+        func->vastapiFilterParamInit(vpp_ctx->vastfilter_params.filt_params);
+
+    while ((en = av_dict_get(ctx->filter_opts, "", en, AV_DICT_IGNORE_SUFFIX))) {
+        int parse_ret = func->vastapiFilterParamParse(vpp_ctx->vastfilter_params.filt_params, en->key, en->value);
+
+        switch (parse_ret) {
+        case MISC_PARAM_BAD_NAME:
+            av_log(avctx, AV_LOG_WARNING, "Unknown option: %s.\n", en->key);
+            goto Error;
+        case MISC_PARAM_BAD_VALUE:
+            av_log(avctx, AV_LOG_WARNING, "Invalid value for %s: %s.\n", en->key, en->value);
+            goto Error;
+        default:
+            break;
+        }
+    }
+    if (!vpp_ctx->vastfilter_params.filt_params->nb_outputs) {
+        vpp_ctx->vastfilter_params.filt_params->nb_outputs = 1;
+    }
+    vastapi_nodev_free_functions(&func);
+    return 0;
+
+Error:
+    vastapi_nodev_free_functions(&func);
+    return -1;
+}
+
+static unsigned int eval_cmd_strings_prase(AVFilterLink *inlink,MiscVASTAPIContext *ctx, char *split)
+{
+    char *sub_string,*saveptr;
+    sub_string = av_strtok(ctx->vpp_ctx.vastfilter_params.filt_params->output_size, split,&saveptr);
+    const char *expr;
+    double res;
+    
+    int ret, w = 0, h = 0,factor_w = 1,factor_h = 1,scale_w,scale_h;
+    ctx->var_values[VAR_IN_W]  = ctx->var_values[VAR_IW] = inlink->w;
+    ctx->var_values[VAR_IN_H]  = ctx->var_values[VAR_IH] = inlink->h;
+    int index = 0, i = -1;
+
+    while (sub_string) {
+        if (index % 2 == 0) {
+            i++;
+            if ((ret = av_expr_parse_and_eval(&res, (expr = sub_string),
+                                var_names, ctx->var_values,
+                                NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)
+            return AVERROR(EINVAL);
+            scale_w = res;
+            w = scale_w;
+            if (w < -1) {
+                factor_w = -w;
+            }
+            if (!(w = scale_w))
+                w = inlink->w;
+        } else {
+            if ((ret = av_expr_parse_and_eval(&res, (expr = sub_string),
+                                var_names, ctx->var_values,
+                                NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)
+            return AVERROR(EINVAL);
+            scale_h = res;
+            h = scale_h;
+            if (h < -1) {
+                factor_h = -h;
+            }
+            if (!(h = scale_h))
+                h = inlink->h;
+        }
+        if(w != 0 && h != 0 ){
+            if (w < 0)
+                w = av_rescale(h, inlink->w, inlink->h * factor_w) * factor_w;
+
+            if (h < 0)
+                h = av_rescale(w, inlink->h, inlink->w * factor_h) * factor_h;
+
+            if (ctx->vpp_ctx.vastfilter_params.filt_params->force_original_aspect_ratio) {
+                int tmp_w = av_rescale(h, inlink->w, inlink->h);
+                int tmp_h = av_rescale(w, inlink->h, inlink->w);
+
+                if (ctx->vpp_ctx.vastfilter_params.filt_params->force_original_aspect_ratio == 1) {
+                    w = FFMIN(tmp_w, w);
+                    h = FFMIN(tmp_h, h);
+                } else {
+                    w = FFMAX(tmp_w, w);
+                    h = FFMAX(tmp_h, h);
+                }
+            }
+
+            if(h < 0 && w < 0){
+                w = inlink->w;
+                h = inlink->h;
+            }
+
+            ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].height = h;
+            if (ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].height % 2 != 0) {
+                ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].height = ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].height & ~0x1;
+            }
+
+            ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].width = w;
+            if (ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].width % 2 != 0) {
+                ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].width = ctx->vpp_ctx.vastfilter_params.filt_params->width_height_array[i].width & ~0x1;
+            }
+            w = 0, h = 0;
+        }
+        sub_string = av_strtok(NULL, split,&saveptr);
+        index++;
+    }
+    return i + 1;
+}
+
+
+static av_cold int misc_vastapi_init(AVFilterContext *avctx)
+{
+    VASTAPIVPPContext  *vpp_ctx = avctx->priv;
+    int                 i = 0, ret = 0;
+    MiscVASTAPIContext *ctx = avctx->priv;
+    ff_vastapi_vpp_ctx_init(avctx);
+    vpp_ctx->pipeline_uninit = ff_vastapi_vpp_pipeline_uninit;
+    if (!vpp_ctx->vastfilter_params.filt_params) {
+        vpp_ctx->vastfilter_params.filt_params = av_mallocz(sizeof(FilterParams));
+    }
+    ret = misc_vastapi_params_parse(avctx);
+    if (ret < 0) {
+        return -1;
+    }
+
+    ctx->nb_outputs = vpp_ctx->vastfilter_params.filt_params->nb_outputs;
+    if (vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterOverlay) {
+        ctx->fs.on_event      = overlay_vastapi_blend;
+        ctx->pad.type         = AVMEDIA_TYPE_VIDEO;
+        ctx->pad.name         = av_asprintf("main%d", 0);
+        ctx->pad.config_props = ff_vastapi_vpp_config_input;
+        if (!ctx->pad.name)
+            return AVERROR(ENOMEM);
+#if FF_GE(N500)
+        ret = ff_append_inpad(avctx, &ctx->pad);
+#else
+        ret = ff_insert_inpad(avctx, 0, &ctx->pad);
+#endif
+        if (ret < 0) {
+            av_freep(&ctx->pad.name);
+            return ret;
+        }
+
+        ctx->pad.type         = AVMEDIA_TYPE_VIDEO;
+        ctx->pad.name         = av_asprintf("overlay%d", 1);
+        ctx->pad.config_props = NULL;
+        if (!ctx->pad.name)
+            return AVERROR(ENOMEM);
+#if FF_GE(N500)
+        ret = ff_append_inpad(avctx, &ctx->pad);
+#else
+        ret = ff_insert_inpad(avctx, 1, &ctx->pad);
+#endif
+        if (ret < 0) {
+            av_freep(&ctx->pad.name);
+            return ret;
+        }
+
+        ctx->pad.type         = AVMEDIA_TYPE_VIDEO;
+        ctx->pad.name         = av_asprintf("output%d", 0);
+        ctx->pad.config_props = misc_vastapi_config_output;
+        if (!ctx->pad.name)
+            return AVERROR(ENOMEM);
+#if FF_GE(N500)
+        ret = ff_append_outpad(avctx, &ctx->pad);
+#else
+        ret = ff_insert_outpad(avctx, 0, &ctx->pad);
+#endif
+        if (ret < 0) {
+            av_freep(&ctx->pad.name);
+            return ret;
+        }
+        ctx->nb_inputs = avctx->nb_inputs;
+    } else {
+        ctx->pad.type         = AVMEDIA_TYPE_VIDEO;
+        ctx->pad.name         = av_asprintf("input%d", 0);
+        ctx->pad.config_props = misc_vastapi_config_input;
+        ctx->pad.filter_frame = &misc_vastapi_filter_frame;
+        if (!ctx->pad.name)
+            return AVERROR(ENOMEM);
+#if FF_GE(N500)
+        ret = ff_append_inpad(avctx, &ctx->pad);
+#else
+        ret = ff_insert_inpad(avctx, 0, &ctx->pad);
+#endif
+        if (ret < 0) {
+            av_freep(&ctx->pad.name);
+            return ret;
+        }
+        ctx->nb_inputs = avctx->nb_inputs;
+        for (i = 0; i < ctx->nb_outputs; i++) {
+            ctx->pad.type         = AVMEDIA_TYPE_VIDEO;
+            ctx->pad.name         = av_asprintf("output%d", i);
+            ctx->pad.config_props = misc_vastapi_config_output;
+            ctx->pad.filter_frame = NULL;
+            if (!ctx->pad.name)
+                return AVERROR(ENOMEM);
+#if FF_GE(N500)
+            ret = ff_append_outpad(avctx, &ctx->pad);
+#else
+            ret = ff_insert_outpad(avctx, i, &ctx->pad);
+#endif
+            if (ret < 0) {
+                av_freep(&ctx->pad.name);
+                return ret;
+            }
+        }
+    }
+    return 0;
+}
+
+static int vastfilter_rotate_switch(VASTFilterParamer *vastfilter_params)
+{
+    if (vastfilter_params->filt_params->type == VASTProcFilterRotate) {
+        if (vastfilter_params->filt_params->rotate_degree == 90 ||
+            vastfilter_params->filt_params->rotate_degree == -90 ||
+            vastfilter_params->filt_params->rotate_degree == 270 ||
+            vastfilter_params->filt_params->rotate_degree == -270) {
+            vastfilter_params->filt_params->width_height_array[0].width  = vastfilter_params->filt_params->height;
+            vastfilter_params->filt_params->width_height_array[0].height = vastfilter_params->filt_params->width;
+        } else if (vastfilter_params->filt_params->rotate_degree == 180 ||
+                   vastfilter_params->filt_params->rotate_degree == -180) {
+            vastfilter_params->filt_params->width_height_array[0].width  = vastfilter_params->filt_params->width;
+            vastfilter_params->filt_params->width_height_array[0].height = vastfilter_params->filt_params->height;
+            vastfilter_params->filt_params->rotate_degree                = 180;
+        } else {
+            // av_log(avctx, AV_LOG_ERROR, "Unsupported rotate_degree value: %d .\n",
+            // vctx->vastfilter_params.filt_params->rotate_degree);
+            return -2;
+        }
+    }
+    return 0;
+}
+
+static int misc_vastapi_config_input(AVFilterLink *inlink)
+{
+    AVFilterContext    *avctx = inlink->dst;
+    MiscVASTAPIContext *ctx   = avctx->priv;
+    VASTAPIVPPContext  *vctx  = avctx->priv;
+    int                 i     = 0;
+    int                 err   = ff_vastapi_vpp_config_input(inlink);
+    if (err < 0)
+        return err;
+    vctx->vastfilter_params.filt_params->height = inlink->h;
+    vctx->vastfilter_params.filt_params->width  = inlink->w;
+
+    vastfilter_rotate_switch(&vctx->vastfilter_params);
+    for (i = 0; i < vctx->vastfilter_params.filt_params->nb_outputs; i++) {
+        if (!vctx->vastfilter_params.filt_params->width_height_array[i].width) {
+            vctx->vastfilter_params.filt_params->width_height_array[i].width = inlink->w;
+        }
+        if (!vctx->vastfilter_params.filt_params->width_height_array[i].height) {
+            vctx->vastfilter_params.filt_params->width_height_array[i].height = inlink->h;
+        }
+    }
+
+    if (vctx->vastfilter_params.filt_params->type == VASTProcFilterTranspose) {
+        vctx->vastfilter_params.filt_params->width_height_array[0].width  = vctx->vastfilter_params.filt_params->height;
+        vctx->vastfilter_params.filt_params->width_height_array[0].height = vctx->vastfilter_params.filt_params->width;
+    }
+
+    if(strstr(ctx->vpp_ctx.vastfilter_params.filt_params->output_size,"if(")
+     || strstr(ctx->vpp_ctx.vastfilter_params.filt_params->output_size,"(") 
+     || strstr(ctx->vpp_ctx.vastfilter_params.filt_params->output_size,"-1")){
+        if (eval_cmd_strings_prase(inlink,ctx,"x+") != ctx->vpp_ctx.vastfilter_params.filt_params->nb_outputs) {
+            av_log(ctx, AV_LOG_ERROR, "The input parameters outputs and output_size do not match .\n");
+            return -1;
+        }   
+    }
+
+    for (i = 0; i < vctx->vastfilter_params.filt_params->nb_outputs; i++) {
+        if (!vctx->vastfilter_params.filt_params->width_height_array[i].width) {
+            vctx->vastfilter_params.filt_params->width_height_array[i].width = inlink->w;
+        }
+        if (!vctx->vastfilter_params.filt_params->width_height_array[i].height) {
+            vctx->vastfilter_params.filt_params->width_height_array[i].height = inlink->h;
+        }
+    }
+
+    return err;
+}
+
+static int misc_vastapi_config_output(AVFilterLink *outlink)
+{
+    AVFilterLink       *inlink  = outlink->src->inputs[0];
+    AVFilterContext    *avctx   = outlink->src;
+    VASTAPIVPPContext  *vpp_ctx = avctx->priv;
+    MiscVASTAPIContext *ctx     = avctx->priv;
+    int                 err     = 0;
+    const int           output  = outlink->srcpad - avctx->output_pads;
+
+    vpp_ctx->output_width  = vpp_ctx->vastfilter_params.filt_params->width_height_array[output].width;
+    vpp_ctx->output_height = vpp_ctx->vastfilter_params.filt_params->width_height_array[output].height;
+    vpp_ctx->output_format = av_get_pix_fmt(vpp_ctx->vastfilter_params.filt_params->format);
+
+    if (vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterBitCvt) {
+        if (vpp_ctx->input_frames->sw_format == AV_PIX_FMT_NV12) {
+            vpp_ctx->output_format = AV_PIX_FMT_YUV420P10LE;
+        } else if (vpp_ctx->input_frames->sw_format == AV_PIX_FMT_P010LE) {
+            vpp_ctx->output_format = AV_PIX_FMT_NV12;
+        } else if (vpp_ctx->input_frames->sw_format == AV_PIX_FMT_YUV420P10LE) {
+            vpp_ctx->output_format = AV_PIX_FMT_NV12;
+        } else if (vpp_ctx->input_frames->sw_format == AV_PIX_FMT_YUV420P) {
+            vpp_ctx->output_format = AV_PIX_FMT_YUV420P10LE;
+        } else
+            vpp_ctx->output_format = vpp_ctx->input_frames->sw_format;
+    }
+
+    err = ff_vastapi_vpp_config_output(outlink);
+    if (err < 0)
+        return err;
+    if (inlink->sample_aspect_ratio.num){
+        if((vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterRotate && 
+            vpp_ctx->vastfilter_params.filt_params->rotate_degree != 180 && vpp_ctx->vastfilter_params.filt_params->rotate_degree != -180)
+            || vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterTranspose)
+            outlink->sample_aspect_ratio = av_div_q((AVRational) { 1, 1 }, inlink->sample_aspect_ratio);
+        else
+            outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h * inlink->w, outlink->w * inlink->h}, inlink->sample_aspect_ratio);
+    }
+    else
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+
+    if (vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterOverlay) {
+        if ((err = ff_framesync_init_dualinput(&ctx->fs, avctx)) < 0)
+            return err;
+
+        err = ff_framesync_configure(&ctx->fs);
+    }
+
+    return err;
+}
+
+static int misc_vastapi_filter_frame(AVFilterLink *inlink, AVFrame *input_frame)
+{
+    AVFilterContext    *avctx        = inlink->dst;
+    VASTAPIVPPContext  *vpp_ctx      = avctx->priv;
+    MiscVASTAPIContext *ctx          = avctx->priv;
+    AVFrame            *output_frame = NULL;
+    int                 err;
+
+    av_log(avctx, AV_LOG_DEBUG, "Filter input: %s, %ux%u (%" PRId64 ").\n", av_get_pix_fmt_name(input_frame->format),
+           input_frame->width, input_frame->height, input_frame->pts);
+
+    if (vpp_ctx->vastfilter_params.va_context == VAST_INVALID_ID)
+        return AVERROR(EINVAL);
+
+    for (int i = 0; i < ctx->nb_outputs; i++) {
+        AVFilterLink *outlink = avctx->outputs[i];
+        switch (vpp_ctx->input_frames->sw_format) {
+        case AV_PIX_FMT_NV12:
+            output_frame = ff_get_video_buffer(
+                outlink, FFALIGN(vpp_ctx->vastfilter_params.filt_params->width_height_array[i].width, 64),
+                FFALIGN(vpp_ctx->vastfilter_params.filt_params->width_height_array[i].height, 64));
+            break;
+        case AV_PIX_FMT_YUV420P:
+            output_frame = ff_get_video_buffer(
+                outlink, FFALIGN(vpp_ctx->vastfilter_params.filt_params->width_height_array[i].width / 2, 64) * 2,
+                FFALIGN(vpp_ctx->vastfilter_params.filt_params->width_height_array[i].height, 64));
+            break;
+        default:
+            output_frame = ff_get_video_buffer(
+                outlink, FFALIGN(vpp_ctx->vastfilter_params.filt_params->width_height_array[i].width, 64),
+                FFALIGN(vpp_ctx->vastfilter_params.filt_params->width_height_array[i].height, 64));
+        }
+        if (!output_frame) {
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+
+        vpp_ctx->vastfilter_params.pipeline_params.output_surface[i] = output_frame->data[3];
+        err                                                          = av_frame_copy_props(output_frame, input_frame);
+        if (err < 0)
+            goto fail;
+
+        if(vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterCSC){
+            //output_frame->format = vpp_ctx->output_format;
+            if(vpp_ctx->vastfilter_params.filt_params->out_fullrange == 1){
+                output_frame->color_range = AVCOL_RANGE_JPEG;
+            }else if(vpp_ctx->vastfilter_params.filt_params->out_fullrange == 0){
+                output_frame->color_range = AVCOL_RANGE_MPEG;
+            }else{
+                output_frame->color_range = input_frame->color_range;
+                av_log(ctx, AV_LOG_WARNING, "color range %d not support, set out eq in:%d\n",
+                        vpp_ctx->vastfilter_params.filt_params->out_fullrange, input_frame->color_range);
+            }
+
+            if(vpp_ctx->vastfilter_params.filt_params->out_primaries == REC_470_BG_C){
+                output_frame->color_primaries = AVCOL_PRI_BT470BG;
+            }else if(vpp_ctx->vastfilter_params.filt_params->out_primaries == SMPTE_C){
+                output_frame->color_primaries = AVCOL_PRI_SMPTE170M;
+            }else if(vpp_ctx->vastfilter_params.filt_params->out_primaries == REC_709_C){
+                output_frame->color_primaries = AVCOL_PRI_BT709;
+            }else{
+                output_frame->color_primaries = input_frame->color_primaries;
+                av_log(ctx, AV_LOG_WARNING, "color primaries %d not support, set out eq in:%d\n",
+                        vpp_ctx->vastfilter_params.filt_params->out_primaries, input_frame->color_primaries);
+            }
+
+            if(vpp_ctx->vastfilter_params.filt_params->out_transfer == REC_709_T){
+                output_frame->color_trc = AVCOL_TRC_BT709;
+            }else{
+                output_frame->color_trc = input_frame->color_trc;
+                av_log(ctx, AV_LOG_WARNING, "color transfer %d not support, set out eq in:%d\n",
+                        vpp_ctx->vastfilter_params.filt_params->out_transfer, input_frame->color_trc);
+            }
+
+            if(vpp_ctx->vastfilter_params.filt_params->out_matrix == REC_601){
+                output_frame->colorspace = AVCOL_SPC_SMPTE170M;
+            }else if(vpp_ctx->vastfilter_params.filt_params->out_matrix == REC_709_M){
+                output_frame->colorspace = AVCOL_SPC_BT709;
+            }else{
+                output_frame->colorspace = input_frame->colorspace;
+                av_log(ctx, AV_LOG_WARNING, "color matrix %d not support, set out eq in:%d\n",
+                        vpp_ctx->vastfilter_params.filt_params->out_matrix, input_frame->colorspace);
+            }
+        }
+
+        ctx->output_frames[i] = output_frame;
+    }
+
+    vpp_ctx->vastfilter_params.pipeline_params.filt_params = vpp_ctx->vastfilter_params.filt_params;
+    vpp_ctx->vastfilter_params.pipeline_params.width       = input_frame->width;
+    vpp_ctx->vastfilter_params.pipeline_params.height      = input_frame->height;
+    vpp_ctx->vastfilter_params.pipeline_params.type        = vpp_ctx->vastfilter_params.filt_params->type;
+
+    for (int i = 0; i < ctx->nb_outputs; i++) {
+        AVFilterLink *outlink = avctx->outputs[i];
+        if (ff_outlink_get_status(outlink))
+            continue;
+    }
+
+    err = ff_vastapi_vpp_render_picture(avctx, &vpp_ctx->vastfilter_params, input_frame);
+    if (err < 0)
+        goto fail;
+
+    for (int i = 0; i < ctx->nb_outputs; i++) {
+        AVFilterLink *outlink = avctx->outputs[i];
+        output_frame          = ctx->output_frames[i];
+        av_log(avctx, AV_LOG_DEBUG, "Filter output: %s, %ux%u (%" PRId64 ").\n",
+               av_get_pix_fmt_name(output_frame->format), output_frame->width, output_frame->height, output_frame->pts);
+
+        err = ff_filter_frame(outlink, output_frame);
+    }
+    av_frame_free(&input_frame);
+    return err;
+fail:
+    av_frame_free(&input_frame);
+    av_frame_free(&output_frame);
+    return err;
+}
+
+static av_cold void misc_vastapi_uninit(AVFilterContext *avctx)
+{
+    VASTAPIVPPContext  *vpp_ctx = avctx->priv;
+    MiscVASTAPIContext *misc    = avctx->priv;
+    int                 i       = 0;
+    for (i = 0; i < misc->nb_inputs; i++) {
+        if (avctx->input_pads[i].name)
+            av_freep(&avctx->input_pads[i].name);
+    }
+
+    for (i = 0; i < misc->nb_outputs; i++) {
+        if (avctx->output_pads[i].name)
+            av_freep(&avctx->output_pads[i].name);
+    }
+    ff_framesync_uninit(&misc->fs);
+    ff_vastapi_vpp_ctx_uninit(avctx);
+
+    if (misc->overlay_data)
+        av_freep(&misc->overlay_data);
+    if (vpp_ctx->vastfilter_params.filt_params) {
+        av_freep(&vpp_ctx->vastfilter_params.filt_params);
+    }
+}
+
+static int save_yuva(MiscVASTAPIContext *ctx, char *data, AVFrame *frame)
+{
+    int            i;
+    unsigned char *yuva = NULL;
+    unsigned char *pos  = NULL;
+
+    if (data == NULL || frame == NULL || frame->data[0] == NULL || frame->data[1] == NULL || frame->data[2] == NULL) {
+        av_log(ctx, AV_LOG_ERROR, "Failed params error\n");
+        return AVERROR(EINVAL);
+    }
+
+    yuva = data;
+    pos  = frame->data[0];
+    for (i = 0; i < frame->height; i++) {
+        memcpy(yuva, pos, frame->width);
+        yuva += frame->width;
+        pos += frame->linesize[0];
+    }
+    pos = frame->data[1];
+    for (i = 0; i < frame->height / 2; i++) {
+        memcpy(yuva, pos, frame->width / 2);
+        yuva += frame->width / 2;
+        pos += frame->linesize[1];
+    }
+    pos = frame->data[2];
+    for (i = 0; i < frame->height / 2; i++) {
+        memcpy(yuva, pos, frame->width / 2);
+        yuva += frame->width / 2;
+        pos += frame->linesize[2];
+    }
+    if (frame->data[3]) {
+        pos = frame->data[3];
+        for (i = 0; i < frame->height; i++) {
+            memcpy(yuva, pos, frame->width);
+            yuva += frame->width;
+            pos += frame->linesize[3];
+        }
+    }
+
+    return 0;
+}
+
+static int overlay_vastapi_blend(FFFrameSync *fs)
+{
+    AVFilterContext    *avctx   = fs->parent;
+    MiscVASTAPIContext *ctx     = avctx->priv;
+    VASTAPIVPPContext  *vpp_ctx = avctx->priv;
+    AVFrame            *main_frame, *overlay_frame, *output_frame;
+    int                 ret = 0;
+
+    ret = ff_framesync_get_frame(fs, 0, &main_frame, 0);
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to get main frame\n");
+        ret = AVERROR(EINVAL);
+        return ret;
+    }
+
+    main_frame->width  = main_frame->width & ~0x1;
+    main_frame->height = main_frame->height & ~0x1;
+
+    main_frame->pts = av_rescale_q(fs->pts, fs->time_base, avctx->outputs[0]->time_base);
+    ret             = ff_framesync_get_frame(fs, 1, &overlay_frame, 0);
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to get overlay frame\n");
+        ret = AVERROR(EINVAL);
+        return ret;
+    }
+
+    if(overlay_frame){
+        if (overlay_frame->width % 2 == 1) {
+            overlay_frame->width--;
+        }
+        if (overlay_frame->height % 2 == 1) {
+            overlay_frame->height--;
+        }
+        if (ctx->is_enable != 1) {
+            ctx->overlay_size = overlay_frame->width * overlay_frame->height * 5 / 2; // yuva
+            ctx->overlay_data = malloc(sizeof(unsigned char) * ctx->overlay_size);
+            ctx->is_enable    = 1;
+        }
+        ret = save_yuva(ctx, ctx->overlay_data, overlay_frame);
+        if (ret != 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to save overlay yuva\n");
+            return ret;
+        }
+        vpp_ctx->vastfilter_params.pipeline_params.overlay_width  = overlay_frame->width;
+        vpp_ctx->vastfilter_params.pipeline_params.overlay_height = overlay_frame->height;
+        vpp_ctx->vastfilter_params.pipeline_params.overlay_data   = ctx->overlay_data;
+    }
+
+    vpp_ctx->vastfilter_params.pipeline_params.filt_params    = vpp_ctx->vastfilter_params.filt_params;
+    vpp_ctx->vastfilter_params.pipeline_params.width          = main_frame->width;
+    vpp_ctx->vastfilter_params.pipeline_params.height         = main_frame->height;
+    vpp_ctx->vastfilter_params.pipeline_params.type           = vpp_ctx->vastfilter_params.filt_params->type;
+    av_hwframe_sync_surface(main_frame);
+    ret = ff_vastapi_vpp_render_picture(avctx, &vpp_ctx->vastfilter_params, main_frame);
+    if (ret < 0) {
+        return -1;
+    }
+
+    output_frame = av_frame_clone(main_frame);
+    return ff_filter_frame(avctx->outputs[0], output_frame);
+}
+
+static int activate(AVFilterContext *avctx)
+{
+    int                 ret     = 0;
+    MiscVASTAPIContext *ctx     = avctx->priv;
+    VASTAPIVPPContext  *vpp_ctx = avctx->priv;
+    if (vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterOverlay) {
+        ret = ff_framesync_activate(&ctx->fs);
+    } else {
+        ret = ff_filter_activate_default_extern(avctx);
+    }
+    return ret;
+}
+
+static int misc_vastapi_query_formats(AVFilterContext *avctx)
+{
+    VASTAPIVPPContext *vpp_ctx = avctx->priv;
+
+    enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_VASTAPI,
+        AV_PIX_FMT_NONE,
+    };
+
+    int                 err;
+    MiscVASTAPIContext *ctx = avctx->priv;
+
+#if FF_GE(N441)
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->inputs[0]->outcfg.formats);
+#else
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->inputs[0]->out_formats);
+#endif
+    if (err < 0)
+        return err;
+#if FF_GE(N441)
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->outputs[0]->incfg.formats);
+#else
+    err = ff_formats_ref(ff_make_format_list(pix_fmts), &avctx->outputs[0]->in_formats);
+#endif
+    if (err < 0)
+        return err;
+
+    if (vpp_ctx->vastfilter_params.filt_params->type == VASTProcFilterOverlay) {
+        enum AVPixelFormat overlay_pix_fmts[] = { AV_PIX_FMT_YUVA420P, AV_PIX_FMT_NONE };
+#if FF_GE(N441)
+        err = ff_formats_ref(ff_make_format_list(overlay_pix_fmts), &avctx->inputs[1]->outcfg.formats);
+#else
+        err = ff_formats_ref(ff_make_format_list(overlay_pix_fmts), &avctx->inputs[1]->out_formats);
+#endif
+        if (err < 0)
+            return err;
+    }
+
+    return 0;
+}
+
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+#define MOFFSET(x) offsetof(MiscVASTAPIContext, x)
+#define ENUM(x, y, z)                                                                                                  \
+    {                                                                                                                  \
+        x, "", 0, AV_OPT_TYPE_CONST, { .i64 = y }, INT_MIN, INT_MAX, FLAGS, z                                          \
+    }
+
+static const AVOption misc_vastapi_options[] = {
+    { "filter_opts",
+      "set the misc proc configuration using a :-separated list of key=value parameters",
+      MOFFSET(filter_opts),
+      AV_OPT_TYPE_DICT,
+      { 0 },
+      0,
+      0,
+      FLAGS },
+    { NULL },
+};
+
+// AVFILTER_DEFINE_CLASS(misc_vastapi);
+static const AVFilterPad misc_vastapi_inputs[] = { {
+                                                       .name         = "default",
+                                                       .type         = AVMEDIA_TYPE_VIDEO,
+                                                       .config_props = &ff_vastapi_vpp_config_input,
+                                                       .filter_frame = &misc_vastapi_filter_frame,
+                                                   },
+                                                   {
+                                                       NULL,
+                                                   } };
+
+static const AVFilterPad misc_vaapi_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = &misc_vastapi_config_output,
+    },
+};
+
+FRAMESYNC_DEFINE_CLASS(misc_vastapi, MiscVASTAPIContext, fs);
+AVFilter ff_vf_misc_vastapi = {
+    .name        = "misc_vastapi",
+    .description = NULL_IF_CONFIG_SMALL("Misc ops to/from vastai surfaces."),
+    .priv_size   = sizeof(MiscVASTAPIContext),
+    .init        = &misc_vastapi_init,
+    .uninit      = &misc_vastapi_uninit,
+#if FF_GE(N500)
+    FILTER_QUERY_FUNC(misc_vastapi_query_formats),
+#else
+    .query_formats = &misc_vastapi_query_formats,
+#endif
+    .inputs         = NULL,
+    .outputs        = NULL,
+    .priv_class     = &misc_vastapi_class,
+    .preinit        = misc_vastapi_framesync_preinit,
+    .activate       = activate,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+    .flags          = AVFILTER_FLAG_DYNAMIC_OUTPUTS,
+};
diff --git a/libavformat/ivfenc.c b/libavformat/ivfenc.c
old mode 100644
new mode 100755
diff --git a/libavutil/Makefile b/libavutil/Makefile
index d17876d..1053797 100644
--- a/libavutil/Makefile
+++ b/libavutil/Makefile
@@ -32,6 +32,7 @@ HEADERS = adler32.h                                                     \
           fifo.h                                                        \
           file.h                                                        \
           frame.h                                                       \
+          frame_vastapi.h                                               \
           hash.h                                                        \
           hdr_dynamic_metadata.h                                        \
           hmac.h                                                        \
@@ -44,6 +45,7 @@ HEADERS = adler32.h                                                     \
           hwcontext_mediacodec.h                                        \
           hwcontext_opencl.h                                            \
           hwcontext_vaapi.h                                             \
+          hwcontext_vastapi.h                                           \
           hwcontext_videotoolbox.h                                      \
           hwcontext_vdpau.h                                             \
           hwcontext_vulkan.h                                            \
@@ -186,6 +188,7 @@ OBJS-$(CONFIG_MEDIACODEC)               += hwcontext_mediacodec.o
 OBJS-$(CONFIG_OPENCL)                   += hwcontext_opencl.o
 OBJS-$(CONFIG_QSV)                      += hwcontext_qsv.o
 OBJS-$(CONFIG_VAAPI)                    += hwcontext_vaapi.o
+OBJS-$(CONFIG_VASTAPI)                  += hwcontext_vastapi.o
 OBJS-$(CONFIG_VIDEOTOOLBOX)             += hwcontext_videotoolbox.o
 OBJS-$(CONFIG_VDPAU)                    += hwcontext_vdpau.o
 OBJS-$(CONFIG_VULKAN)                   += hwcontext_vulkan.o
@@ -204,6 +207,7 @@ SKIPHEADERS-$(CONFIG_DXVA2)            += hwcontext_dxva2.h
 SKIPHEADERS-$(CONFIG_QSV)              += hwcontext_qsv.h
 SKIPHEADERS-$(CONFIG_OPENCL)           += hwcontext_opencl.h
 SKIPHEADERS-$(CONFIG_VAAPI)            += hwcontext_vaapi.h
+SKIPHEADERS-$(CONFIG_VASTAPI)          += hwcontext_vastapi.h
 SKIPHEADERS-$(CONFIG_VIDEOTOOLBOX)     += hwcontext_videotoolbox.h
 SKIPHEADERS-$(CONFIG_VDPAU)            += hwcontext_vdpau.h
 SKIPHEADERS-$(CONFIG_VULKAN)           += hwcontext_vulkan.h vulkan.h   \
diff --git a/libavutil/cpu.c b/libavutil/cpu.c
index 1368502..8023349 100644
--- a/libavutil/cpu.c
+++ b/libavutil/cpu.c
@@ -194,6 +194,11 @@ int av_cpu_count(void)
 
     int nb_cpus = 1;
     int count   = 0;
+
+#if defined ANDROID || defined ANDROID_32BIT
+    return nb_cpus;
+#endif
+
 #if HAVE_WINRT
     SYSTEM_INFO sysinfo;
 #endif
diff --git a/libavutil/frame.h b/libavutil/frame.h
index 18e239f..bfa2a2d 100644
--- a/libavutil/frame.h
+++ b/libavutil/frame.h
@@ -201,6 +201,28 @@ enum AVFrameSideDataType {
      * libavutil/dovi_meta.h.
      */
     AV_FRAME_DATA_DOVI_METADATA,
+
+#if CONFIG_VASTAPI
+    /**
+     * dynamic param change
+     * ((u32*)AVFrameSideData.data)[0] is u32 for kbps targetbitrate
+     * ((u32*)AVFrameSideData.data)[1] is u32 for kbps vbvmaxrate  default value 0, 1.05*targetbitrate
+     * ((u32*)AVFrameSideData.data)[1] is u32 for kbps vbvbufsize  default value 0,
+     *
+     */
+    AV_FRAME_DATE_VASTAI_BITRATE_EXT1,
+
+    AV_FRAME_DATA_UDU_SEI,
+    AV_FRAME_DATA_RESERVED_SEI,
+    AV_FRAME_DATA_ROIMAP, // set user roimap
+
+    AV_FRAME_DATA_VASTAI_FRAMERATE,
+
+    AV_FRAME_DATA_VASTAI_CRF,
+
+    AV_FRAME_DATA_VASTAI_KEYINT
+#endif
+
 };
 
 enum AVActiveFormatDescription {
@@ -683,6 +705,9 @@ typedef struct AVFrame {
     AVBufferRef *private_ref;
 } AVFrame;
 
+#if CONFIG_VASTAPI
+#include "frame_vastapi.h"
+#endif
 
 #if FF_API_COLORSPACE_NAME
 /**
diff --git a/libavutil/frame_vastapi.h b/libavutil/frame_vastapi.h
new file mode 100644
index 0000000..83f65db
--- /dev/null
+++ b/libavutil/frame_vastapi.h
@@ -0,0 +1,21 @@
+typedef struct VastFrameInfo {
+    int width;
+    int height;
+    int format;
+} VastFrameInfo;
+
+/**
+ * Allocate an vastai custome AVFrame and set its data[] as dma buffer vir addr,
+ * fill linesize[] info from vastai hw. the user can copy their raw data to data[]
+ * directly according linesize. The resulting struct must be freed using av_frame_free().
+ *
+ * @param hw_frames_ctx: AVHWFramesContext used to get pitch info
+ *
+ * @param frameInfo: used for getting hw pitch info, include width,height,format
+ *
+ * @return An AVFrame used for dma transfer directly or NULL on failure.
+ *
+ * @note this already allocates the AVFrame data buffer, no need to get buffer
+ * by av_frame_get_buffer();
+ */
+AVFrame *av_frame_alloc_vastai(AVBufferRef *hw_frames_ctx, VastFrameInfo *frameInfo);
\ No newline at end of file
diff --git a/libavutil/hwcontext.c b/libavutil/hwcontext.c
index 31c7840..ae0a070 100644
--- a/libavutil/hwcontext.c
+++ b/libavutil/hwcontext.c
@@ -50,6 +50,9 @@ static const HWContextType * const hw_table[] = {
 #if CONFIG_VAAPI
     &ff_hwcontext_type_vaapi,
 #endif
+#if CONFIG_VASTAPI
+    &ff_hwcontext_type_vastapi,
+#endif
 #if CONFIG_VDPAU
     &ff_hwcontext_type_vdpau,
 #endif
@@ -73,6 +76,7 @@ static const char *const hw_type_names[] = {
     [AV_HWDEVICE_TYPE_OPENCL] = "opencl",
     [AV_HWDEVICE_TYPE_QSV]    = "qsv",
     [AV_HWDEVICE_TYPE_VAAPI]  = "vaapi",
+    [AV_HWDEVICE_TYPE_VASTAPI]  = "vastapi",
     [AV_HWDEVICE_TYPE_VDPAU]  = "vdpau",
     [AV_HWDEVICE_TYPE_VIDEOTOOLBOX] = "videotoolbox",
     [AV_HWDEVICE_TYPE_MEDIACODEC] = "mediacodec",
@@ -307,7 +311,9 @@ static int hwframe_pool_prealloc(AVBufferRef *ref)
     AVHWFramesContext *ctx = (AVHWFramesContext*)ref->data;
     AVFrame **frames;
     int i, ret = 0;
-
+#ifdef CONFIG_VASTAPI 
+    int pre_pool_size = ctx->initial_pool_size;
+#endif  
     frames = av_calloc(ctx->initial_pool_size, sizeof(*frames));
     if (!frames)
         return AVERROR(ENOMEM);
@@ -320,6 +326,17 @@ static int hwframe_pool_prealloc(AVBufferRef *ref)
         ret = av_hwframe_get_buffer(ref, frames[i], 0);
         if (ret < 0)
             goto fail;
+#ifdef CONFIG_VASTAPI            
+        if(pre_pool_size != ctx->initial_pool_size){
+            frames = av_realloc(frames, ctx->initial_pool_size*sizeof(*frames));
+            if(!frames){
+                return AVERROR(ENOMEM);
+            }
+            memset(&frames[pre_pool_size], 0, sizeof(*frames)*(ctx->initial_pool_size - pre_pool_size));
+            pre_pool_size = ctx->initial_pool_size;
+        }          
+#endif
+
     }
 
 fail:
@@ -926,3 +943,4 @@ int ff_hwframe_map_replace(AVFrame *dst, const AVFrame *src)
     av_frame_unref(hwmap->source);
     return av_frame_ref(hwmap->source, src);
 }
+
diff --git a/libavutil/hwcontext.h b/libavutil/hwcontext.h
index 04d19d8..f3e74b2 100644
--- a/libavutil/hwcontext.h
+++ b/libavutil/hwcontext.h
@@ -29,6 +29,7 @@ enum AVHWDeviceType {
     AV_HWDEVICE_TYPE_VDPAU,
     AV_HWDEVICE_TYPE_CUDA,
     AV_HWDEVICE_TYPE_VAAPI,
+    AV_HWDEVICE_TYPE_VASTAPI,
     AV_HWDEVICE_TYPE_DXVA2,
     AV_HWDEVICE_TYPE_QSV,
     AV_HWDEVICE_TYPE_VIDEOTOOLBOX,
@@ -227,6 +228,19 @@ typedef struct AVHWFramesContext {
      * Must be set by the user before calling av_hwframe_ctx_init().
      */
     int width, height;
+#if CONFIG_VASTAPI
+    /**
+     * The frame buffer status flag, add by vastai.
+     *
+     * 0:  Real HW buffer allocated when av_hwframe_get_buffer called, default value.
+     *
+     * 1： No HW real buffer allocated when av_hwframe_get_buffer called, must call av_hwframe_set_addr_to_surfaceid
+     *     to set an external buffer addr to the frame;
+     *
+     * Must be set by the user before calling av_hwframe_ctx_init().
+     */
+    int frame_buffer_flag;
+#endif
 } AVHWFramesContext;
 
 /**
@@ -412,6 +426,80 @@ int av_hwframe_get_buffer(AVBufferRef *hwframe_ctx, AVFrame *frame, int flags);
  */
 int av_hwframe_transfer_data(AVFrame *dst, const AVFrame *src, int flags);
 
+#if CONFIG_VASTAPI
+int av_hwframe_sync_surface(const AVFrame *src);
+
+/**
+ * Get vastai soc addr from surface id,.
+ *
+ * @param hw_frame hw_frame which contain a surface id, surface_id and hw_frames_ctx MUST be setted.
+ *
+ * @param frame_addr the pointer to store output addr.
+ *
+ * @return 0 on success, a negative AVERROR code on failure
+ */
+int av_hwframe_get_addr_from_surfaceid(const AVFrame *src, uint64_t *frame_addr);
+
+/**
+ * Set vastai soc addr to surface id,.
+ *
+ * @param hw_frame hw_frame which contain a surface id, surface_id and hw_frames_ctx MUST be setted.
+ *
+ * @param frame_addr the pointer to be set to surface.
+ *
+ * @return 0 on success, a negative AVERROR code on failure
+ */
+int av_hwframe_set_addr_to_surfaceid(const AVFrame *src, uint64_t frame_addr);
+
+/**
+ * Alloc a dma buffer and mmap to user space,  set frame->data[] as dma buffer vir addr,
+ * fill linesize[] info from hwfc. the user can copy their raw data to data[]
+ * directly according linesize[].
+ *
+ * @param hwfc AVHWFramesContext struct for this frame.
+ *
+ * @param frame the customed AVFrame, already filled format,width and height.
+ *            NOT need get buffer before call this API, its data and linesize will be
+ *            filled after call this API.
+ *
+ * @return 0 on success, a negative AVERROR code on failure
+ */
+int av_hwframe_get_dmabuffer(AVHWFramesContext* hwfc, AVFrame *frame);
+
+/**
+ * Set vastai soc addr to surface id, the soc addr is from dmabuf.
+ *
+ * @param hw_frame hw_frame which contain a surface id, surface_id and hw_frames_ctx MUST be setted.
+ *
+ * @param dmabuf_fd the dmabuf fd from buffer exporter.
+ *
+ * @return 0 on success, a negative AVERROR code on failure
+ */
+int av_hwframe_set_addr_to_surfaceid_from_fd(const AVFrame *src, int dmabuf_fd);
+
+/**
+ * transfer a dma buffer to device,  user may set a dmabuffer fd or phy addr
+ *
+ * @param dst the dst AVframe. catch the surface id
+ *
+ * @param src the src AVFrame, catch the fd or phy addr on src->opaque,
+ *
+ * @param src_type input src type. dmabuffer fd: 0 , phy addr: 1
+ *
+ * @return 0 on success, a negative AVERROR code on failure
+ */
+int av_hwframe_transfer_data_ex(AVFrame *dst, const AVFrame *src, int src_type);
+
+/**
+ * Set preset for loadbalance.
+ *
+ * @param preset encoder preset.
+ *
+ * @return 0 on success, a negative AVERROR code on failure
+ */
+int av_hwframe_set_preset_to_loadbalance(char *preset);
+#endif
+
 enum AVHWFrameTransferDirection {
     /**
      * Transfer the data from the queried hw frame.
diff --git a/libavutil/hwcontext_internal.h b/libavutil/hwcontext_internal.h
index e626649..af45a04 100644
--- a/libavutil/hwcontext_internal.h
+++ b/libavutil/hwcontext_internal.h
@@ -98,6 +98,18 @@ typedef struct HWContextType {
                                          AVHWFramesContext *src_ctx, int flags);
     int              (*frames_derive_from)(AVHWFramesContext *dst_ctx,
                                            AVHWFramesContext *src_ctx, int flags);
+#if CONFIG_VASTAPI
+    int              (*sync_surface)(AVHWFramesContext *ctx, const AVFrame *src);
+    int              (*get_frame_addr)(AVHWFramesContext *ctx, const AVFrame *src,
+                                uint64_t* frame_addr);
+    int              (*set_frame_addr)(AVHWFramesContext *ctx, const AVFrame *src, uint64_t frame_addr);
+    int              (*set_frame_addr_from_fd)(AVHWFramesContext *ctx, const AVFrame *src, int dmabuf_fd);
+    int              (*frames_get_dmabuffer)(AVHWFramesContext *ctx, AVFrame *frame);
+    int              (*transfer_data_to_ex)(AVHWFramesContext *hwfc,
+                                  AVFrame *dst, const AVFrame *src, int src_type);
+    int              (*transfer_data_from_ex)(AVHWFramesContext *hwfc,
+                                  AVFrame *dst, const AVFrame *src, int src_type);
+#endif
 } HWContextType;
 
 struct AVHWDeviceInternal {
@@ -170,6 +182,7 @@ extern const HWContextType ff_hwcontext_type_dxva2;
 extern const HWContextType ff_hwcontext_type_opencl;
 extern const HWContextType ff_hwcontext_type_qsv;
 extern const HWContextType ff_hwcontext_type_vaapi;
+extern const HWContextType ff_hwcontext_type_vastapi;
 extern const HWContextType ff_hwcontext_type_vdpau;
 extern const HWContextType ff_hwcontext_type_videotoolbox;
 extern const HWContextType ff_hwcontext_type_mediacodec;
diff --git a/libavutil/hwcontext_vastapi.c b/libavutil/hwcontext_vastapi.c
new file mode 100644
index 0000000..19d7dcd
--- /dev/null
+++ b/libavutil/hwcontext_vastapi.c
@@ -0,0 +1,1228 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+#include <sys/types.h>
+#include <sys/stat.h>
+#include "config.h"
+
+#include <fcntl.h>
+#if HAVE_UNISTD_H
+#include <unistd.h>
+#endif
+
+#include <time.h>
+#include "avassert.h"
+#include "buffer.h"
+#include "common.h"
+#include "hwcontext.h"
+#include "hwcontext_drm.h"
+#include "hwcontext_internal.h"
+#include "hwcontext_vastapi.h"
+#include "mem.h"
+#include "pixdesc.h"
+#include "pixfmt.h"
+#ifdef DMA_TRANS_WITH_USERBUF
+#include "attributes.h"
+#endif
+#include <pthread.h>
+
+#define DECODER_WIDTH_ALIGN (128)
+#define DECODER_HEIGHT_ALIGN (64)
+
+#define DMA_INPUT_ADDR_ALIGN (0x1000)
+#define UPPER_ALIGN(size, align) (((size) + (align)-1) & (~((align)-1)))
+#define DOWN_ALIGN(size, align) ((size) & (~((align)-1)))
+
+static VASTAPIContext vstctx_from_avHwFrmCtx(AVHWFramesContext *hwfc)
+{
+    VASTAPIContext vstCtx;
+
+    vstCtx.avVstDevCtx = hwfc->device_ctx->hwctx;
+    vstCtx.avVstFrmCtx = hwfc->hwctx;
+    vstCtx.avVstHwCfg  = NULL;
+
+    vstCtx.vstDevCtx = hwfc->device_ctx->internal->priv;
+    vstCtx.vstFrmCtx = hwfc->internal->priv;
+
+    vstCtx.dmahandle = NULL;
+    vstCtx.map       = NULL;
+    vstCtx.surfaceId = 0;
+
+    return vstCtx;
+}
+
+static VASTAPIContext vstctx_from_avHwDevCtx(AVHWDeviceContext *hwdev)
+{
+    VASTAPIContext vstCtx;
+
+    vstCtx.avVstDevCtx = hwdev->hwctx;
+    vstCtx.avVstFrmCtx = NULL;
+    vstCtx.avVstHwCfg  = NULL;
+
+    vstCtx.vstDevCtx = hwdev->internal->priv;
+    vstCtx.vstFrmCtx = NULL;
+
+    vstCtx.dmahandle = NULL;
+    vstCtx.map       = NULL;
+    vstCtx.surfaceId = 0;
+
+    return vstCtx;
+}
+
+static int vastapi_frames_get_constraints(AVHWDeviceContext *hwdev, const void *hwconfig,
+                                          AVHWFramesConstraints *constraints)
+{
+    AVVASTAPIDeviceContext  *hwctx     = hwdev->hwctx;
+    VastapiFunctions        *func      = (VastapiFunctions *)hwctx->vst_func;
+    const AVVASTAPIHWConfig *config    = hwconfig;
+    VASTAPIDeviceContext    *ctx       = hwdev->internal->priv;
+    VASTSurfaceAttrib       *attr_list = NULL;
+    VAST_PIX_FTM             vst_pix_ftm;
+    enum AVPixelFormat       pix_fmt;
+    unsigned int             fourcc;
+    int                      err, i, j;
+    VastapiConstraint        csts;
+
+    VASTAPIContext vstCtx = vstctx_from_avHwDevCtx(hwdev);
+    vstCtx.avVstHwCfg     = hwconfig;
+
+    if (config) {
+        err                     = func->vastapiHwGetConstraints(&vstCtx, &csts, &attr_list);
+        constraints->min_width  = csts.min_width;
+        constraints->min_height = csts.min_height;
+        constraints->max_width  = csts.max_width;
+        constraints->max_height = csts.max_height;
+
+        if (csts.pix_fmt_count == 0) {
+            constraints->valid_sw_formats = NULL;
+        } else {
+            constraints->valid_sw_formats = av_malloc_array(csts.pix_fmt_count + 1, sizeof(pix_fmt));
+            if (!constraints->valid_sw_formats) {
+                err = AVERROR(ENOMEM);
+                goto fail;
+            }
+
+            for (i = j = 0; i < csts.attr_count; i++) {
+                if (attr_list[i].type != VASTSurfaceAttribPixelFormat)
+                    continue;
+                fourcc      = attr_list[i].value.value.i;
+                vst_pix_ftm = func->vastapiHwPixFmtFromFourcc(fourcc);
+                pix_fmt     = vastaiFmtToAvFmt(vst_pix_ftm);
+                if (pix_fmt != AV_PIX_FMT_NONE)
+                    constraints->valid_sw_formats[j++] = pix_fmt;
+            }
+            av_assert0(j == csts.pix_fmt_count);
+            constraints->valid_sw_formats[j] = AV_PIX_FMT_NONE;
+        }
+    } else {
+        constraints->valid_sw_formats = av_malloc_array(ctx->nb_formats + 1, sizeof(pix_fmt));
+        if (!constraints->valid_sw_formats) {
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+        for (i = 0; i < ctx->nb_formats; i++) {
+            pix_fmt                          = vastaiFmtToAvFmt(ctx->formats[i].pix_fmt);
+            constraints->valid_sw_formats[i] = pix_fmt;
+        }
+        constraints->valid_sw_formats[i] = AV_PIX_FMT_NONE;
+    }
+
+    constraints->valid_hw_formats = av_malloc_array(2, sizeof(pix_fmt));
+    if (!constraints->valid_hw_formats) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    constraints->valid_hw_formats[0] = AV_PIX_FMT_VASTAPI;
+    constraints->valid_hw_formats[1] = AV_PIX_FMT_NONE;
+
+    err = 0;
+fail:
+    func->vastapiFreeMemory(attr_list);
+    return err;
+}
+
+static int vastapi_device_init(AVHWDeviceContext *hwdev)
+{
+    VASTAPIDeviceContext   *ctx   = hwdev->internal->priv;
+    AVVASTAPIDeviceContext *hwctx = hwdev->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+
+    return func->vastapiHwDeviceInit(ctx, hwctx);
+}
+
+static void vastapi_device_uninit(AVHWDeviceContext *hwdev)
+{
+    VASTAPIDeviceContext   *ctx   = hwdev->internal->priv;
+    AVVASTAPIDeviceContext *hwctx = hwdev->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    if(!func){
+        return;
+    }
+
+    if (ctx->formats)
+        func->vastapiFreeMemory(ctx->formats);
+    ctx->formats = NULL;
+
+    func->vastapiHwDeviceFree(hwctx, hwdev->user_opaque);
+
+    vastapi_free_functions((VastapiFunctions **)&hwctx->vst_func);
+}
+
+static AVBufferRef *vastapi_pool_alloc(void *opaque, int size)
+{
+    AVHWFramesContext      *hwfc  = opaque;
+    VASTAPIFramesContext   *ctx   = hwfc->internal->priv;
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    AVVASTAPIFramesContext *avfc  = hwfc->hwctx;
+    VASTSurfaceID           surface_id;
+    VASTStatus              vas;
+    AVBufferRef            *ref;
+
+    if (hwfc->initial_pool_size > 0 && avfc->nb_surfaces >= hwfc->initial_pool_size)
+        return NULL;
+
+    vas = func->vastapiCreateSurfaces(hwctx->display, ctx->rt_format, hwfc->width, hwfc->height, &surface_id, 1,
+                                      ctx->attributes, ctx->nb_attributes);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(hwfc, AV_LOG_ERROR, "Failed to create surface: %d.\n", vas);
+        return NULL;
+    }
+    av_log(hwfc, AV_LOG_DEBUG, "Created surface %#x.\n", surface_id);
+
+    ref = av_buffer_create((uint8_t *)(uintptr_t)surface_id, sizeof(surface_id), func->vastapiHwBuffFree, hwctx,
+                           AV_BUFFER_FLAG_READONLY);
+    if (!ref) {
+        func->vastapiHwBuffFree(hwctx, (void *)&surface_id);
+        return NULL;
+    }
+
+    if (hwfc->initial_pool_size > 0) {
+        // This is a fixed-size pool, so we must still be in the initial
+        // allocation sequence.
+        av_assert0(avfc->nb_surfaces < hwfc->initial_pool_size);
+        avfc->surface_ids[avfc->nb_surfaces] = surface_id;
+        ++avfc->nb_surfaces;
+    }
+
+    return ref;
+}
+
+static AVBufferRef *vastapi_dmabuffer_pool_alloc(void *opaque, int size)
+{
+    AVHWFramesContext      *hwfc  = opaque;
+    VASTAPIFramesContext   *ctx   = hwfc->internal->priv;
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    AVBufferRef            *ref;
+    VASTAPIDmaHandle       *dmahandle = NULL;
+
+    VASTAPIContext vstCtx = vstctx_from_avHwFrmCtx(hwfc);
+
+    dmahandle = func->vastapiHwAllocDmaBuff(&vstCtx);
+    if (dmahandle == NULL)
+        return NULL;
+
+    av_log(hwfc, AV_LOG_DEBUG, "Created dma buffer device id=0x%x, size=%d\n", dmahandle->device_id,
+           dmahandle->data_size);
+
+    ref = av_buffer_create((uint8_t *)(uintptr_t)dmahandle, sizeof(VASTAPIDmaHandle *), func->vastapiHwDmaBuffFree,
+                           hwctx, AV_BUFFER_FLAG_READONLY);
+    if (!ref) {
+        func->vastapiDestroyDmaHandle(hwctx->display, dmahandle);
+        av_log(hwctx, AV_LOG_ERROR, "Failed to create buffer for dma handle\n");
+        return NULL;
+    }
+
+    ctx->number_dmabuffer++;
+
+    return ref;
+}
+
+static int vastapi_transfer_data_to_ex(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src, int src_type)
+{
+    int                     fd              = 0;
+    uint64_t                dmabuffer_addr  = 0;
+    int                     dmabuf_size     = 0;
+    uint64_t                input_addr_mask = ~(DMA_INPUT_ADDR_ALIGN - 1); // 4k align for dma transfer
+    AVVASTAPIDeviceContext *hwctx           = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func            = (VastapiFunctions *)hwctx->vst_func;
+
+    VASTAPIContext vstCtx = vstctx_from_avHwFrmCtx(hwfc);
+
+    if (!dst || !dst->hw_frames_ctx || !dst->data[3]) {
+        av_log(hwfc, AV_LOG_ERROR, "%s %d invalid hw frame \n", __func__, __LINE__);
+        return AVERROR(EINVAL);
+    }
+
+    if (!src || !src->opaque) {
+        av_log(hwfc, AV_LOG_ERROR, "%s %d invalid src frame\n", __func__, __LINE__);
+        return AVERROR(EINVAL);
+    }
+
+    if (src_type) {
+        dmabuffer_addr = ((uint64_t)src->opaque) & input_addr_mask;
+        dmabuf_size    = (src->linesize[0] + src->linesize[1]) * src->height + ((uint64_t)src->opaque - dmabuffer_addr);
+    } else {
+        fd = *((int *)src->opaque);
+    }
+
+    return func->vastapiHwTransferData(&vstCtx, dmabuffer_addr, dmabuf_size, dst->data[3], fd, src_type, 0);
+}
+
+static int vastapi_transfer_data_from_ex(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src, int src_type)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    VASTImage               image;
+    VASTStatus              vas;
+    VASTSurfaceID           surface_id;
+    int                     fd             = 0;
+    uint64_t                dmabuffer_addr = 0;
+    int                     dmabuf_size    = 0;
+
+    VASTAPIContext vstCtx = vstctx_from_avHwFrmCtx(hwfc);
+
+    if (!src || !src->hw_frames_ctx || !src->data[3]) {
+        av_log(hwfc, AV_LOG_ERROR, "%s %d invalid hw frame \n", __func__, __LINE__);
+        return AVERROR(EINVAL);
+    }
+
+    if (!dst) {
+        av_log(hwfc, AV_LOG_ERROR, "%s %d invalid dst frame\n", __func__, __LINE__);
+        return AVERROR(EINVAL);
+    }
+
+    surface_id = (VASTSurfaceID)(uintptr_t)src->data[3];
+
+    av_log(hwfc, AV_LOG_DEBUG, "%s %d fd=%d, dmabuffer_addr=0x%lx, surface_id=0x%x\n", __func__, __LINE__, fd,
+           dmabuffer_addr, surface_id);
+
+    image.image_id = VAST_INVALID_ID;
+    vas            = func->vastapiDeriveImage(hwctx->display, surface_id, &image);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(hwfc, AV_LOG_ERROR, "Failed to derive image from surface %#x: %d.\n", surface_id, vas);
+        return AVERROR(EINVAL);
+    }
+
+    dst->linesize[0] = image.pitches[0];
+    dst->linesize[1] = image.pitches[1];
+    dst->linesize[2] = image.pitches[2];
+    dst->width       = image.width;
+    dst->height      = image.height;
+    dst->format      = AV_PIX_FMT_NV12;
+    dst->crop_right  = UPPER_ALIGN(dst->width, DECODER_WIDTH_ALIGN) - dst->width;
+    dst->crop_bottom = UPPER_ALIGN(dst->height, DECODER_HEIGHT_ALIGN) - dst->height;
+
+    av_log(hwfc, AV_LOG_DEBUG, "%s %d width=%d height=%d format=%d linesize[%d %d %d] crop_right=%ld crop_bottom=%ld\n",
+           __func__, __LINE__, dst->width, dst->height, dst->format, dst->linesize[0], dst->linesize[1],
+           dst->linesize[2], dst->crop_right, dst->crop_bottom);
+
+    if (src_type) {
+        dmabuffer_addr = ((uint64_t)dst->data[0]);
+        dmabuf_size    = image.data_size;
+    } else {
+        fd = *((int *)dst->opaque);
+    }
+
+    return func->vastapiHwTransferData(&vstCtx, dmabuffer_addr, dmabuf_size, src->data[3], fd, src_type, 1);
+}
+
+static int vastapi_frames_init(AVHWFramesContext *hwfc)
+{
+    AVVASTAPIFramesContext *avfc         = hwfc->hwctx;
+    VASTAPIFramesContext   *ctx          = hwfc->internal->priv;
+    AVVASTAPIDeviceContext *hwctx        = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func         = (VastapiFunctions *)hwctx->vst_func;
+    AVBufferRef            *test_surface = NULL;
+    int                     err;
+
+    VASTAPIContext vstCtx  = vstctx_from_avHwFrmCtx(hwfc);
+    VAST_PIX_FTM   pix_fmt = avFmtToVastaiFmt(hwfc->sw_format);
+
+    if (!hwfc->pool) {
+
+        err = func->vastapiHwFrameInit(&vstCtx, pix_fmt, hwfc->initial_pool_size, hwfc->frame_buffer_flag);
+        if (err < 0) {
+            return err;
+        }
+
+        hwfc->internal->pool_internal = av_buffer_pool_init2(sizeof(VASTSurfaceID), hwfc, &vastapi_pool_alloc, NULL);
+        if (!hwfc->internal->pool_internal) {
+            av_log(hwfc, AV_LOG_ERROR, "Failed to create VASTAPI surface pool.\n");
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+
+        ctx->pool_dmabuffer =
+            av_buffer_pool_init2(sizeof(VASTAPIDmaHandle *), hwfc, &vastapi_dmabuffer_pool_alloc, NULL);
+        if (!ctx->pool_dmabuffer) {
+            av_log(hwfc, AV_LOG_ERROR, "Failed to create VASTAPI dmabuffer pool.\n");
+            err = AVERROR(ENOMEM);
+            goto fail;
+        }
+    }
+
+    test_surface = av_buffer_pool_get(hwfc->internal->pool_internal);
+    if (!test_surface) {
+        av_log(hwfc, AV_LOG_ERROR, "Unable allocate surface from internal buffer pool.\n");
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    func->vastapiHwTestDeriveWork(&vstCtx, pix_fmt, test_surface->data);
+
+    av_buffer_unref(&test_surface);
+    return 0;
+
+fail:
+    av_buffer_unref(&test_surface);
+    if (avfc->surface_ids)
+        free(avfc->surface_ids);
+    if (ctx->attributes)
+        free(ctx->attributes);
+    return err;
+}
+
+static void vastapi_frames_uninit(AVHWFramesContext *hwfc)
+{
+    AVVASTAPIFramesContext *avfc  = hwfc->hwctx;
+    VASTAPIFramesContext   *ctx   = hwfc->internal->priv;
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+
+#ifdef VENC_INPUT_DMA
+    if (ctx->dma_transfer.inited){
+        if (ctx->dma_hack_enable) {
+            if(ctx->dma_transfer.dmabuff_viraddr){
+                free(ctx->dma_transfer.dmabuff_viraddr);
+                ctx->dma_transfer.dmabuff_viraddr = NULL;
+            }
+        } else {
+            func->vastapiDestroyDmaHandle(hwctx->display, &ctx->dma_transfer);
+        }
+    }
+
+    if (ctx->pool_dmabuffer) {
+        av_buffer_pool_uninit(&ctx->pool_dmabuffer);
+        ctx->init_dmabuffer_pool_size = 0;
+        ctx->number_dmabuffer = 0;
+        ctx->buffer_elem_size = 0;
+    }
+#endif
+
+    if (avfc->surface_ids)
+        func->vastapiFreeMemory(avfc->surface_ids);
+    if (ctx->attributes)
+        func->vastapiFreeMemory(ctx->attributes);
+}
+
+static int av_buffer_pool_realloc(AVHWFramesContext *hwfc)
+{
+    AVVASTAPIFramesContext *avfc = hwfc->hwctx;
+
+    hwfc->initial_pool_size = hwfc->initial_pool_size + 10;
+    avfc->surface_ids       = realloc(avfc->surface_ids, hwfc->initial_pool_size * sizeof(*avfc->surface_ids));
+
+    return 0;
+}
+
+static int av_buffer_pool_revert_size(AVHWFramesContext *hwfc)
+{
+    hwfc->initial_pool_size = hwfc->initial_pool_size - 10;
+    return 0;
+}
+
+static int vastapi_get_buffer(AVHWFramesContext *hwfc, AVFrame *frame)
+{
+    frame->buf[0] = av_buffer_pool_get(hwfc->pool);
+
+    if (!frame->buf[0]) {
+        if (av_buffer_pool_realloc(hwfc) < 0)
+            return AVERROR(ENOMEM);
+        frame->buf[0] = av_buffer_pool_get(hwfc->pool);
+    }
+    if (!frame->buf[0]) {
+        printf("Error: there is no space left, vastapi_get_buffer failed.\n");
+        av_buffer_pool_revert_size(hwfc);
+        return AVERROR(ENOMEM);
+    }
+
+    frame->data[3] = frame->buf[0]->data;
+    frame->format  = AV_PIX_FMT_VASTAPI;
+    frame->width   = hwfc->width;
+    frame->height  = hwfc->height;
+
+    return 0;
+}
+
+static int vastapi_transfer_get_formats(AVHWFramesContext *hwfc, enum AVHWFrameTransferDirection dir,
+                                        enum AVPixelFormat **formats)
+{
+    VASTAPIDeviceContext *ctx = hwfc->device_ctx->internal->priv;
+    enum AVPixelFormat   *pix_fmts, tmp_fmts;
+    int                   i, k, sw_format_available;
+
+    sw_format_available = 0;
+    for (i = 0; i < ctx->nb_formats; i++) {
+        tmp_fmts = vastaiFmtToAvFmt(ctx->formats[i].pix_fmt);
+        if (tmp_fmts == hwfc->sw_format)
+            sw_format_available = 1;
+    }
+
+    pix_fmts = av_malloc((ctx->nb_formats + 1) * sizeof(*pix_fmts));
+    if (!pix_fmts)
+        return AVERROR(ENOMEM);
+
+    if (sw_format_available) {
+        pix_fmts[0] = hwfc->sw_format;
+        k           = 1;
+    } else {
+        k = 0;
+    }
+    for (i = 0; i < ctx->nb_formats; i++) {
+        tmp_fmts = vastaiFmtToAvFmt(ctx->formats[i].pix_fmt);
+        if (tmp_fmts == hwfc->sw_format)
+            continue;
+        av_assert0(k < ctx->nb_formats);
+        pix_fmts[k++] = tmp_fmts;
+    }
+    pix_fmts[k] = AV_PIX_FMT_NONE;
+
+    *formats = pix_fmts;
+    return 0;
+}
+
+static void vastapi_unmap_frame(AVHWFramesContext *hwfc, HWMapDescriptor *hwmap)
+{
+    VASTAPIContext          vstCtx = vstctx_from_avHwFrmCtx(hwfc);
+    AVVASTAPIDeviceContext *hwctx  = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func   = (VastapiFunctions *)hwctx->vst_func;
+    vstCtx.map                     = hwmap->priv;
+
+    func->vastapiHwUnmapFrame(&vstCtx, hwmap->source->data[3], hwfc->width, hwfc->height);
+
+    av_free(hwmap->priv);
+}
+
+static int vastapi_map_frame_dma(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src, int flags, int isUseDma)
+{
+    AVVASTAPIDeviceContext  *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions        *func  = (VastapiFunctions *)hwctx->vst_func;
+    VASTAPIFramesContext    *ctx   = hwfc->internal->priv;
+    VASTAPIFormatDescriptor *desc;
+    VASTAPIMapping          *map     = NULL;
+    void                    *address = NULL;
+    int                      err, i;
+    VAST_PIX_FTM             dstFtm = 0;
+    VASTAPIContext           vstCtx = vstctx_from_avHwFrmCtx(hwfc);
+
+    if (dst->format == AV_PIX_FMT_NONE)
+        dst->format = hwfc->sw_format;
+    if (dst->format != hwfc->sw_format && (flags & AV_HWFRAME_MAP_DIRECT)) {
+        return AVERROR(EINVAL);
+    }
+
+    map = av_malloc(sizeof(*map));
+    if (!map)
+        return AVERROR(ENOMEM);
+
+    vstCtx.surfaceId = (VASTSurfaceID)(uintptr_t)src->data[3];
+    vstCtx.map       = map;
+    dstFtm           = avFmtToVastaiFmt(dst->format);
+    err              = func->vastapiHwMapFrame(&vstCtx, dstFtm, hwfc->width, hwfc->height, flags);
+    if (err < 0) {
+        goto fail;
+    }
+
+    if (isUseDma) {
+        address = ctx->dma_transfer.dmabuff_viraddr;
+    } else {
+        if (func->vastapiMapBuffer(hwctx->display, map->image.buf, &address) != 0) {
+            av_log(hwfc, AV_LOG_ERROR, "Failed to map image from surface %#x.\n", vstCtx.surfaceId);
+            err = AVERROR(EIO);
+            goto fail;
+        }
+    }
+
+    err = ff_hwframe_map_create(src->hw_frames_ctx, dst, src, &vastapi_unmap_frame, map);
+    if (err < 0)
+        goto fail;
+
+    dst->width  = src->width;
+    dst->height = src->height;
+
+    for (i = 0; i < map->image.num_planes; i++) {
+        dst->data[i]     = (uint8_t *)address + map->image.offsets[i];
+        dst->linesize[i] = map->image.pitches[i];
+    }
+
+    desc = func->vastapiHwFmtFromFourcc(map->image.format.fourcc);
+    if (desc && desc->chroma_planes_swapped) {
+        FFSWAP(uint8_t *, dst->data[1], dst->data[2]);
+    }
+
+    return 0;
+
+fail:
+    if (map) {
+        if (address)
+            func->vastapiUnmapBuffer(hwctx->display, map->image.buf);
+        if (map->image.image_id != VAST_INVALID_ID)
+            func->vastapiDestroyImage(hwctx->display, map->image.image_id);
+        av_free(map);
+    }
+    return err;
+}
+
+static int vastapi_get_dma_buffer(AVHWFramesContext *hwfc, AVFrame *frame)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    VASTAPIFramesContext   *ctx   = hwfc->internal->priv;
+    VASTStatus              vas;
+    int                     i, err = 0, ret = 0;
+    VASTAPIDmaHandle       *dmahandle;
+    AVFrame                *hw_frame;
+    VASTSurfaceID           surface_id;
+    VASTImage               image;
+    void                   *address = NULL;
+
+    hw_frame = av_frame_alloc();
+    if (hw_frame == NULL) {
+        av_log(hwfc, AV_LOG_ERROR, "%s %d alloc avframe failed\n", __func__, __LINE__);
+        return AVERROR(ENOMEM);
+    }
+
+    ret = vastapi_get_buffer(hwfc, hw_frame);
+    if (ret) {
+        av_log(hwfc, AV_LOG_ERROR, "%s %d get buffer for hw frame failed\n", __func__, __LINE__);
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    image.image_id = VAST_INVALID_ID;
+    surface_id     = (VASTSurfaceID)(uintptr_t)hw_frame->data[3];
+
+    vas = func->vastapiDeriveImage(hwctx->display, surface_id, &image);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(hwfc, AV_LOG_ERROR, "Failed to derive image from surface %#x: %d.\n", surface_id, vas);
+        err = AVERROR(EIO);
+        goto fail;
+    }
+
+    ctx->buffer_elem_size = image.data_size;
+    frame->opaque_ref     = av_buffer_pool_get(ctx->pool_dmabuffer);
+
+    if (!frame->opaque_ref) {
+        av_log(hwfc, AV_LOG_ERROR, "vastapi get dma buffer from pool failed!\n");
+        return AVERROR(ENOMEM);
+    }
+
+    dmahandle = (VASTAPIDmaHandle *)frame->opaque_ref->data;
+    if (dmahandle == NULL) {
+        av_log(hwfc, AV_LOG_ERROR, "invalid vastai frame, dmahandle is null\n");
+        return AVERROR(EINVAL);
+    }
+
+    address = dmahandle->dmabuff_viraddr;
+
+    for (i = 0; i < image.num_planes; i++) {
+        frame->data[i]     = (uint8_t *)address + image.offsets[i];
+        frame->linesize[i] = image.pitches[i];
+    }
+
+fail:
+    if (image.image_id != VAST_INVALID_ID) {
+        func->vastapiDestroyImage(hwctx->display, image.image_id);
+    }
+
+    av_frame_free(&hw_frame);
+
+    return err;
+}
+
+static int vastapi_sync_surface_s(AVHWFramesContext *hwfc, const AVFrame *src)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    VASTSurfaceID           surface_id;
+    VASTStatus              vas;
+    int                     err = 0;
+
+    surface_id = (VASTSurfaceID)(uintptr_t)src->data[3];
+
+    vas = func->vastapiSyncSurface(hwctx->display, surface_id);
+    if (vas != VAST_STATUS_SUCCESS) {
+        av_log(hwfc, AV_LOG_ERROR, "Failed to sync surface %#x: %d.\n", surface_id, vas);
+        err = AVERROR(EIO);
+    }
+
+    return err;
+}
+
+static int vastapi_get_addr_from_surfaceid(AVHWFramesContext *hwfc, const AVFrame *src, uint64_t *frame_addr)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+
+    return func->vastapiHwSurfaceAddr(hwctx, src->data[3], frame_addr, 1);
+}
+
+static int vastapi_set_addr_to_surfaceid(AVHWFramesContext *hwfc, const AVFrame *src, uint64_t frame_addr)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+
+    return func->vastapiHwSurfaceAddr(hwctx, src->data[3], &frame_addr, 0);
+}
+
+static int vastapi_set_addr_to_surfaceid_from_fd(AVHWFramesContext *hwfc, const AVFrame *src, int dmabuf_fd)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+
+    if (!func->vastapiHwSurfaceAddrFromFd) {
+        av_log(hwfc, AV_LOG_ERROR,
+               "failed to load fun vastapiHwSurfaceAddrFromFd\n");
+        return -1;
+    }
+
+    return func->vastapiHwSurfaceAddrFromFd(hwctx, src->data[3], dmabuf_fd);
+}
+
+static int vastapi_transfer_data_from(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    VASTAPIFramesContext   *ctx   = hwfc->internal->priv;
+    AVFrame                *map;
+    int                     err;
+
+    if (dst->width > hwfc->width || dst->height > hwfc->height)
+        return AVERROR(EINVAL);
+
+    map = av_frame_alloc();
+    if (!map)
+        return AVERROR(ENOMEM);
+    map->format = dst->format;
+
+    err = vastapi_map_frame_dma(hwfc, map, src, AV_HWFRAME_MAP_DIRECT, 1);
+    if (err)
+        goto fail;
+
+    map->width  = src->width;
+    map->height = src->height;
+    if (ctx->dma_hack_enable) {
+        err = func->vastapiDeviceMemcpy(hwctx->display, (ctx->dma_transfer.device_id)>>24, ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size, ctx->dma_transfer.dmabuff_viraddr, 1, &ctx->dma_transfer);
+        if (err) {
+            av_log(hwfc, AV_LOG_ERROR, "Failed to transfer yuv data by hack dma, err = %d, busaddr=0x%x, size=%d\n",
+                    err, ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size);
+        }
+    } else {
+        err = func->vastapiDmaReadBuf(hwctx->display, ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size,
+                                    &ctx->dma_transfer);
+        if (err) {
+            av_log(hwfc, AV_LOG_ERROR, "Failed to transfer yuv data by dma, err = %d, busaddr=0x%lx, size=%d\n", err,
+                ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size);
+        }
+    }
+
+    err = av_frame_copy(dst, map);
+    if (err)
+        goto fail;
+
+    err = 0;
+fail:
+    av_frame_free(&map);
+    return err;
+}
+
+static int vastapi_transfer_data_to(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src)
+{
+    AVVASTAPIDeviceContext *hwctx = hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+    VASTAPIFramesContext   *ctx   = hwfc->internal->priv;
+    AVFrame                *map;
+    int                     err = 0;
+    VASTAPIDmaHandle       *dmahandle;
+    VASTStatus              vas;
+
+    if (src->width > hwfc->width || src->height > hwfc->height)
+        return AVERROR(EINVAL);
+
+    if (src->opaque_ref != NULL) {
+        if (!dst->hw_frames_ctx || !dst->data[3]) {
+            av_log(hwfc, AV_LOG_ERROR, "%s %d invalid hw frame, ctx is null \n", __func__, __LINE__);
+            return AVERROR(EINVAL);
+        }
+
+        dmahandle = (VASTAPIDmaHandle *)src->opaque_ref->data;
+        if (dmahandle == NULL) {
+            av_log(hwfc, AV_LOG_ERROR, "invalid dmahandle from frame, \n");
+            return AVERROR(ENOMEM);
+        }
+
+        if (!dst->hw_frames_ctx || !dst->data[3]) {
+            av_log(hwfc, AV_LOG_ERROR, "%s %d invalid hw frame, ctx is null \n", __func__, __LINE__);
+            return AVERROR(EINVAL);
+        }
+
+        err = func->vastapiHwSurfaceAddr(hwctx, dst->data[3], &dmahandle->bus_addr, 1);
+        if (err < 0) {
+            return err;
+        }
+
+        vas = func->vastapiDmaWriteBuf(hwctx->display, (unsigned long long)dmahandle->bus_addr, dmahandle->data_size,
+                                       dmahandle);
+        if (vas != VAST_STATUS_SUCCESS) {
+            av_log(hwfc, AV_LOG_ERROR, "Failed to transfer yuv data by map dma, err = %d, busaddr=0x%lx, size=%d\n",
+                   vas, ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size);
+            return AVERROR(EIO);
+        }
+
+        return 0;
+
+    } else {
+        map = av_frame_alloc();
+        if (!map)
+            return AVERROR(ENOMEM);
+        map->format = src->format;
+        err         = vastapi_map_frame_dma(hwfc, map, dst, AV_HWFRAME_MAP_OVERWRITE, 1);
+        if (err)
+            goto fail;
+
+        map->width  = src->width;
+        map->height = src->height;
+
+#ifndef DMA_TRANS_WITH_USERBUF
+        err = av_frame_copy(map, src);
+        if (err)
+            goto fail;
+#endif
+
+#ifdef DMA_TRANS_WITH_USERBUF
+        unsigned int              i;
+        unsigned int              trans_cnt                     = 0;
+        unsigned int              remain_len                    = 0;
+        unsigned int              aheight                       = 0;
+        struct vastai_channel_buf channel[AV_NUM_DATA_POINTERS] = { 0 };
+        int                       planes                        = 0;
+        int                       h                             = 0;
+        AVPixFmtDescriptor       *desc;
+
+        h    = src->height;
+        desc = av_pix_fmt_desc_get(map->format);
+
+        for (i = 0; i < AV_NUM_DATA_POINTERS; i++) {
+            if (i == 1 || i == 2) {
+                h = AV_CEIL_RSHIFT(src->height, desc->log2_chroma_h);
+            }
+            if (src->data[i] != NULL) {
+                planes++;
+                channel[i].width            = src->linesize[i];
+                channel[i].high             = h;
+                channel[i].user_buf         = src->data[i];
+                channel[i].src_width_offset = 0;
+                channel[i].src_high_offset  = 0;
+                channel[i].dst_width_offset = map->linesize[i] - src->linesize[i];
+                if ((i < AV_NUM_DATA_POINTERS - 1) && map->data[i + 1] != NULL) {
+                    aheight                    = (u32)(map->data[i + 1] - map->data[i]) / map->linesize[i] - h;
+                    channel[i].dst_high_offset = aheight;
+                } else {
+                    channel[i].dst_high_offset = 0;
+                }
+                av_log(NULL, AV_LOG_DEBUG, "channel[%d]h %d, dst_width_offset %d, dst_high_offset %d.\n", i, i,
+                       map->linesize[i], i, src->linesize[i], h, channel[i].dst_width_offset,
+                       channel[i].dst_high_offset);
+            } else {
+                break;
+            }
+        }
+        QueWriteDmaBufSg(channel, planes, dma_meta.bus_addr, dma_meta.die_id);
+#else
+        if (ctx->dma_hack_enable) {
+            err = func->vastapiDeviceMemcpy(hwctx->display, (ctx->dma_transfer.device_id)>>24, ctx->dma_transfer.dmabuff_viraddr, ctx->dma_transfer.data_size, ctx->dma_transfer.bus_addr, 0, &ctx->dma_transfer);
+            if (err) {
+                av_log(hwfc, AV_LOG_ERROR, "Failed to transfer yuv data by hack dma, err = %d, busaddr=0x%x, size=%d\n",
+                     err, ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size);
+            }
+        } else {
+            err = func->vastapiDmaWriteBuf(hwctx->display, ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size,
+                                        &ctx->dma_transfer);
+            if (err) {
+                av_log(hwfc, AV_LOG_ERROR, "Failed to transfer yuv data by dma, err = %d, busaddr=0x%lx, size=%d\n", err,
+                    ctx->dma_transfer.bus_addr, ctx->dma_transfer.data_size);
+            }
+        }
+
+
+#endif
+
+    fail:
+        av_frame_free(&map);
+        return err;
+    }
+}
+
+static int vastapi_map_to_memory(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src, int flags)
+{
+    int                     err;
+    AVVASTAPIDeviceContext *hwctx = (AVVASTAPIDeviceContext *)hwfc->device_ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+
+    if (dst->format != AV_PIX_FMT_NONE) {
+        err = func->vastapiHwGetImgFmt(hwfc->device_ctx->internal->priv, avFmtToVastaiFmt(dst->format), NULL);
+        if (err < 0)
+            return AVERROR(ENOSYS);
+    }
+
+    err = vastapi_map_frame_dma(hwfc, dst, src, flags, 0);
+    if (err)
+        return err;
+
+    err = av_frame_copy_props(dst, src);
+    if (err)
+        return err;
+
+    return 0;
+}
+
+static int vastapi_map_to(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src, int flags)
+{
+    switch (src->format) {
+    default:
+        return AVERROR(ENOSYS);
+    }
+}
+
+static int vastapi_map_from(AVHWFramesContext *hwfc, AVFrame *dst, const AVFrame *src, int flags)
+{
+    switch (dst->format) {
+    default:
+        return vastapi_map_to_memory(hwfc, dst, src, flags);
+    }
+}
+
+static void vastapi_device_free(AVHWDeviceContext *ctx)
+{
+    AVVASTAPIDeviceContext *hwctx = (AVVASTAPIDeviceContext *)ctx->hwctx;
+    VastapiFunctions       *func  = (VastapiFunctions *)hwctx->vst_func;
+
+    // func->vastapiHwDeviceFree(ctx->hwctx, ctx->user_opaque);
+}
+
+int av_hwframe_set_preset_to_loadbalance(char *preset)
+{
+    int                    ret  = 0;
+    VastapiFunctionsNoDev *func = NULL;
+    if (vastapi_nodev_load_functions(&func) < 0) {
+        printf("Could not dynamically load vastapi\n");
+        return AVERROR(EIO);
+    }
+    ret = func->vastapiPresetLoadBL(preset);
+
+    vastapi_nodev_free_functions(&func);
+    return ret;
+}
+
+static int vastapi_device_create(AVHWDeviceContext *ctx, const char *device, AVDictionary *opts, int flags)
+{
+    void                   *user_opaque = NULL;
+    int                     ret         = 0;
+    AVVASTAPIDeviceContext *hwctx       = (AVVASTAPIDeviceContext *)ctx->hwctx;
+    VastapiFunctions       *func        = NULL;
+
+    if (!hwctx->vst_func) {
+        ret = vastapi_load_functions((VastapiFunctions **)&hwctx->vst_func);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Could not dynamically load vastapi\n");
+            return AVERROR(EIO);
+        }
+    }
+    func = (VastapiFunctions *)hwctx->vst_func;
+
+    user_opaque = func->vastapiHwDeviceCreate(hwctx, device);
+    if (!user_opaque) {
+        vastapi_free_functions((VastapiFunctions **)&hwctx->vst_func);
+        return AVERROR(ENOMEM);
+    }
+
+    ctx->user_opaque = user_opaque;
+    ctx->free        = vastapi_device_free;
+
+    return 0;
+}
+
+static int vastapi_device_derive(AVHWDeviceContext *ctx, AVHWDeviceContext *src_ctx,
+#if LIBAVUTIL_VERSION_INT >= AV_VERSION_INT(56, 51, 100) // n4.3
+                                 AVDictionary *opts,
+#endif
+                                 int flags)
+{
+    return AVERROR(ENOSYS);
+}
+
+const HWContextType ff_hwcontext_type_vastapi = {
+    .type = AV_HWDEVICE_TYPE_VASTAPI,
+    .name = "VASTAPI",
+
+    .device_hwctx_size    = sizeof(AVVASTAPIDeviceContext),
+    .device_priv_size     = sizeof(VASTAPIDeviceContext),
+    .device_hwconfig_size = sizeof(AVVASTAPIHWConfig),
+    .frames_hwctx_size    = sizeof(AVVASTAPIFramesContext),
+    .frames_priv_size     = sizeof(VASTAPIFramesContext),
+
+    .device_create          = &vastapi_device_create,
+    .device_derive          = &vastapi_device_derive,
+    .device_init            = &vastapi_device_init,
+    .device_uninit          = &vastapi_device_uninit,
+    .frames_get_constraints = &vastapi_frames_get_constraints,
+    .frames_init            = &vastapi_frames_init,
+    .frames_uninit          = &vastapi_frames_uninit,
+    .frames_get_buffer      = &vastapi_get_buffer,
+    .transfer_get_formats   = &vastapi_transfer_get_formats,
+    .transfer_data_to       = &vastapi_transfer_data_to,
+    .transfer_data_from     = &vastapi_transfer_data_from,
+    .map_to                 = &vastapi_map_to,
+    .map_from               = &vastapi_map_from,
+    .sync_surface           = &vastapi_sync_surface_s,
+    .get_frame_addr         = &vastapi_get_addr_from_surfaceid,
+    .set_frame_addr         = &vastapi_set_addr_to_surfaceid,
+    .set_frame_addr_from_fd = &vastapi_set_addr_to_surfaceid_from_fd,
+    .frames_get_dmabuffer   = &vastapi_get_dma_buffer,
+    .transfer_data_to_ex    = &vastapi_transfer_data_to_ex,
+    .transfer_data_from_ex  = &vastapi_transfer_data_from_ex,
+    .pix_fmts               = (const enum AVPixelFormat[]){ AV_PIX_FMT_VASTAPI, AV_PIX_FMT_NONE },
+};
+
+AVFrame *av_frame_alloc_vastai(AVBufferRef *hw_frames_ctx, VastFrameInfo *frameInfo)
+{
+    AVHWFramesContext *hwfc  = NULL;
+    AVFrame           *frame = NULL;
+    int                ret   = 0;
+
+    // 1. check params
+    if (frameInfo == NULL || frameInfo->width <= 0 || frameInfo->height <= 0 || hw_frames_ctx == NULL ||
+        hw_frames_ctx->data == NULL) {
+        av_log(hwfc, AV_LOG_ERROR, "%s: error, Invalid params frameInfo=%p, width=%d, height=%d, hw_frames_ctx=%p\n",
+               __func__, frameInfo, frameInfo->width, frameInfo->height, hwfc);
+        return NULL;
+    }
+
+    hwfc = (AVHWFramesContext *)hw_frames_ctx->data;
+
+    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frameInfo->format);
+    if (!desc) {
+        printf("%s: error, Invalid format %d\n", __func__, frameInfo->format);
+        return NULL;
+    }
+
+    // 2. allocate a new frame
+    frame = av_frame_alloc();
+    if (!frame) {
+        av_log(hwfc, AV_LOG_ERROR, "%s: error, Mem alloc failed\n", __func__);
+        return NULL;
+    }
+
+    frame->format = frameInfo->format;
+    frame->width  = frameInfo->width;
+    frame->height = frameInfo->height;
+
+    // 3. attach a dma buffer to frame->data
+    ret = av_hwframe_get_dmabuffer(hwfc, frame);
+    if (ret) {
+        av_log(hwfc, AV_LOG_ERROR, "%s: get dma buffer error, ret=%d\n", __func__, ret);
+        av_frame_free(&frame);
+        return NULL;
+    }
+
+    frame->extended_data = frame->data;
+
+    return frame;
+}
+
+int av_hwframe_sync_surface(const AVFrame *src)
+{
+    int                ret     = 0;
+    AVHWFramesContext *src_ctx = NULL;
+
+    if (!src->hw_frames_ctx) {
+        av_log(NULL, AV_LOG_ERROR, " hw_frames_ctx is NULL!!!");
+        return -1;
+    }
+
+    src_ctx = (AVHWFramesContext *)src->hw_frames_ctx->data;
+    ret     = src_ctx->internal->hw_type->sync_surface(src_ctx, src);
+
+    return ret;
+}
+
+int av_hwframe_get_addr_from_surfaceid(const AVFrame *src, uint64_t *frame_addr)
+{
+    int                ret     = 0;
+    AVHWFramesContext *src_ctx = NULL;
+
+    if (!src->hw_frames_ctx) {
+        av_log(NULL, AV_LOG_ERROR, " hw_frames_ctx is NULL!!!\n");
+        return -1;
+    }
+
+    src_ctx = (AVHWFramesContext *)src->hw_frames_ctx->data;
+    ret     = src_ctx->internal->hw_type->get_frame_addr(src_ctx, src, frame_addr);
+
+    return ret;
+}
+
+int av_hwframe_set_addr_to_surfaceid(const AVFrame *src, uint64_t frame_addr)
+{
+    int                ret     = 0;
+    AVHWFramesContext *src_ctx = NULL;
+
+    if (!src->hw_frames_ctx) {
+        av_log(NULL, AV_LOG_ERROR, " hw_frames_ctx is NULL!!!\n");
+        return -1;
+    }
+
+    src_ctx = (AVHWFramesContext *)src->hw_frames_ctx->data;
+    ret     = src_ctx->internal->hw_type->set_frame_addr(src_ctx, src, frame_addr);
+
+    return ret;
+}
+
+int av_hwframe_get_dmabuffer(AVHWFramesContext *hwfc, AVFrame *frame)
+{
+    int ret = 0;
+
+    if (!hwfc || !frame) {
+        av_log(NULL, AV_LOG_ERROR, " frame or hw_frames_ctx is NULL!!!\n");
+        return -1;
+    }
+
+    ret = hwfc->internal->hw_type->frames_get_dmabuffer(hwfc, frame);
+    if (ret) {
+        av_log(NULL, AV_LOG_ERROR, " frames_get_dmabuffer failed, ret=%d\n", ret);
+    }
+
+    return ret;
+}
+
+int av_hwframe_transfer_data_ex(AVFrame *dst, const AVFrame *src, int src_type)
+{
+    int                ret = 0;
+    AVHWFramesContext *hwfc;
+
+    if (!dst || !src) {
+        av_log(NULL, AV_LOG_ERROR, "%s %d frame or hw_frames_ctx is NULL!!!\n", __func__, __LINE__);
+        return AVERROR(EINVAL);
+    }
+
+    if (!dst->hw_frames_ctx && !src->hw_frames_ctx) {
+        av_log(NULL, AV_LOG_ERROR, "%s %d invalid hw frame, hw ctx is NULL!!!\n", __func__, __LINE__);
+        return AVERROR(EINVAL);
+    }
+
+    if (dst->hw_frames_ctx) {
+
+        hwfc = (AVHWFramesContext *)(dst->hw_frames_ctx->data);
+
+        ret = hwfc->internal->hw_type->transfer_data_to_ex(hwfc, dst, src, src_type);
+        if (ret) {
+            av_log(NULL, AV_LOG_ERROR, "%s %d  transfer data failed, ret=%d\n", __func__, __LINE__, ret);
+        }
+
+    } else if (src->hw_frames_ctx) {
+
+        hwfc = (AVHWFramesContext *)(src->hw_frames_ctx->data);
+
+        if (!dst->buf[0]) {
+            dst->width  = (((src->width) + (128) - 1) & (~((128) - 1)));
+            dst->height = (((src->height) + (64) - 1) & (~((64) - 1)));
+            dst->format = AV_PIX_FMT_NV12;
+            av_frame_get_buffer(dst, 0x1000);
+        }
+
+        ret = hwfc->internal->hw_type->transfer_data_from_ex(hwfc, dst, src, src_type);
+        if (ret) {
+            av_log(NULL, AV_LOG_ERROR, "%s %d  transfer data failed, ret=%d\n", __func__, __LINE__, ret);
+        }
+
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "%s %d  invalid call func, ret=%d\n", __func__, __LINE__, ret);
+        ret = AVERROR(EPERM);
+    }
+
+    return ret;
+}
+
+int av_hwframe_set_addr_to_surfaceid_from_fd(const AVFrame *src, int dmabuf_fd)
+{
+    int ret = 0;
+    AVHWFramesContext *src_ctx = NULL;
+
+    if (!src->hw_frames_ctx) {
+        av_log(NULL, AV_LOG_ERROR, " hw_frames_ctx is NULL!!!\n");
+        return -1;
+    }
+
+    if (dmabuf_fd <= 0) {
+        av_log(NULL, AV_LOG_ERROR, " invalid dmabuf_fd: %d\n", dmabuf_fd);
+        return -1;
+    }
+
+    src_ctx = (AVHWFramesContext *)src->hw_frames_ctx->data;
+    ret     = src_ctx->internal->hw_type->set_frame_addr_from_fd(src_ctx, src, dmabuf_fd);
+
+    return ret;
+}
+
+#ifdef ANDROID
+#include <android/log.h>
+
+void android_log_callback(void *ptr, int level, const char *fmt, va_list vl)
+{
+    int android_level;
+
+    if (level > av_log_get_level())
+        return;
+
+    switch (level) {
+    case AV_LOG_PANIC:
+    case AV_LOG_FATAL:
+        android_level = ANDROID_LOG_FATAL;
+        break;
+    case AV_LOG_ERROR:
+        android_level = ANDROID_LOG_ERROR;
+        break;
+    case AV_LOG_WARNING:
+        android_level = ANDROID_LOG_WARN;
+        break;
+    case AV_LOG_INFO:
+        android_level = ANDROID_LOG_INFO;
+        break;
+    case AV_LOG_VERBOSE:
+    default:
+        android_level = ANDROID_LOG_DEBUG;
+        break;
+    }
+
+    char message[4096];
+    vsnprintf(message, sizeof(message), fmt, vl);
+
+    __android_log_vprint(android_level, "va_video FFmpeg", message, vl);
+}
+#endif
diff --git a/libavutil/hwcontext_vastapi.h b/libavutil/hwcontext_vastapi.h
new file mode 100644
index 0000000..a13ea83
--- /dev/null
+++ b/libavutil/hwcontext_vastapi.h
@@ -0,0 +1,151 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef AVUTIL_HWCONTEXT_VASTAPI_H
+#define AVUTIL_HWCONTEXT_VASTAPI_H
+
+#include "pixfmt.h"
+#include "vastva/vastapi.h"
+#include "vastva/vastapi_dynlink_loader.h"
+
+static inline int vastaiFmtToAvFmt(int pix_fmt)
+{
+    switch (pix_fmt) {
+    case VAST_FTM_NONE:
+        return AV_PIX_FMT_NONE;
+    case NV12:
+        return AV_PIX_FMT_NV12;
+    case YUV420P:
+        return AV_PIX_FMT_YUV420P;
+    case YUV422P:
+        return AV_PIX_FMT_YUV422P;
+    case UYVY422:
+        return AV_PIX_FMT_UYVY422;
+    case YUYV422:
+        return AV_PIX_FMT_YUYV422;
+    case YUV411P:
+        return AV_PIX_FMT_YUV411P;
+    case YUV440P:
+        return AV_PIX_FMT_YUV440P;
+    case YUV444P:
+        return AV_PIX_FMT_YUV444P;
+    case GRAY8:
+        return AV_PIX_FMT_GRAY8;
+    case P010:
+        return AV_PIX_FMT_P010;
+    case BGRA:
+        return AV_PIX_FMT_BGRA;
+    case BGR0:
+        return AV_PIX_FMT_BGR0;
+    case RGBA:
+        return AV_PIX_FMT_RGBA;
+    case RGB0:
+        return AV_PIX_FMT_RGB0;
+    case ABGR:
+        return AV_PIX_FMT_ABGR;
+    case XBGR:
+        return AV_PIX_FMT_0BGR;
+    case ARGB:
+        return AV_PIX_FMT_ARGB;
+    case XRGB:
+        return AV_PIX_FMT_0RGB;
+    case YUV420P10LE:
+        return AV_PIX_FMT_YUV420P10LE;
+    case YUVJ420P:
+        return AV_PIX_FMT_YUVJ420P;
+    case BAYER_BGGR8:
+        return AV_PIX_FMT_BAYER_BGGR8;
+    case BAYER_RGGB8:
+        return AV_PIX_FMT_BAYER_RGGB8;
+    case BAYER_GBRG8:
+        return AV_PIX_FMT_BAYER_GBRG8;
+    case BAYER_GRBG8:
+        return AV_PIX_FMT_BAYER_GRBG8;
+    // case Y210:           return AV_PIX_FMT_Y210;
+    case YUV420P10:
+        return AV_PIX_FMT_YUV420P10;
+    default:
+        return AV_PIX_FMT_NONE;
+    }
+}
+
+static inline VAST_PIX_FTM avFmtToVastaiFmt(int pix_fmt)
+{
+    switch (pix_fmt) {
+    case AV_PIX_FMT_NONE:
+        return VAST_FTM_NONE;
+    case AV_PIX_FMT_NV12:
+        return NV12;
+    case AV_PIX_FMT_YUV420P:
+        return YUV420P;
+    case AV_PIX_FMT_YUV422P:
+        return YUV422P;
+    case AV_PIX_FMT_UYVY422:
+        return UYVY422;
+    case AV_PIX_FMT_YUYV422:
+        return YUYV422;
+    case AV_PIX_FMT_YUV411P:
+        return YUV411P;
+    case AV_PIX_FMT_YUV440P:
+        return YUV440P;
+    case AV_PIX_FMT_YUV444P:
+        return YUV444P;
+    case AV_PIX_FMT_GRAY8:
+        return GRAY8;
+    case AV_PIX_FMT_P010:
+        return P010;
+    case AV_PIX_FMT_BGRA:
+        return BGRA;
+    case AV_PIX_FMT_BGR0:
+        return BGR0;
+    case AV_PIX_FMT_RGBA:
+        return RGBA;
+    case AV_PIX_FMT_RGB0:
+        return RGB0;
+    case AV_PIX_FMT_ABGR:
+        return ABGR;
+    case AV_PIX_FMT_0BGR:
+        return XBGR;
+    case AV_PIX_FMT_ARGB:
+        return ARGB;
+    case AV_PIX_FMT_0RGB:
+        return XRGB;
+    case AV_PIX_FMT_YUV420P10LE:
+        return YUV420P10LE;
+    case AV_PIX_FMT_YUVJ420P:
+        return YUVJ420P;
+    case AV_PIX_FMT_BAYER_BGGR8:
+        return BAYER_BGGR8;
+    case AV_PIX_FMT_BAYER_RGGB8:
+        return BAYER_RGGB8;
+    case AV_PIX_FMT_BAYER_GBRG8:
+        return BAYER_GBRG8;
+    case AV_PIX_FMT_BAYER_GRBG8:
+        return BAYER_GRBG8;
+        // case AV_PIX_FMT_Y210:         return Y210;
+
+    default:
+        return VAST_FTM_NONE;
+    }
+}
+
+#ifdef ANDROID
+void android_log_callback(void *ptr, int level, const char *fmt, va_list vl);
+#endif
+
+#endif /* AVUTIL_HWCONTEXT_VASTAPI_H */
diff --git a/libavutil/log.c b/libavutil/log.c
index 66defa9..a87bfae 100644
--- a/libavutil/log.c
+++ b/libavutil/log.c
@@ -401,8 +401,13 @@ end:
     ff_mutex_unlock(&mutex);
 }
 
+#ifdef ANDROID
+void android_log_callback(void* ptr, int level, const char* fmt, va_list vl);
+static void (*av_log_callback)(void*, int, const char*, va_list) = android_log_callback;
+#else
 static void (*av_log_callback)(void*, int, const char*, va_list) =
     av_log_default_callback;
+#endif
 
 void av_log(void* avcl, int level, const char *fmt, ...)
 {
diff --git a/libavutil/pixdesc.c b/libavutil/pixdesc.c
index 727d754..5182e5f 100644
--- a/libavutil/pixdesc.c
+++ b/libavutil/pixdesc.c
@@ -1354,6 +1354,12 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         .log2_chroma_h = 1,
         .flags = AV_PIX_FMT_FLAG_HWACCEL,
     },
+    [AV_PIX_FMT_VASTAPI] = {
+        .name = "vastapi",
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
     [AV_PIX_FMT_YUV420P9LE] = {
         .name = "yuv420p9le",
         .nb_components = 3,
diff --git a/libavutil/pixfmt.h b/libavutil/pixfmt.h
index 02e355e..dcce333 100644
--- a/libavutil/pixfmt.h
+++ b/libavutil/pixfmt.h
@@ -117,6 +117,7 @@ enum AVPixelFormat {
      *  VASurfaceID.
      */
     AV_PIX_FMT_VAAPI,
+    AV_PIX_FMT_VASTAPI,
 
     AV_PIX_FMT_YUV420P16LE,  ///< planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), little-endian
     AV_PIX_FMT_YUV420P16BE,  ///< planar YUV 4:2:0, 24bpp, (1 Cr & Cb sample per 2x2 Y samples), big-endian
diff --git a/libswscale/utils.c b/libswscale/utils.c
old mode 100644
new mode 100755
index c5ea885..6ecd8db
--- a/libswscale/utils.c
+++ b/libswscale/utils.c
@@ -175,6 +175,9 @@ static const FormatEntry format_entries[] = {
     [AV_PIX_FMT_BGR565LE]    = { 1, 1 },
     [AV_PIX_FMT_BGR555BE]    = { 1, 1 },
     [AV_PIX_FMT_BGR555LE]    = { 1, 1 },
+    #if CONFIG_VASTAPI
+    [AV_PIX_FMT_VASTAPI]     = { 1, 1 },
+    #endif
     [AV_PIX_FMT_YUV420P16LE] = { 1, 1 },
     [AV_PIX_FMT_YUV420P16BE] = { 1, 1 },
     [AV_PIX_FMT_YUV422P16LE] = { 1, 1 },
